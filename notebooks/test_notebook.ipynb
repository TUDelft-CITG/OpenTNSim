{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "828b9bd9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Installed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c7f1513",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# package(s) related to time, space and id\n",
    "import datetime, time\n",
    "import os\n",
    "import io\n",
    "import functools\n",
    "import logging\n",
    "import pickle\n",
    "import random\n",
    "import math\n",
    "\n",
    "# package(s) related to the simulation\n",
    "import enum\n",
    "import simpy\n",
    "import scipy as sc\n",
    "import math\n",
    "import networkx as nx  \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import yaml as yaml\n",
    "import time\n",
    "import bisect\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as tri\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "from scipy import interpolate\n",
    "from scipy.signal import correlate\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "\n",
    "# OpenTNSim\n",
    "from opentnsim import core\n",
    "from opentnsim import plot\n",
    "from opentnsim import model\n",
    "\n",
    "# spatial libraries \n",
    "import shapely.geometry\n",
    "import shapely.wkt\n",
    "import pyproj\n",
    "import shapely.geometry\n",
    "import folium\n",
    "import datetime\n",
    "import time as timepy\n",
    "\n",
    "# package(s) for data handling\n",
    "import requests\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# define the coorinate systemb\n",
    "geod = pyproj.Geod(ellps=\"WGS84\")\n",
    "\n",
    "location_vessel_database = \"Vessels/richtlijnen-vaarwegen-2017.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a603b08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "core.__file__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ea83ea",
   "metadata": {},
   "source": [
    "# Load data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0081a438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_wlevel= pd.read_csv(r'C:\\Users\\floorbakker\\OpenTNSim\\notebooks\\WL_dataset.csv',delimiter=',')\n",
    "# df_VM= pd.read_csv(r'C:\\Users\\floorbakker\\OpenTNSim\\notebooks\\VM_dataset.csv',delimiter=',')\n",
    "# df_Van= pd.read_csv(r'C:\\Users\\floorbakker\\OpenTNSim\\notebooks\\Van_dataset.csv',delimiter=',')\n",
    "\n",
    "df_wlevel= pd.read_csv(r'C:\\Users\\floorbakker\\OpenTNSim\\notebooks\\WL_dataset.csv',delimiter=',')\n",
    "df_VM= pd.read_csv(r'C:\\Users\\floorbakker\\OpenTNSim\\notebooks\\VM_dataset.csv',delimiter=',')\n",
    "df_Van= pd.read_csv(r'C:\\Users\\floorbakker\\OpenTNSim\\notebooks\\Van_dataset.csv',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e87926",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Node = type('Site', (core.Identifiable, core.Log, core.Locatable, core.HasResource), {})\n",
    "nodes = []\n",
    "path = []\n",
    "coords = []\n",
    "\n",
    "coords.append([2.68276,51.84278]) #node_1 origin\n",
    "coords.append([2.76847,51.8981])#node_2\n",
    "coords.append([2.89251,51.94136])#node_3\n",
    "coords.append([2.91627,51.94957])#node_4\n",
    "coords.append([3.88419,52.02922])#node_5\n",
    "coords.append([3.93995795592471,52.0219158335973]) #node_6\n",
    "coords.append([4.04961843717028,51.9913123648208]) #node_7\n",
    "coords.append([4.1187846584378,51.9756279862634]) #node_8\n",
    "coords.append([4.15471631295706,51.9596283586068]) #node_9\n",
    "coords.append([4.19884102088863,51.9382313719035]) #node_10\n",
    "coords.append([4.22030870030092,51.9302898518613]) #node_11\n",
    "coords.append([4.24286991304305,51.9141858383526]) #node_12\n",
    "coords.append([4.27537465881064,51.9015756264453]) #node_13\n",
    "coords.append([4.29337962495028,51.8968867771695]) #node_14\n",
    "coords.append([4.30388786112617,51.8947760348761]) #node_15\n",
    "coords.append([4.308557,51.889522]) #node_16 turning basin\n",
    "coords.append([4.308335,51.884692])#node_17 \n",
    "coords.append([4.306804,51.879432]) #node_18\n",
    "coords.append([4.312392,51.874262]) #node_19, destination\n",
    "coords.append([2.9054,51.92534]) #node_20, anchorage 1 north\n",
    "coords.append([2.7474,52.08876]) #node_21, anchorage 2 south\n",
    "\n",
    "for d in range(len(coords)):\n",
    "    data_node = {\"env\": [],\n",
    "                 \"name\": \"Node \" + str(d+1),\n",
    "                 \"geometry\": shapely.geometry.Point(coords[d][0], coords[d][1])}\n",
    "    node = Node(**data_node)\n",
    "    nodes.append(node)\n",
    "    \n",
    "for i in range(len(nodes)-3):\n",
    "    path.append([nodes[i],nodes[i+1]]) \n",
    "    path.append([nodes[i+1],nodes[i]])\n",
    "    \n",
    "path.append([nodes[2],nodes[19]]) # channel - anchorage 1 \n",
    "path.append([nodes[19],nodes[2]]) # anchorage 1- channel\n",
    "path.append([nodes[2],nodes[20]])  # channel - anchorage 2\n",
    "path.append([nodes[20],nodes[2]])  # anchorage 2-channel\n",
    "\n",
    "\n",
    "FG = nx.DiGraph()\n",
    "\n",
    "positions = {}\n",
    "for node in nodes:\n",
    "    positions[node.name] = (node.geometry.x, node.geometry.y)\n",
    "    FG.add_node(node.name, geometry = node.geometry)\n",
    "\n",
    "for edge in path:\n",
    "    FG.add_edge(edge[0].name, edge[1].name, weight = 1, Info = {})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "nx.draw(FG, positions)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7645455b",
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the network \n",
    "m = folium.Map(location=[52, 3.4], zoom_start = 9, tiles=\"cartodbpositron\")\n",
    "\n",
    "line = []\n",
    "for node in list(FG.nodes())[0:19]:\n",
    "    points_x = FG.nodes[node][\"geometry\"].x\n",
    "    points_y = FG.nodes[node][\"geometry\"].y\n",
    "    line.append([points_y, points_x])\n",
    "    if node == 'Node 3':\n",
    "        line.append([FG.nodes['Node 20'][\"geometry\"].y, FG.nodes['Node 20'][\"geometry\"].x])\n",
    "        line.append([points_y, points_x])\n",
    "        line.append([FG.nodes['Node 21'][\"geometry\"].y, FG.nodes['Node 21'][\"geometry\"].x])\n",
    "        line.append([points_y, points_x])\n",
    "    \n",
    "folium.PolyLine(line, weight = 2).add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c03e66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_start = datetime.datetime.now()\n",
    "sim = model.Simulation(simulation_start,FG)\n",
    "env = sim.environment\n",
    "duration = 14*24*3600 #seconds\n",
    "#duration = 15290000 #seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0ce24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "terminal_1 = core.IsTerminal(env = env, \n",
    "                             name = 'Koole terminal',\n",
    "                             length = 700, \n",
    "                             node_start = 'Node 18', \n",
    "                             node_end = 'Node 19', \n",
    "                             type = 'quay')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc5f356",
   "metadata": {},
   "source": [
    "The Koole terminal has 5 deepsea jetties, coaster+IWT jetties, and 6 jetties dedicated for IWT. For this exercise I'll only take the 5 deepsea jetties and I'll add them to a single terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7a01af",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.FG = FG\n",
    "\n",
    "turning_basin_1 = core.IsTurningBasin(env = env, name = 'Turning Basin 1', node = 'Node 16', length = 300)\n",
    "\n",
    "origin_1 = core.IsOrigin(env = env, name = 'Origin 1')\n",
    "\n",
    "anchorage_1 = core.IsAnchorage(env = env, name = 'Anchorage 1', node = 'Node 20', type = 'sea_going_vessels',max_capacity = 50)\n",
    "anchorage_2 = core.IsAnchorage(env = env, name = 'Anchorage 2', node = 'Node 21', type = 'sea_going_vessels',max_capacity = 50)\n",
    "\n",
    "terminal_1 = core.IsTerminal(env = env, name = 'Koole terminal',length = 700, jetty_locations = [100,200,300,400,500], jetty_lengths = [300,300,300,300,300], node_start = 'Node 18', node_end = 'Node 19', type = 'jetty')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ba63c8",
   "metadata": {},
   "source": [
    "## Anchorage capacity\n",
    "\n",
    "Argument: Anchorage areas 3A + 3C seems to have around 10 ships at the same time (Marine Traffic.com and master thesis by Devill√©). \n",
    "\n",
    "what is a reasonable value of the anchorage capacity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544c87ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FG.nodes[\"Node 1\"][\"Origin\"] = [origin_1]\n",
    "\n",
    "FG.nodes[\"Node 20\"][\"Anchorage\"] = [anchorage_1]\n",
    "\n",
    "FG.nodes[\"Node 21\"][\"Anchorage\"] = [anchorage_2]\n",
    "\n",
    "FG.nodes[\"Node 16\"][\"Turning Basin\"] = [turning_basin_1]\n",
    "\n",
    "# FG.nodes[\"Node 18\"][\"Turning Basin\"] = [turning_basin_2] I could add this one later on\n",
    "\n",
    "FG.nodes[\"Node 1\"][\"Junction\"] = core.IsJunction(env = [], name = [], sections = [], type = []) #origin\n",
    "FG.nodes[\"Node 1\"][\"Junction\"].name = ['waterway_access']\n",
    "FG.nodes[\"Node 1\"][\"Junction\"].type = ['two-way_traffic']\n",
    "\n",
    "FG.nodes[\"Node 16\"][\"Junction\"] = core.IsJunction(env = [], name = [], sections = [], type = []) #turn Basin acccess to 3e PH\n",
    "FG.nodes[\"Node 16\"][\"Junction\"].name = ['waterway_access','harbour_basin_access']\n",
    "FG.nodes[\"Node 16\"][\"Junction\"].type = ['two-way_traffic','one-way_traffic']\n",
    "\n",
    "#FG.nodes[\"Node 17\"][\"Junction\"] = core.IsJunction(env = [], name = [], sections = [], type = []) #start terminal\n",
    "#FG.nodes[\"Node 17\"][\"Junction\"].name = ['waterway_access','waterway_access']\n",
    "#FG.nodes[\"Node 17\"][\"Junction\"].type = ['one-way_traffic','one-way_traffic']\n",
    "\n",
    "#FG.nodes[\"Node 18\"][\"Junction\"] = core.IsJunction(env = [], name = [], sections = [], type = []) #middle part of the terminal\n",
    "#FG.nodes[\"Node 18\"][\"Junction\"].name = ['waterway_access','harbour_basin_access']\n",
    "#FG.nodes[\"Node 18\"][\"Junction\"].type = ['one-way_traffic','one-way_traffic']\n",
    "\n",
    "FG.nodes[\"Node 19\"][\"Junction\"] = core.IsJunction(env = [], name = [], sections = [], type = []) #end point route\n",
    "FG.nodes[\"Node 19\"][\"Junction\"].name = ['harbour_basin_access']\n",
    "FG.nodes[\"Node 19\"][\"Junction\"].type = ['one-way_traffic']\n",
    "\n",
    "FG.nodes[\"Node 3\"][\"Junction\"] = core.IsJunction(env = [], name = [], sections = [], type = []) #neural point\n",
    "FG.nodes[\"Node 3\"][\"Junction\"].name = ['waterway_access','waterway_access','anchorage_access','anchorage_access']\n",
    "FG.nodes[\"Node 3\"][\"Junction\"].type = ['two-way_traffic','two-way_traffic','two-way_traffic','two-way_traffic']\n",
    "\n",
    "FG.nodes[\"Node 20\"][\"Junction\"] = core.IsJunction(env = [], name = [], sections = [], type = []) #anchorage 1\n",
    "FG.nodes[\"Node 20\"][\"Junction\"].name = ['anchorage_access']\n",
    "FG.nodes[\"Node 20\"][\"Junction\"].type = ['two-way_traffic']\n",
    "\n",
    "FG.nodes[\"Node 21\"][\"Junction\"] = core.IsJunction(env = [], name = [], sections = [], type = []) #anchorage 2\n",
    "FG.nodes[\"Node 21\"][\"Junction\"].name = ['anchorage_access']\n",
    "FG.nodes[\"Node 21\"][\"Junction\"].type = ['two-way_traffic']\n",
    "\n",
    "\n",
    "junction_nodes = []\n",
    "for node in list(FG.nodes):\n",
    "    if 'Junction' in FG.nodes[node]:\n",
    "        junction_nodes.append(node)\n",
    "        \n",
    "for node1 in junction_nodes:\n",
    "    names = []\n",
    "    sections = []\n",
    "    types = []\n",
    "    for node2 in junction_nodes:\n",
    "        if node1 == node2:\n",
    "            continue\n",
    "            \n",
    "        route = nx.dijkstra_path(FG, node1, node2)\n",
    "        section = True\n",
    "        for node in route[1:-1]:\n",
    "            if 'Junction' in FG.nodes[node]:\n",
    "                section = False\n",
    "                break\n",
    "\n",
    "        if section:\n",
    "            sections.append([node1,node2])\n",
    "            names.append(FG.nodes[node1][\"Junction\"].name[len(sections)-1])\n",
    "            types.append(FG.nodes[node1][\"Junction\"].type[len(sections)-1])\n",
    "    \n",
    "    FG.nodes[node1][\"Junction\"] = [core.IsJunction(env = env, name = names, sections = sections, type = types)]\n",
    "            \n",
    "FG.edges['Node 18','Node 19'][\"Terminal\"] = [terminal_1]\n",
    "\n",
    "for edge in enumerate(FG.edges):\n",
    "    if 'Terminal' in FG.edges[edge[1]]:\n",
    "        FG.edges[edge[1][1],edge[1][0]]['Terminal'] = FG.edges[edge[1]]['Terminal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc58205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List 8 vessels\n",
    "vdf = pd.DataFrame()\n",
    "vdf[0] = ['Small coaster 1','Small coaster 2','Coaster','Handysize','Tanker MR','Tanker LR1','Tanker LR2 1','Tanker LR2 2']\n",
    "vdf[1] = [71,110,126,149,184,228,243,249] #length\n",
    "vdf[2] = [10.1,13.5,19,22,27,32,42,46] #beam\n",
    "vdf[3] = [4.5,5.45,8.5,10,11.4,12.1,13.6,15] # draught + FWA\n",
    "vdf[4] = 0.5*vdf[3] #unloaded draught\n",
    "vdf[5] = [17,17,17,17,17,17,17,17] #H_e free board empty- Update!\n",
    "vdf[6] = vdf[5]-(vdf[3]-vdf[4]) #H_f free board loaded\n",
    "vdf[7] = [60,60,60,60,60,60,60,60] #t_b in minutes - berthing time (assumed in 1hs)\n",
    "vdf[8] = [15*60,16.7*60,16.7*60,18.3*60,18.3*60,18.3*60,18.3*60,18.3*60] #t_l loading + unloading time (in minutes)\n",
    "vdf[9] = [0,0,0,0,0,0,0,0] #UKC\n",
    "vdf[10] = [4.5,4.5,4.5,4.5,4.5,4.5,4.5,4.5] # vessel speed in m/s - check with S. de Jong thesis\n",
    "# vdf[10] = [6,6,6,6,6,6,6,6] # vessel speed in m/s - own assumption\n",
    "vdf[11] = [18*60*60,18*60*60,18*60*60,18*60*60,18*60*60,18*60*60,18*60*60,18*60*60] # max waiting time in seconds\n",
    "vdf[12] = [0,0,0,0,0,0,0,0] #critical cross-current velocity in m/s\n",
    "vdf.columns = ['type','L','B','T_f','T_e','H_e','H_f','t_b','t_l','ukc','v','max_waiting_time','max_cross_current']\n",
    "vdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381f3238",
   "metadata": {},
   "source": [
    "Explanation parameters: \n",
    "- max current: for Node 15 a maximum FLOOD current of 0.5knots is defined --> I'll assume the same limit as CROSS-CURRENT for that node\n",
    "- For nodes between 15 and 19 (to destination), the same limit is applied.\n",
    "- max current: for the rest of the nodes, define a theoretical value for the open sea and another for the NWW channel --> values in PIANC Design of Harbour Approach channels --> open sea: strong current 2knots ; channel=moderate current 1.5knots\n",
    "\n",
    "\n",
    "Max waiting time:\n",
    "For liquid bulk = 18hs so it is the same as the largest value of the service time --> check with literature!\n",
    "\n",
    "Terminal occupancy, typical value for a liquid bulk terminal (van Koninsgveld et al, 2021)\n",
    "the acceptable berth occupancy lies between 40% for a single berth and 80% for four berths --> in this case, 4/5 jetties are occupied\n",
    "\n",
    "Service time --> values based on EIA deepening project\n",
    "\n",
    "Arrival time --> define value in such a way that there is a terminal occupancy of 0.6-0.8 and no port congestion.\n",
    "ASK FLOOR IF THE MODEL CAN USE STOCHASTIC ARRIVAL TIME DISTRIBUTIONS\n",
    "\n",
    "Duration of the sumlation and number of generated vessels --> number of generated vessels defines the accuracy of the generator (sampling uniform distribution) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84436c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## USE THIS CELL FOR SHIP GENERATOR WITH constant ARRIVAL RATE\n",
    "Vessel = type('Vessel', \n",
    "              (core.Identifiable, core.Movable, core.Routeable, core.VesselProperties, core.ExtraMetadata), {})\n",
    "\n",
    "generator_sea = model.VesselGenerator(Vessel,vdf,random_seed=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a641e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### USE THIS CELL FOR SHIP GENERATOR WITH constant ARRIVAL RATE\n",
    "origin = 'Node 1' #coasters should enter empty and leave full (export) --> UPDATE SOMEWHERE\n",
    "destination = 'Node 19'\n",
    "vessel1 = Vessel(name='LR1',\n",
    "                 geometry=FG.nodes[origin]['geometry'],\n",
    "                 route=nx.dijkstra_path(FG,origin,destination),\n",
    "                 env=env,\n",
    "                 type='Tanker',\n",
    "                 B = vdf['B'][5],\n",
    "                 L = vdf['L'][5],\n",
    "                 T_f = vdf['T_f'][5],\n",
    "                 T_e = vdf['T_e'][5],\n",
    "                 H_e = vdf['H_e'][5],\n",
    "                 H_f = vdf['H_f'][5],\n",
    "                 t_b = vdf['t_b'][5],\n",
    "                 t_l = vdf['t_l'][5],\n",
    "                 ukc = vdf['ukc'][5],\n",
    "                 v = vdf['v'][5],\n",
    "                 max_waiting_time = vdf['max_waiting_time'][5],\n",
    "                 max_cross_current = vdf['max_cross_current'][5],\n",
    "                 start_time = 12500,)\n",
    "sim.add_vessels(origin,destination,[],vessel1)\n",
    "vessel2 = Vessel(name='MR',\n",
    "                 geometry=FG.nodes[origin]['geometry'],\n",
    "                 route=nx.dijkstra_path(FG,origin,destination),\n",
    "                 env=env,\n",
    "                 type='Tanker',\n",
    "                 B = vdf['B'][4],\n",
    "                 L = vdf['L'][4],\n",
    "                 T_f = vdf['T_f'][4],\n",
    "                 T_e = vdf['T_e'][4],\n",
    "                 H_e = vdf['H_e'][4],\n",
    "                 H_f = vdf['H_f'][4],\n",
    "                 t_b = vdf['t_b'][4],\n",
    "                 t_l = vdf['t_l'][4],\n",
    "                 ukc = vdf['ukc'][4],\n",
    "                 v = vdf['v'][4],\n",
    "                 max_waiting_time = vdf['max_waiting_time'][4],\n",
    "                 max_cross_current = vdf['max_cross_current'][4],\n",
    "                 start_time = 50000,)\n",
    "sim.add_vessels(origin,destination,[],vessel2)\n",
    "vessel3 = Vessel(name='LR2 1',\n",
    "                 geometry=FG.nodes[origin]['geometry'],\n",
    "                 route=nx.dijkstra_path(FG,origin,destination),\n",
    "                 env=env,\n",
    "                 type='Tanker',\n",
    "                 B = vdf['B'][6],\n",
    "                 L = vdf['L'][6],\n",
    "                 T_f = vdf['T_f'][6],\n",
    "                 T_e = vdf['T_e'][6],\n",
    "                 H_e = vdf['H_e'][6],\n",
    "                 H_f = vdf['H_f'][6],\n",
    "                 t_b = vdf['t_b'][6],\n",
    "                 t_l = vdf['t_l'][6],\n",
    "                 ukc = vdf['ukc'][6],\n",
    "                 v = vdf['v'][6],\n",
    "                 max_waiting_time = vdf['max_waiting_time'][6],\n",
    "                 max_cross_current = vdf['max_cross_current'][6],\n",
    "                 start_time = 240000,)\n",
    "sim.add_vessels(origin,destination,[],vessel3)\n",
    "vessel4 = Vessel(name='Handysize',\n",
    "                 geometry=FG.nodes[origin]['geometry'],\n",
    "                 route=nx.dijkstra_path(FG,origin,destination),\n",
    "                 env=env,\n",
    "                 type='Tanker',\n",
    "                 B = vdf['B'][3],\n",
    "                 L = vdf['L'][3],\n",
    "                 T_f = vdf['T_f'][2],\n",
    "                 T_e = vdf['T_e'][3],\n",
    "                 H_e = vdf['H_e'][3],\n",
    "                 H_f = vdf['H_f'][3],\n",
    "                 t_b = vdf['t_b'][3],\n",
    "                 t_l = vdf['t_l'][3],\n",
    "                 ukc = vdf['ukc'][3],\n",
    "                 v = vdf['v'][3],\n",
    "                 max_waiting_time = vdf['max_waiting_time'][3],\n",
    "                 max_cross_current = vdf['max_cross_current'][3],\n",
    "                 start_time = 285000,)\n",
    "sim.add_vessels(origin,destination,[],vessel4)\n",
    "vessel5 = Vessel(name='LR1',\n",
    "                 geometry=FG.nodes[origin]['geometry'],\n",
    "                 route=nx.dijkstra_path(FG,origin,destination),\n",
    "                 env=env,\n",
    "                 type='Tanker',\n",
    "                 B = vdf['B'][5],\n",
    "                 L = vdf['L'][5],\n",
    "                 T_f = vdf['T_f'][5],\n",
    "                 T_e = vdf['T_e'][5],\n",
    "                 H_e = vdf['H_e'][5],\n",
    "                 H_f = vdf['H_f'][5],\n",
    "                 t_b = vdf['t_b'][5],\n",
    "                 t_l = vdf['t_l'][5],\n",
    "                 ukc = vdf['ukc'][5],\n",
    "                 v = vdf['v'][5],\n",
    "                 max_waiting_time = vdf['max_waiting_time'][5],\n",
    "                 max_cross_current = vdf['max_cross_current'][5],\n",
    "                 start_time = 451000,)\n",
    "sim.add_vessels(origin,destination,[],vessel5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedd58fd",
   "metadata": {},
   "source": [
    "## WATER LEVEL AND VELOCITY FIELD + BATHYMETRY (water depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da02094c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define variables\n",
    "depth = [[],[]]\n",
    "width = [[],[]]\n",
    "MBL = [[],[]]\n",
    "water_level=[[],[]]\n",
    "current_velocity = [[],[]]\n",
    "current_direction = [[],[]]\n",
    "time = np.arange(0,duration,60)\n",
    "\n",
    "# depth according to MBL values, and waterway navigational width obtained from measuring on HavenKaart\n",
    "MBL[1] = [50,50,50,50,50,24.3,13.1,13.1,13.1,13.1,13.1,13.1,13.1,13.1,13.1,13.1,13.1,13.1,50,50,50]\n",
    "depth[1] = MBL[1]\n",
    "width[1] = [1000,1000,1000,1000,1000,600,300,300,200,200,200,200,200,200,200,200,180,180,180,1000,1000]\n",
    "\n",
    "# load water level, velocity magnitude and direction time series to each node\n",
    "for nodes in enumerate(FG.nodes):\n",
    "    MBL[0].append(FG.nodes[nodes[1]]['geometry'])\n",
    "    width[0].append(FG.nodes[nodes[1]]['geometry'])\n",
    "    depth[0].append((FG.nodes[nodes[1]]['geometry']))\n",
    "    water_level[0].append((FG.nodes[nodes[1]]['geometry']))\n",
    "    water_level[1].append([[],[]])\n",
    "    current_velocity[0].append((FG.nodes[nodes[1]]['geometry']))\n",
    "    current_velocity[1].append([[],[]])\n",
    "    current_direction[0].append((FG.nodes[nodes[1]]['geometry']))\n",
    "    current_direction[1].append([[],[]])\n",
    "    \n",
    "for col in enumerate(df_wlevel.columns[1:]): #load water level\n",
    "    water_level[1][col[0]][0]=[x-df_wlevel[df_wlevel.columns[0]][0]+simulation_start.timestamp() for x in list(df_wlevel[df_wlevel.columns[0]])]\n",
    "    water_level[1][col[0]][1]=list(df_wlevel[col[1]])    \n",
    "    \n",
    "for col in enumerate(df_VM.columns[1:]): #load velocity magnitude\n",
    "    current_velocity[1][col[0]][0]=[x-df_VM[df_VM.columns[0]][0]+simulation_start.timestamp() for x in list(df_VM[df_VM.columns[0]])]\n",
    "    current_velocity[1][col[0]][1]=list(df_VM[col[1]])\n",
    "     \n",
    "for col in enumerate(df_Van.columns[1:]): #load velocity direction\n",
    "    current_direction[1][col[0]][0]=[x-df_Van[df_Van.columns[0]][0]+simulation_start.timestamp() for x in list(df_Van[df_Van.columns[0]])]\n",
    "    current_direction[1][col[0]][1]=list(df_Van[col[1]])\n",
    "\n",
    "core.NetworkProperties.append_data_to_nodes(FG,width,depth,MBL,water_level,current_velocity,current_direction)\n",
    "knots = 0.51444444444444"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f3b543",
   "metadata": {},
   "outputs": [],
   "source": [
    "class window_method(Enum):\n",
    "    critical_cross_current = 'Critical cross-current'\n",
    "    point_based = 'Point-based'\n",
    "    \n",
    "class vessel_characteristics(Enum):\n",
    "    min_ge_Length = ['minLength','>=']\n",
    "    min_gt_Length = ['minLength','>']\n",
    "    max_le_Length = ['maxLength','<=']\n",
    "    max_lt_Length = ['maxLength','<']\n",
    "    min_ge_Draught = ['minDraught','>=']\n",
    "    min_gt_Draught = ['minDraught','>']\n",
    "    max_le_Draught = ['maxDraught','<=']\n",
    "    max_lt_Draught = ['maxDraught','<']\n",
    "    min_ge_Beam = ['minBeam','>=']\n",
    "    min_gt_Beam = ['minBeam','>']\n",
    "    max_le_Beam = ['maxBeam','<=']\n",
    "    max_lt_Beam = ['maxBeam','<']\n",
    "    min_ge_UKC = ['minUKC','>=']\n",
    "    min_gt_UKC = ['minUKC','>']\n",
    "    max_le_UKC = ['maxUKC','<=']\n",
    "    max_lt_UKC = ['maxUKC','<']\n",
    "    Type = ['Type','==']\n",
    "\n",
    "class vessel_direction(Enum):\n",
    "    inbound = 'inbound'\n",
    "    outbound = 'outbound'\n",
    "    \n",
    "class vessel_type(Enum):\n",
    "    GeneralCargo = 'GeneralCargo'\n",
    "    LiquidBulk = 'LiquidBulk'\n",
    "    Container = 'Container'\n",
    "    DryBulk = 'DryBulk'\n",
    "    MultiPurpose = 'MultiPurpose'\n",
    "    Reefer = 'Reefer'\n",
    "    RoRo = 'RoRo'\n",
    "    Barge = 'Barge'\n",
    "    \n",
    "class accessibility(Enum):\n",
    "    non_accessible = 0\n",
    "    accessible = -1\n",
    "    \n",
    "class tidal_period(Enum):\n",
    "    Flood = 'Flood'\n",
    "    Ebb = 'Ebb'\n",
    "    \n",
    "class current_velocity_type(Enum):\n",
    "    CurrentVelocity = 'Current velocity'\n",
    "    LongitudinalCurrent = 'Longitudinal current'\n",
    "    CrossCurrent = 'Cross-current'\n",
    "    \n",
    "@dataclass\n",
    "class vessel_specifications:\n",
    "    vessel_characteristics: dict #{item of vessel_characteristics class: user-defined value,...}\n",
    "    vessel_method: str #string containing the operators between the vessel characteristics (symbolized by x): e.g. '(x and x) or x'\n",
    "    vessel_direction: str #item of vessel_direction class\n",
    "\n",
    "    def characteristic_dicts(self):\n",
    "        characteristic_dicts = {}\n",
    "        for characteristic in self.vessel_characteristics:\n",
    "            characteristic_dict = {characteristic.value[0]: [characteristic.value[1],self.vessel_characteristics[characteristic]]}\n",
    "            characteristic_dicts = characteristic_dicts | characteristic_dict\n",
    "        return characteristic_dicts\n",
    "\n",
    "@dataclass\n",
    "class window_specifications:\n",
    "    window_method: str #item of window_method class\n",
    "    current_velocity_values: dict #{tidal_period.Flood.value: user-defined value or item from accessibility class,...}\n",
    "    current_velocity_ranges: dict = dict #if window_method is point-based: {tidal_period.Ebb.value: user-defined value,...}\n",
    "\n",
    "@dataclass\n",
    "class vtw_window_specifications:\n",
    "    ukc_s: dict #{tidal_period.Flood.value: user-defined value or item from accessibility class,...}\n",
    "    ukc_p: dict #{tidal_period.Flood.value: user-defined value or item from accessibility class,...}\n",
    "    fwa: dict #{tidal_period.Flood.value: user-defined value or item from accessibility class,...}\n",
    "\n",
    "@dataclass\n",
    "class vertical_tidal_window_input:\n",
    "    vessel_specifications: vessel_specifications #class\n",
    "    window_specifications: window_specifications #class     \n",
    "        \n",
    "@dataclass\n",
    "class horizontal_tidal_window_input:\n",
    "    vessel_specifications: vessel_specifications #class\n",
    "    window_specifications: window_specifications #class     \n",
    "    condition: dict #{'Origin':node, 'Destination': node}\n",
    "    data: list #Calculated input: [node,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9db3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in FG.nodes:\n",
    "    vertical_tidal_window_inputs = []\n",
    "\n",
    "    vessel_specification = vessel_specifications({vessel_characteristics.min_ge_Draught: 0},\n",
    "                                                  'x',vessel_direction.inbound.value)\n",
    "\n",
    "    window_specification = vtw_window_specifications({'ukc_s': 0.0},\n",
    "                                                     {'ukc_p': 0.1},\n",
    "                                                     {'fwa': 0.025})\n",
    "    \n",
    "    vertical_tidal_window_inputs.append(vertical_tidal_window_input(vessel_specifications = vessel_specification,\n",
    "                                                                    window_specifications = window_specification))\n",
    "\n",
    "    vessel_specification = vessel_specifications({vessel_characteristics.min_ge_Draught: 0},\n",
    "                                                  'x',vessel_direction.outbound.value)\n",
    "\n",
    "    window_specification = vtw_window_specifications({'ukc_s': 0.0},\n",
    "                                                     {'ukc_p': 0.1},\n",
    "                                                     {'fwa': 0.025})\n",
    "\n",
    "    vertical_tidal_window_inputs.append(vertical_tidal_window_input(vessel_specifications = vessel_specification,\n",
    "                                                                    window_specifications = window_specification))\n",
    "\n",
    "    core.NetworkProperties.append_vertical_tidal_restriction_to_network(FG,node,vertical_tidal_window_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b50641",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_tidal_window_inputs = []\n",
    "\n",
    "#Inbound_Vessels_Condition1\n",
    "vessel_specification = vessel_specifications({vessel_characteristics.max_lt_Draught: 14.3},\n",
    "                                              'x',vessel_direction.inbound.value)\n",
    "\n",
    "window_specification = window_specifications(window_method.point_based.value,\n",
    "                                             {tidal_period.Flood.value: 2*knots,tidal_period.Ebb.value: accessibility.accessible.value},\n",
    "                                             {tidal_period.Flood.value: 0.3,tidal_period.Ebb.value:0})\n",
    "\n",
    "horizontal_tidal_window_inputs.append(horizontal_tidal_window_input(vessel_specifications = vessel_specification,\n",
    "                                                                    window_specifications = window_specification,\n",
    "                                                                    condition = {'Origin': 'Node 11', 'Destination': 'Node 13'},\n",
    "                                                                    data = ['Node 14', current_velocity_type.CurrentVelocity.value]));\n",
    "\n",
    "#Inbound_Vessels_Condition2\n",
    "vessel_specification = vessel_specifications({vessel_characteristics.min_ge_Draught: 14.3},\n",
    "                                              'x',vessel_direction.inbound.value)\n",
    "\n",
    "window_specification = window_specifications(window_method.point_based.value,\n",
    "                                             {tidal_period.Flood.value: 0.5*knots,tidal_period.Ebb.value: accessibility.accessible.value},\n",
    "                                             {tidal_period.Flood.value: 0.3,tidal_period.Ebb.value:0})\n",
    "\n",
    "horizontal_tidal_window_inputs.append(horizontal_tidal_window_input(vessel_specifications = vessel_specification,\n",
    "                                                                    window_specifications = window_specification,\n",
    "                                                                    condition = {'Origin': 'Node 11', 'Destination': 'Node 13'},\n",
    "                                                                    data = ['Node 14', current_velocity_type.CurrentVelocity.value]));\n",
    "\n",
    "#Outbound_Vessels_Condition1\n",
    "vessel_specification = vessel_specifications({vessel_characteristics.max_lt_Draught: 14.3},\n",
    "                                              'x',vessel_direction.outbound.value)\n",
    "\n",
    "window_specification = window_specifications(window_method.point_based.value,\n",
    "                                             {tidal_period.Flood.value: 2*knots,tidal_period.Ebb.value: accessibility.accessible.value},\n",
    "                                             {tidal_period.Flood.value: 0,tidal_period.Ebb.value:0})\n",
    "\n",
    "horizontal_tidal_window_inputs.append(horizontal_tidal_window_input(vessel_specifications = vessel_specification,\n",
    "                                                                    window_specifications = window_specification,\n",
    "                                                                    condition = {'Origin': 'Node 13', 'Destination': 'Node 11'},\n",
    "                                                                    data = ['Node 14', current_velocity_type.CurrentVelocity.value]));\n",
    "\n",
    "#Outbound_Vessels_Condition2\n",
    "vessel_specification = vessel_specifications({vessel_characteristics.min_ge_Draught: 14.3},\n",
    "                                              'x',vessel_direction.outbound.value)\n",
    "\n",
    "window_specification = window_specifications(window_method.point_based.value,\n",
    "                                             {tidal_period.Flood.value: 0.5*knots,tidal_period.Ebb.value: accessibility.non_accessible.value},\n",
    "                                             {tidal_period.Flood.value: 0.3,tidal_period.Ebb.value:0})\n",
    "\n",
    "horizontal_tidal_window_inputs.append(horizontal_tidal_window_input(vessel_specifications = vessel_specification,\n",
    "                                                                    window_specifications = window_specification,\n",
    "                                                                    condition = {'Origin': 'Node 13', 'Destination': 'Node 11'},\n",
    "                                                                    data = ['Node 14', current_velocity_type.CurrentVelocity.value]));\n",
    "\n",
    "core.NetworkProperties.append_horizontal_tidal_restriction_to_network(FG,'Node 12',horizontal_tidal_window_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe0dcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_tidal_window_inputs = []\n",
    "\n",
    "#Inbound_Vessels_Condition1\n",
    "vessel_specification = vessel_specifications({vessel_characteristics.min_ge_Length: 180,\n",
    "                                              vessel_characteristics.min_ge_Draught: 11.4,\n",
    "                                              vessel_characteristics.max_lt_Draught: 14.3},\n",
    "                                              '(x and x and x)',vessel_direction.inbound.value)\n",
    "\n",
    "window_specification = window_specifications(window_method.critical_cross_current.value,\n",
    "                                             {tidal_period.Flood.value: 2*knots,tidal_period.Ebb.value: 1*knots})\n",
    "\n",
    "horizontal_tidal_window_inputs.append(horizontal_tidal_window_input(vessel_specifications = vessel_specification,\n",
    "                                                                    window_specifications = window_specification,\n",
    "                                                                    condition = {'Origin': 'Node 14', 'Destination': 'Node 17'},\n",
    "                                                                    data = ['Node 14', current_velocity_type.CurrentVelocity.value]));\n",
    "\n",
    "#Inbound_Vessels_Condition2\n",
    "vessel_specification = vessel_specifications({vessel_characteristics.min_ge_Draught: 14.3},\n",
    "                                              'x',vessel_direction.inbound.value)\n",
    "\n",
    "window_specification = window_specifications(window_method.point_based.value,\n",
    "                                             {tidal_period.Flood.value: 0.5*knots,tidal_period.Ebb.value: accessibility.accessible.value},\n",
    "                                             {tidal_period.Flood.value: 0.3,tidal_period.Ebb.value:0})\n",
    "\n",
    "horizontal_tidal_window_inputs.append(horizontal_tidal_window_input(vessel_specifications = vessel_specification,\n",
    "                                                                    window_specifications = window_specification,\n",
    "                                                                    condition = {'Origin': 'Node 14', 'Destination': 'Node 17'},\n",
    "                                                                    data = ['Node 14', current_velocity_type.CurrentVelocity.value]));\n",
    "\n",
    "#Outbound_Vessels_Condition1\n",
    "vessel_specification = vessel_specifications({vessel_characteristics.max_lt_Draught: 14.3},\n",
    "                                              'x',vessel_direction.outbound.value)\n",
    "\n",
    "window_specification = window_specifications(window_method.point_based.value,\n",
    "                                             {tidal_period.Flood.value: 2*knots,tidal_period.Ebb.value: accessibility.accessible.value},\n",
    "                                             {tidal_period.Flood.value: 0,tidal_period.Ebb.value:0})\n",
    "\n",
    "horizontal_tidal_window_inputs.append(horizontal_tidal_window_input(vessel_specifications = vessel_specification,\n",
    "                                                                    window_specifications = window_specification,\n",
    "                                                                    condition = {'Origin': 'Node 17', 'Destination': 'Node 14'},\n",
    "                                                                    data = ['Node 14', current_velocity_type.CurrentVelocity.value]));\n",
    "\n",
    "#Outbound_Vessels_Condition2\n",
    "vessel_specification = vessel_specifications({vessel_characteristics.min_ge_Draught: 14.3},\n",
    "                                              'x',vessel_direction.outbound.value)\n",
    "\n",
    "window_specification = window_specifications(window_method.point_based.value,\n",
    "                                             {tidal_period.Flood.value: 0.5*knots,tidal_period.Ebb.value: accessibility.non_accessible.value},\n",
    "                                             {tidal_period.Flood.value: 0.3,tidal_period.Ebb.value:0})\n",
    "\n",
    "horizontal_tidal_window_inputs.append(horizontal_tidal_window_input(vessel_specifications = vessel_specification,\n",
    "                                                                    window_specifications = window_specification,\n",
    "                                                                    condition = {'Origin': 'Node 17', 'Destination': 'Node 14'},\n",
    "                                                                    data = ['Node 14', current_velocity_type.CurrentVelocity.value]));\n",
    "\n",
    "core.NetworkProperties.append_horizontal_tidal_restriction_to_network(FG,'Node 15',horizontal_tidal_window_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d3552c",
   "metadata": {},
   "source": [
    "Choice about the bathymetry\n",
    "\n",
    "make all 16.4m until destination point, even if it is the MBL shown in the Haven Kaart\n",
    "Realistic MBL would be 16.4 at Node 15\n",
    "Then, 15.9 from Node 16 to 19 --> inside the basins\n",
    "\n",
    "Since the UKC policy is different in the NWW than inside the basins, it results in that the required water depth inside the basin is lower than in the NWW. UKC=0.5m for any vessel inside the basisn VS UKC=10%D for the NWW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7450e4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#water_level[1][col[0]][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf283d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(df_wlevel[df_wlevel.columns[0]])\n",
    "#print(df_wlevel[df_wlevel.columns[0]][:])\n",
    "#print(water_level[1][col[0]][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf55261",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "edge_count = []\n",
    "for edge in enumerate(FG.edges):\n",
    "    edge_count.append(FG.edges[edge[1]]['Info']['Depth'])\n",
    "\n",
    "colormap = cm.get_cmap('Blues', 256)\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.axis('off')\n",
    "ax = fig.add_axes([0, 0.4, 1, 0.3]);\n",
    "nx.draw(FG, positions, node_size = 5, node_color ='k', with_labels = False, horizontalalignment = 'right', verticalalignment = 'bottom', edge_color = edge_count, edge_cmap = colormap, edge_vmin = 0, arrows = False, width= 4)\n",
    "plt.axis('equal')\n",
    "cbar = fig.colorbar(cm.ScalarMappable(cmap=colormap), ax=ax, ticks=[0, 1])\n",
    "cbar.ax.set_yticklabels(['shallow','deep'])  # vertically oriented colorbar\n",
    "plt.title('Bathymetry of Port X',fontsize = 14, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49d2329",
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge in FG.edges:\n",
    "    print(edge,FG.edges[edge]['Info']['Tidal phase lag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25f7cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "core.Output.general_output(sim)\n",
    "core.Output.node_dependent_output(env.FG)\n",
    "core.Output.edge_dependent_output(env.FG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f8c941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(core)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f301862",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t0 = timepy.time()\n",
    "sim.run(duration = duration) # this statement runs the simulation\n",
    "t1 = timepy.time()\n",
    "total = t1-t0\n",
    "print(total) #simulation time in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9e5e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readjust_available_quay_lengths(aql,position):\n",
    "    for i in range(len(aql)):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        if aql[i - 1][1] < position and aql[i][1] > position:\n",
    "            break\n",
    "\n",
    "    if i == 1:\n",
    "        aql[i - 1][0] = 0\n",
    "        aql[i][0] = 0\n",
    "\n",
    "    elif i == len(aql) - 1:\n",
    "        aql[i - 1][0] = 0\n",
    "        aql[i][0] = 0\n",
    "\n",
    "    else:\n",
    "        aql[i - 1][0] = 0\n",
    "        aql[i][0] = 0\n",
    "\n",
    "    to_remove = []\n",
    "    for i in enumerate(aql):\n",
    "        for j in enumerate(aql):\n",
    "            if i[0] != j[0] and i[1][0] == 0 and j[1][0] == 0 and i[1][1] == j[1][1]:\n",
    "                to_remove.append(i[0])\n",
    "\n",
    "    for i in list(reversed(to_remove)):\n",
    "        aql.pop(i)\n",
    "\n",
    "    return aql\n",
    "\n",
    "def pick_minimum_length(aql,L):\n",
    "    available_quay_lengths = [0]\n",
    "    index_quay_position = 0\n",
    "    move_to_anchorage = False\n",
    "    for index in range(len(aql)):\n",
    "        if index == 0 or aql[index][1] == aql[index - 1][1] or aql[index][0] == 1:\n",
    "            if index == len(aql) - 1 and not index_quay_position:\n",
    "                move_to_anchorage = True\n",
    "            continue\n",
    "\n",
    "        available_quay_lengths.append(aql[index][1] - aql[index - 1][1])\n",
    "\n",
    "        for jndex in range(len(available_quay_lengths)):\n",
    "            if L <= available_quay_lengths[jndex]:\n",
    "                index_quay_position = index\n",
    "                print(index_quay_position)\n",
    "                break\n",
    "\n",
    "            elif jndex == len(available_quay_lengths) - 1 and not index_quay_position:\n",
    "                move_to_anchorage = True\n",
    "        \n",
    "        if index_quay_position != 0:\n",
    "            break\n",
    "\n",
    "    return index_quay_position, move_to_anchorage\n",
    "\n",
    "def adjust_available_quay_lengths(aql, L, index_quay_position):\n",
    "    if aql[index_quay_position - 1][0] == 0:\n",
    "        aql[index_quay_position - 1][0] = 1\n",
    "\n",
    "    if aql[index_quay_position][0] == 0 and aql[index_quay_position][1] == aql[index_quay_position - 1][1] + L:\n",
    "        aql[index_quay_position][0] = 1\n",
    "    else:\n",
    "        aql.insert(index_quay_position, [1, L + aql[index_quay_position - 1][1]])\n",
    "        aql.insert(index_quay_position + 1, [0, L + aql[index_quay_position - 1][1]])\n",
    "        \n",
    "    print(0.5 * L + aql[index_quay_position - 1][1])\n",
    "    return aql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d86d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vessels = sim.environment.vessels #extract vessels (entitie) from environment. It collects info while it moves through the network. That info is stored in the log file. The log file has \n",
    "env = sim.environment #extract the environment itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37aee9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', 500)\n",
    "vessel = vessels[1]\n",
    "print(vessel.type)\n",
    "df = pd.DataFrame.from_dict(vessel.log) #creates a data frame with all the info of vessels[0].\n",
    "df[20:80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b13442",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Timestamp'][51].timestamp()-df['Timestamp'][50].timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d6b3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(orig, dest):\n",
    "    wgs84 = pyproj.Geod(ellps='WGS84')\n",
    "    \n",
    "    distance = wgs84.inv(orig[0], orig[1], \n",
    "                         dest[0], dest[1])[2]\n",
    "    \n",
    "    return distance\n",
    "\n",
    "vessel_path_x = []\n",
    "vessel_path_t = []\n",
    "\n",
    "list_of_nodes = list(vessels[0].env.FG.nodes)\n",
    "\n",
    "for node in list_of_nodes:\n",
    "    if 'Origin' in vessels[0].env.FG.nodes[node].keys():\n",
    "        origin = node\n",
    "        \n",
    "    if 'Anchorage' in vessels[0].env.FG.nodes[node].keys():\n",
    "        list_of_nodes.remove(node)\n",
    "\n",
    "    if 'Junction' in vessels[0].env.FG.nodes[node].keys() and vessels[0].env.FG.nodes[node]['Junction'][0].name == ['waterway_access', 'waterway_access', 'anchorage_access', 'anchorage_access']:\n",
    "        virtual_anchorage = node\n",
    "\n",
    "for v in range(len(vessels)):\n",
    "    vessel_path_xt = []\n",
    "    vessel_path_tt = []\n",
    "    distance = 0\n",
    "    direction = 0\n",
    "    vessel_path_t0 = simulation_start.timestamp()\n",
    "    vessel_path_xt.append(distance)\n",
    "    vessel_path_tt.append(vessels[v].log[\"Timestamp\"][0].timestamp()-vessel_path_t0)\n",
    "    for t in range(1,len(vessels[v].log[\"Message\"])):  \n",
    "        if ('Deberthing stop' in vessels[v].log[\"Message\"][t] or ('Waiting in anchorage stop' in vessels[v].log[\"Message\"][t] and\n",
    "            vessels[v].log[\"Message\"][-1] == 'Sailing from node Node 2 to node Node 1 stop' and len(vessels[v].log[\"Message\"]) < 20)):\n",
    "            direction = 1\n",
    "        for node1 in list_of_nodes: \n",
    "            for node2 in list_of_nodes:\n",
    "                if (vessels[v].log[\"Message\"][t] == 'Sailing from node ' + node1 + ' to node ' + node2 + ' start' or \n",
    "                    vessels[v].log[\"Message\"][t] == 'Sailing from node ' + node1 + ' to node ' + node2 + ' stop'):\n",
    "                    if node2 == virtual_anchorage:\n",
    "                        distance_to_anchorage = calculate_distance((vessels[v].env.FG.nodes[origin]['geometry'].x,vessels[v].env.FG.nodes[origin]['geometry'].y),(vessels[v].env.FG.nodes[node2]['geometry'].x,vessels[v].env.FG.nodes[node2]['geometry'].y))\n",
    "                    if direction == 0:\n",
    "                        distance += calculate_distance((vessels[v].log[\"Geometry\"][t-1].x,vessels[v].log['Geometry'][t-1].y),(vessels[v].log[\"Geometry\"][t].x,vessels[v].log['Geometry'][t].y))\n",
    "                    elif direction == 1:\n",
    "                        distance -= calculate_distance((vessels[v].log[\"Geometry\"][t-1].x,vessels[v].log['Geometry'][t-1].y),(vessels[v].log[\"Geometry\"][t].x,vessels[v].log['Geometry'][t].y))\n",
    "                    vessel_path_xt.append(distance)\n",
    "                    vessel_path_tt.append(vessels[v].log[\"Timestamp\"][t].timestamp()-vessel_path_t0)\n",
    "                    break\n",
    "                    \n",
    "    vessel_path_x.append(vessel_path_xt)\n",
    "    vessel_path_t.append(vessel_path_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab5da1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tidal_window_start_stop_xloc(time,signal,correction,roots,start,end):\n",
    "    if roots != []:\n",
    "        for root_start in enumerate(roots):\n",
    "            if root_start[1] >= start:\n",
    "                break\n",
    "        for root_end in enumerate(roots):\n",
    "            if root_end[1] >= end:\n",
    "                break\n",
    "\n",
    "        def find_nearest(array, value):\n",
    "            array = np.asarray(array)\n",
    "            idx = (np.abs(array - value)).argmin()\n",
    "            return idx,array[idx]\n",
    "\n",
    "        idx,x = find_nearest(time,root_start[1])\n",
    "        ylim = correction\n",
    "\n",
    "        booleanlist = []\n",
    "        rootlist = []\n",
    "        rootlist.append(start)\n",
    "\n",
    "        if root_start != root_end:\n",
    "            if x >= root_start[1]:\n",
    "                if signal[idx] > ylim:\n",
    "                    booleanlist.append(0)\n",
    "                    booleanlist.append(1)\n",
    "                    rootlist.append(root_start[1])\n",
    "                else:\n",
    "                    booleanlist.append(1)\n",
    "                    booleanlist.append(0)\n",
    "                    rootlist.append(root_start[1])\n",
    "            else:\n",
    "                if signal[idx] > ylim:\n",
    "                    booleanlist.append(1)\n",
    "                    booleanlist.append(0)\n",
    "                    rootlist.append(root_start[1])\n",
    "                else:\n",
    "                    booleanlist.append(0)\n",
    "                    booleanlist.append(1)\n",
    "                    rootlist.append(root_start[1])\n",
    "\n",
    "            if booleanlist[0] == 0:\n",
    "                boolean = 1\n",
    "            else:\n",
    "                boolean = 0\n",
    "\n",
    "            for root in roots[(root_start[0]+1):root_end[0]]:\n",
    "                if boolean == 0:\n",
    "                    boolean = 1\n",
    "                elif boolean == 1:\n",
    "                    boolean = 0\n",
    "                booleanlist.append(boolean)\n",
    "                rootlist.append(root)\n",
    "        else:\n",
    "            boolean = 1\n",
    "            booleanlist.append(boolean)\n",
    "\n",
    "        rootlist.append(end)\n",
    "        if boolean == 0:\n",
    "            booleanlist.append(1)\n",
    "        elif boolean == 1:\n",
    "            booleanlist.append(0) \n",
    "    return booleanlist,rootlist\n",
    "\n",
    "def tidal_window_start_stop_polygon(booleanlist,rootlist,figylimits):\n",
    "    xfill_lists = []\n",
    "    yfill_lists = []\n",
    "    for i in range(len(booleanlist)):\n",
    "        xfill_list = []\n",
    "        yfill_list = []\n",
    "        if booleanlist[i] == 0 and i != len(booleanlist)-1:\n",
    "            xfill_list = [rootlist[i],rootlist[i],rootlist[i+1],rootlist[i+1]]\n",
    "            yfill_list = [figylimits[0],figylimits[1],figylimits[1],figylimits[0]]\n",
    "            xfill_lists.append(xfill_list)\n",
    "            yfill_lists.append(yfill_list)\n",
    "        elif i != len(booleanlist)-1:\n",
    "            xfill_list = [rootlist[i],rootlist[i],rootlist[i+1],rootlist[i+1]]\n",
    "            yfill_list = [figylimits[0],figylimits[1],figylimits[1],figylimits[0]]\n",
    "            xfill_lists.append(xfill_list)\n",
    "            yfill_lists.append(yfill_list)\n",
    "    return xfill_lists,yfill_lists\n",
    "\n",
    "def colors_tidal_window_polygons(xfill_lists,yfill_lists,booleanlist):\n",
    "    color = []\n",
    "    for i in range(len(xfill_lists)):\n",
    "        if booleanlist[i] == 0:\n",
    "            color.append('red')\n",
    "        elif booleanlist[i] == 2:\n",
    "            color.append('darkred')\n",
    "        else:\n",
    "            color.append('g')\n",
    "    return color        \n",
    "        \n",
    "def times_tidal_window(vertical_tidal_window_bools,vertical_tidal_window_roots,horizontal_tidal_window_bools,horizontal_tidal_window_roots): \n",
    "    list_of_times_vertical_tidal_window = []\n",
    "    list_of_times_horizontal_tidal_windows = []\n",
    "\n",
    "    for time in range(len(vertical_tidal_window_roots)):\n",
    "        list_of_times_vertical_tidal_window.append([vertical_tidal_window_roots[time],vertical_tidal_window_bools[time]])\n",
    "    for time in range(len(horizontal_tidal_window_roots)):\n",
    "        list_of_times_horizontal_tidal_windows.append([horizontal_tidal_window_roots[time],horizontal_tidal_window_bools[time]])\n",
    "\n",
    "    list_indexes = list(np.arange(0, len(list_of_times_horizontal_tidal_windows) + 1))\n",
    "    times_tidal_window = []\n",
    "    list_of_list_indexes = []\n",
    "\n",
    "    for time in list_of_times_vertical_tidal_window:\n",
    "        times_tidal_window.append(time)\n",
    "        list_of_list_indexes.append(0)\n",
    "    for time in list_of_times_horizontal_tidal_windows:\n",
    "        times_tidal_window.append(time)\n",
    "        list_of_list_indexes.append(1)\n",
    "\n",
    "    list_of_list_indexes = [x for _, x in sorted(zip(times_tidal_window, list_of_list_indexes))]\n",
    "    times_tidal_window.sort()\n",
    "    \n",
    "    indexes_to_be_removed = []\n",
    "    for list_index in list_indexes:\n",
    "        for time1 in range(len(times_tidal_window)):\n",
    "            if times_tidal_window[time1][1] == 0 and list_of_list_indexes[time1] == list_index:\n",
    "                for time2 in range(len(times_tidal_window)):\n",
    "                    if time2 > time1 and times_tidal_window[time2][1] == 1 and list_of_list_indexes[time2] == list_index:\n",
    "                        indexes = np.arange(time1 + 1, time2, 1)\n",
    "                        for index in indexes:\n",
    "                            indexes_to_be_removed.append(index)\n",
    "                        break\n",
    "\n",
    "    for time in range(len(times_tidal_window)):\n",
    "        if time == 0:\n",
    "            continue\n",
    "        elif times_tidal_window[time][1] == 1 and times_tidal_window[time - 1][1] == 1:\n",
    "            indexes_to_be_removed.append(time - 1)\n",
    "        elif times_tidal_window[time][1] == 0 and times_tidal_window[time - 1][1] == 0:\n",
    "            indexes_to_be_removed.append(time)\n",
    "\n",
    "    indexes_to_be_removed.sort()\n",
    "    indexes_to_be_removed = list(dict.fromkeys(indexes_to_be_removed))\n",
    "      \n",
    "    times_tidal_window_bools = []\n",
    "    times_tidal_window_roots = []\n",
    "    for time in times_tidal_window:\n",
    "        times_tidal_window_bools.append(time[1])\n",
    "        times_tidal_window_roots.append(time[0])\n",
    "    \n",
    "    return times_tidal_window_bools,times_tidal_window_roots,indexes_to_be_removed\n",
    "\n",
    "def cross_current_calculation(magnitude,direction,origin,location,destination):\n",
    "    origin_lat1 = FG.nodes[origin]['geometry'].x\n",
    "    origin_lon1 = FG.nodes[origin]['geometry'].y\n",
    "    destination_lat1 = FG.nodes[location]['geometry'].x\n",
    "    destination_lon1 = FG.nodes[location]['geometry'].y\n",
    "    fwd_azimuth1, _, _ = pyproj.Geod(ellps=\"WGS84\").inv(origin_lat1, origin_lon1,destination_lat1, destination_lon1)\n",
    "    origin_lat2 = FG.nodes[location]['geometry'].x\n",
    "    origin_lon2 = FG.nodes[location]['geometry'].y\n",
    "    destination_lat2 = FG.nodes[destination]['geometry'].x\n",
    "    destination_lon2 = FG.nodes[destination]['geometry'].y\n",
    "    fwd_azimuth2, _, _ = pyproj.Geod(ellps=\"WGS84\").inv(origin_lat2, origin_lon2,destination_lat2, destination_lon2)\n",
    "    cross_current_signal_at_node = []\n",
    "    for t in range(len(magnitude)):\n",
    "        cross_current_signal_at_node.append(np.max([abs(magnitude[t]*np.sin((direction[t]-fwd_azimuth2)/180*np.pi)),\n",
    "                                                    abs(magnitude[t]*np.sin((direction[t]-fwd_azimuth1)/180*np.pi))]))\n",
    "    return cross_current_signal_at_node\n",
    "\n",
    "def color_vessels(vessel,\n",
    "                  min_linewidth = 0.5,\n",
    "                  max_linewidth = 3,\n",
    "                  vessel_database = vdf,\n",
    "                  vessel_norm=mpl.colors.BoundaryNorm(boundaries=list(vdf['T_f']),\n",
    "                                                      ncolors=len(list(vdf['T_f'])), \n",
    "                                                      extend='max'),\n",
    "                  vessel_cmap = mpl.colorbar.cm.tab10):\n",
    "    if str(type(vessel)) == \"<class '__main__.Vessel'>\":\n",
    "        linewidth = vessel.T_f/(list(vdf['T_f'])[-1]-list(vdf['T_e'])[0])*max_linewidth+min_linewidth\n",
    "        for c in enumerate(vessel_cmap.colors[0:len(list(vdf['type']))]):\n",
    "            if vessel.T_f >= vessel_norm.boundaries[c[0]]:\n",
    "                color = c[1]\n",
    "            else:\n",
    "                break\n",
    "    else:\n",
    "        color = []\n",
    "        linewidth = []\n",
    "        for draught in vessel:\n",
    "            linewidth.append(draught/(list(vdf['T_f'])[-1]-list(vdf['T_e'])[0])*max_linewidth+min_linewidth)\n",
    "        for c in enumerate(vessel_cmap.colors[0:len(list(vdf['type']))]):\n",
    "            color.append(c[1])\n",
    "        \n",
    "    return color,linewidth\n",
    "\n",
    "def vessel_legend(axis,\n",
    "                  vessel_types=list(vdf['type']),\n",
    "                  vessel_draught=list(vdf['T_f']),\n",
    "                  min_linewidth = 0.5,\n",
    "                  max_linewidth = 3,\n",
    "                  vessel_database = vdf,\n",
    "                  vessel_norm=mpl.colors.BoundaryNorm(boundaries=list(vdf['T_f']),\n",
    "                                                      ncolors=len(list(vdf['T_f'])), \n",
    "                                                      extend='max'),\n",
    "                  vessel_cmap = mpl.colorbar.cm.tab10):\n",
    "    colors,linestyles = color_vessels(vessel_draught)\n",
    "    for vtype in enumerate(vessel_types):\n",
    "        axis.plot([0,0],[0,0],\n",
    "                  color=colors[vtype[0]],\n",
    "                  label=str(vtype[1]))\n",
    "    leg= axis.legend(loc='lower right',handlelength=8,ncol=2,bbox_to_anchor=(0.95, -0.25),frameon=False)\n",
    "    for line in leg.get_lines():\n",
    "        line.set_linewidth((max_linewidth-min_linewidth)*0.5+min_linewidth)\n",
    "        \n",
    "    plt.plot([0,0],[0,0],\n",
    "                  color='k',\n",
    "                  linewidth = list(vdf['T_e'])[0]/(list(vdf['T_f'])[-1]-list(vdf['T_e'])[0])*max_linewidth+min_linewidth,\n",
    "                  label=str(round(list(vdf['T_e'])[0],2)) +' m')\n",
    "    for vtype in enumerate(vessel_types):\n",
    "        plt.plot([0,0],[0,0],\n",
    "                  color='k',\n",
    "                  linewidth = vessel_draught[vtype[0]]/(list(vdf['T_f'])[-1]-list(vdf['T_e'])[0])*max_linewidth+min_linewidth,\n",
    "                  label=str(round(vessel_draught[vtype[0]],2)) +' m')\n",
    "    plt.legend(loc='lower right',handlelength=9,ncol=3,bbox_to_anchor=(1.35, -0.215),frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e225d8",
   "metadata": {},
   "source": [
    "# Vertical and Horizontal windows\n",
    "The model does the following:\n",
    "1) check the cross current for edges node14-node15-node16 and check the available water depth at VERY node\n",
    "2) calculates the roots (intersection to each part where required value and signal crossess)\n",
    "3) defines tidal windows and non-sailing parts --> discovers where is time available considering the overlapping of cross current and water depth requirement\n",
    "4) vessel sail if: there is room at the terminal + horizontal/vertical tidal window\n",
    "\n",
    "\n",
    "## ABOUT THE TWO PLOTS ON THE RIGHT - water levels and currents\n",
    "The green/red areas will show the tidal windows for the node that you select. For instance: \n",
    "\n",
    "    - water_level[1][7][1]]   \n",
    "  \n",
    "    - current_velocity[1][9][1],current_direction[1][9][1]\n",
    "Will show the an hypothetic vertical tidal window defined with water levels at 'node 8', and horizontal tidal window defined at 'node 10' (python starts at zero so python is always one lower).\n",
    "\n",
    "The max cross current can be modified at the input table, and it can be defined separately for each ship.\n",
    "\n",
    "The vertical tidal window can be modified with two parameters:\n",
    "- At the input table by defining the ukc + loaded draught --> required_water_level = vessels[0].metadata['ukc'] + vessels[0].T_f\n",
    "- By modifying the reference value for the water level signal (eta) with this line: ax3xlist = [eta+{h0} for eta in water_level[1][1][1]] --> the value {h0} value is the mean available water depth, which is defined from the mean water level --> as the mean water level is =0.00 m NAP, then h0 can be calculated from the MBL value by: h0=0.00-MBL --> if MBL=-16.4m NAP then h0=16.4m\n",
    "\n",
    "This means the vertical tidal window should be defined at the critical part of the NWW which is presente between node 15 and node 19 with a MBL=-15.9m NAP --> then h0=15.9m\n",
    "\n",
    "The horizontal tidal window is also shown at node 15, right at the point where the ship starts turns towards the access to 3ePH/Botlek area.\n",
    "\n",
    "Example:\n",
    "For an Aframax, required water depth is D+FWA+UKC=16.7m --> available water depth for h0+eta=15.9+0.8m meaning for high tide\n",
    "\n",
    "\n",
    "## IMPORTANT:\n",
    "The two plots on the left will never change no matter what you change in the next cell, as these visualize what the model calculates. The code calculation is done following the four steps explained before --> the ship check all nodes against required depth requirement, and checks edges 14-15-16 against the max cross current. The available water depth in each node is computed with the depth at each node and the water level at each node. If there is sufficient water depth, sufficiently low cross current, and a palce at the terminal, then it will sail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b2ac81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "terminal = vessels[0].env.FG.edges['Node 18','Node 19']['Terminal'][0]\n",
    "if terminal.type == 'quay':\n",
    "    max_available_quay_length = terminal.length.capacity\n",
    "if terminal.type == 'jetty':\n",
    "    max_available_quay_length = 5\n",
    "\n",
    "vesseltje = vessels[0]\n",
    "start = 0\n",
    "end =  10*12.5*60*60\n",
    "end_cor = 5*12.5*60*60\n",
    "ax3xlist = [eta+depth[1][16] for eta in water_level[1][16][1]] #let's define it at node 15 to visualize when we have the critical bed level of MBL=-16.4m NAP\n",
    "ax3ylist = [t-simulation_start.timestamp() for t in water_level[1][16][0]] \n",
    "ax4xlist = cross_current_calculation(current_velocity[1][14][1],current_direction[1][14][1],'Node 14','Node 15','Node 16') # let's show the cross-current at the node 15 when the ship turns towards the access to 3ePH/Botlek area. This point is subsequent to Node 14: Scheurkade\n",
    "ax4ylist = [t-simulation_start.timestamp() for t in current_velocity[1][14][0]]\n",
    "required_water_level = vesseltje.metadata['ukc'] + vesseltje.T_f\n",
    "root_interp_water_level_at_edge = sc.interpolate.CubicSpline(ax3ylist,[x-required_water_level for x in ax3xlist])\n",
    "root_interp_cross_current_at_edge = sc.interpolate.CubicSpline(ax4ylist,[abs(x)-vessels[0].metadata['max_cross_current'] for x in ax4xlist])\n",
    "if root_interp_water_level_at_edge.roots() != []:\n",
    "    stst_vtw,roots_vtw = tidal_window_start_stop_xloc(ax3ylist,ax3xlist,required_water_level,root_interp_water_level_at_edge.roots(),start,end)\n",
    "else:\n",
    "    stst_vtw,roots_vtw = [],[]\n",
    "if root_interp_cross_current_at_edge.roots() != []:\n",
    "    stst_htw,roots_htw = tidal_window_start_stop_xloc(ax4ylist,ax4xlist,-vessels[0].metadata['max_cross_current'],root_interp_cross_current_at_edge.roots(),start,end)\n",
    "else:\n",
    "    stst_htw,roots_htw = [],[]\n",
    "    \n",
    "stst_tw,roots_tw,indexes_to_be_removed = times_tidal_window(stst_vtw,roots_vtw,stst_htw,roots_htw)\n",
    "if len(roots_vtw) >= 2 and len(roots_htw) >= 2:\n",
    "    for i in indexes_to_be_removed:\n",
    "        if stst_tw[i] == 0:\n",
    "            stst_tw[i] = 2   \n",
    "        elif stst_tw[i] == 1:\n",
    "            stst_tw[i] = 0\n",
    "    \n",
    "if terminal.type == 'quay':\n",
    "    time_available_quay_length = []\n",
    "    available_quay_length = []\n",
    "    quay_level = 0\n",
    "    time_available_quay_length.append(0)\n",
    "    available_quay_length.append(quay_level)\n",
    "    for t in range(len(terminal.log[\"Message\"])):\n",
    "        time_available_quay_length.append(terminal.log[\"Timestamp\"][t].timestamp()-simulation_start.timestamp())\n",
    "        available_quay_length.append(quay_level)\n",
    "        time_available_quay_length.append(terminal.log[\"Timestamp\"][t].timestamp()-simulation_start.timestamp())\n",
    "        available_quay_length.append(terminal.log[\"Value\"][t])\n",
    "        quay_level = terminal.log[\"Value\"][t]\n",
    "        \n",
    "if terminal.type == 'jetty':\n",
    "    time_available_quay_length = []\n",
    "    available_quay_length = []\n",
    "    quay_level = 0\n",
    "    time_available_quay_length.append(0)\n",
    "    available_quay_length.append(quay_level)\n",
    "    for t in range(len(terminal.log[\"Message\"])):\n",
    "        time_available_quay_length.append(terminal.log[\"Timestamp\"][t].timestamp()-simulation_start.timestamp())\n",
    "        available_quay_length.append(quay_level)\n",
    "        time_available_quay_length.append(terminal.log[\"Timestamp\"][t].timestamp()-simulation_start.timestamp())\n",
    "        available_quay_length.append(terminal.log[\"Value\"][t])\n",
    "        quay_level = terminal.log[\"Value\"][t]\n",
    "    \n",
    "anchorage = vessels[0].env.FG.nodes['Node 20']['Anchorage'][0]\n",
    "time_anchorage_occupation = []\n",
    "anchorage_occupation = []\n",
    "anchorage_capacity = 0\n",
    "time_anchorage_occupation.append(0)\n",
    "anchorage_occupation.append(anchorage_capacity)\n",
    "for t in range(len(anchorage.log[\"Message\"])):\n",
    "    time_anchorage_occupation.append(anchorage.log[\"Timestamp\"][t].timestamp()-simulation_start.timestamp())\n",
    "    anchorage_occupation.append(anchorage_capacity)\n",
    "    time_anchorage_occupation.append(anchorage.log[\"Timestamp\"][t].timestamp()-simulation_start.timestamp())\n",
    "    anchorage_occupation.append(anchorage.log[\"Value\"][t])\n",
    "    anchorage_capacity = anchorage.log[\"Value\"][t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8445f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vessel_types = []\n",
    "for v in range(0,len(vessels)-24): # this part filters the first vessels generated with the minus sign --> use for warming-up time\n",
    "    if len(vessels[v].log['Message']) > 15: #this part filters out all vessels with a timestamp lower than X (in the line '> X') rows, meaning all vessels that do not enter the port\n",
    "        vessel_types.append(vessels[v].type)\n",
    "vessel_types\n",
    "dataframe = pd.DataFrame(vessel_types) \n",
    "dataframe.to_csv('Sim_ref_T1.1.csv',index=False) #export all vessels of the simulation, which can be usede to compute the throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd6c3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#water_level[1][14][1] #it is in fact ''node 15''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fac15e",
   "metadata": {},
   "source": [
    "## Traffic intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cc16b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_count = np.zeros(len(FG.edges))\n",
    "for v in vessels:\n",
    "    df = pd.DataFrame.from_dict(v.log)\n",
    "    for message in df['Message']:\n",
    "        if 'Sailing' in message and 'stop' in message:\n",
    "            r = re.search('Sailing from node (.+?) to node (.+?) stop', message)\n",
    "            if r:\n",
    "                node1 = r.group(1)\n",
    "                node2 = r.group(2)\n",
    "            for e in enumerate(FG.edges):\n",
    "                if (node1,node2) == e[1]:\n",
    "                    edge_count[e[0]] += 1\n",
    "\n",
    "edge_count_final = np.zeros(len(FG.edges))\n",
    "for e in enumerate(FG.edges):\n",
    "    for e2 in enumerate(FG.edges):\n",
    "        if [e[1][0],e[1][1]] == [e2[1][1],e2[1][0]]:\n",
    "            edge_count_final[e[0]] = edge_count[e[0]]+edge_count[e2[0]]\n",
    "            edge_count_final[e2[0]] = edge_count_final[e[0]] \n",
    "            break\n",
    "\n",
    "colormap = cm.get_cmap('RdYlBu_r', 256)\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "ax.axis('off')\n",
    "ax = fig.add_axes([0, 0.4, 1, 0.3]);\n",
    "nx.draw(FG, positions, node_size = 10, node_color ='k', with_labels = True, horizontalalignment = 'right', verticalalignment = 'bottom', edge_color = edge_count_final, edge_cmap = colormap, arrows = False, width= 4)\n",
    "plt.axis('equal')\n",
    "cbar = fig.colorbar(cm.ScalarMappable(cmap=colormap), ax=ax, ticks=[0, 1])\n",
    "cbar.ax.set_yticklabels(['low','high'])  # vertically oriented colorbar\n",
    "plt.title('Traffic Intensity of Port X',fontsize = 14, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd81583c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Occupancy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5801ad36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_occupancy(infrastructure,duration):\n",
    "    time_infrastructure_occupation = []\n",
    "    infrastructure_occupation = []\n",
    "    infrastructure_capacity = 0\n",
    "    time_infrastructure_occupation.append(0)\n",
    "    t = False\n",
    "    infrastructure_occupation.append(infrastructure_capacity)\n",
    "    for t in range(len(infrastructure.log[\"Message\"])):\n",
    "        time_infrastructure_occupation.append(infrastructure.log[\"Timestamp\"][t].timestamp()-simulation_start.timestamp())\n",
    "        infrastructure_occupation.append(infrastructure_capacity)\n",
    "        time_infrastructure_occupation.append(infrastructure.log[\"Timestamp\"][t].timestamp()-simulation_start.timestamp())\n",
    "        infrastructure_occupation.append(infrastructure.log[\"Value\"][t])\n",
    "        infrastructure_capacity = infrastructure.log[\"Value\"][t]\n",
    "    \n",
    "    if t:\n",
    "        time_infrastructure_occupation.append(duration)\n",
    "        infrastructure_occupation.append(infrastructure.log[\"Value\"][t])\n",
    "    return time_infrastructure_occupation,infrastructure_occupation\n",
    "\n",
    "def occupancy_calculation(infrastructure,duration):\n",
    "    time_infrastructure_occupation = []\n",
    "    infrastructure_occupation = []\n",
    "    infrastructure_capacity = 0\n",
    "    t = 0\n",
    "    for t in range(len(infrastructure.log[\"Message\"])):\n",
    "        if t == 0:\n",
    "            time_infrastructure_occupation.append(infrastructure.log[\"Timestamp\"][t].timestamp()-simulation_start.timestamp())\n",
    "            infrastructure_occupation.append(infrastructure_capacity)\n",
    "        else:\n",
    "            time_infrastructure_occupation.append(infrastructure.log[\"Timestamp\"][t].timestamp()-infrastructure.log[\"Timestamp\"][t-1].timestamp())\n",
    "            infrastructure_occupation.append(infrastructure.log[\"Value\"][t-1])\n",
    "        infrastructure_capacity = infrastructure.log[\"Value\"][t]\n",
    "    if not t:\n",
    "        time_infrastructure_occupation.append(0)\n",
    "        infrastructure_occupation.append(infrastructure_capacity)\n",
    "        time_infrastructure_occupation.append(duration)\n",
    "        infrastructure_occupation.append(infrastructure_capacity)\n",
    "    return time_infrastructure_occupation,infrastructure_occupation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d023d34",
   "metadata": {},
   "source": [
    "## Terminal occupation output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73811feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(terminal.log)\n",
    "df\n",
    "\n",
    "terminal_edges = [['Node 18','Node 19']]\n",
    "fig,ax = plt.subplots(figsize=(16, 9))\n",
    "start = 0\n",
    "end = duration\n",
    "\n",
    "for edge in enumerate(terminal_edges):\n",
    "    terminal = vessels[0].env.FG.edges[edge[1]]['Terminal'][0]\n",
    "    plt.plot(plot_occupancy(terminal,duration)[0],plot_occupancy(terminal,duration)[1])\n",
    "    if edge[0] == 0:\n",
    "        ymax = np.max(occupancy_calculation(terminal,duration)[1])\n",
    "    elif np.max(occupancy_calculation(terminal,duration)[1]) > ymax:\n",
    "        ymax = np.max(occupancy_calculation(terminal,duration)[1])\n",
    "\n",
    "plt.xlabel('Time [s]')\n",
    "plt.xlim([start,end])\n",
    "plt.ylabel('Number of vessels')\n",
    "plt.ylim([0,math.ceil(1.1*ymax)])\n",
    "plt.title(\"Terminal occupation\", fontweight='bold', pad = 12)\n",
    "plt.legend(['Terminal 1'])\n",
    "plt.show()\n",
    "\n",
    "time_quay_occupation,quay_occupation = occupancy_calculation(terminal,duration)\n",
    "\n",
    "weighted_quay_occupancy = []\n",
    "for t in range(len(quay_occupation)):\n",
    "    weighted_quay_occupancy.append(quay_occupation[t]/max_available_quay_length*time_quay_occupation[t])\n",
    "      \n",
    "terminal_occupancy = np.sum(weighted_quay_occupancy)/duration\n",
    "print('terminal occupancy:',terminal_occupancy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ea6460",
   "metadata": {},
   "source": [
    "## Anchorage occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c720b58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# anchorage = vessels[0].env.FG.nodes['Node 20']['Anchorage'][0]\n",
    "df = pd.DataFrame.from_dict(anchorage.log)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe091bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchorage_nodes = ['Node 20','Node 21']\n",
    "fig,ax = plt.subplots(figsize=(16, 9))\n",
    "start = 0\n",
    "end = duration\n",
    "for node in enumerate(anchorage_nodes):\n",
    "    anchorage = vessels[0].env.FG.nodes[node[1]]['Anchorage'][0]\n",
    "    plt.plot(plot_occupancy(anchorage,duration)[0],plot_occupancy(anchorage,duration)[1])\n",
    "    if node[0] == 0:\n",
    "        ymax = np.max(occupancy_calculation(anchorage,duration)[1])\n",
    "    elif np.max(occupancy_calculation(anchorage,duration)[1]) > ymax:\n",
    "        ymax = np.max(occupancy_calculation(anchorage,duration)[1])\n",
    "    \n",
    "plt.xlabel('Time [s]')\n",
    "plt.xlim([start,end])\n",
    "plt.ylabel('Number of vessels')\n",
    "plt.ylim([0,math.ceil(1.1*ymax)])\n",
    "plt.title(\"Anchorage occupation\", fontweight='bold', pad = 12)\n",
    "plt.legend(['Anchorage 1','Anchorage 2'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926277b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchorage = vessels[0].env.FG.nodes['Node 20']['Anchorage'][0]\n",
    "time_anchorage_occupation,anchorage_occupation = occupancy_calculation(anchorage,duration)\n",
    "\n",
    "list_anchorage_occupancy = []\n",
    "for t in range(len(time_anchorage_occupation)):\n",
    "    list_anchorage_occupancy.append(anchorage_occupation[t]*(time_anchorage_occupation[t]))\n",
    "\n",
    "print('Anchorage occupancy:', np.sum(list_anchorage_occupancy)/(duration*anchorage.anchorage_area['Node 20'].capacity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31ac4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(anchorage.log)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3955658d",
   "metadata": {},
   "source": [
    "## Output parameters plots and time-averaged values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2d7679",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "turnaround_times = []\n",
    "waiting_times = []\n",
    "sailing_times = []\n",
    "service_times = []\n",
    "list_berth_productivity = []\n",
    "number_of_vessels_served = 0\n",
    "for v in range(len(vessels)):\n",
    "    v = v\n",
    "    start_node = []\n",
    "    end_node = []\n",
    "    waiting_time = 0\n",
    "    sailing_time = 0\n",
    "    berth_productivity = 1\n",
    "    was_at_berth = False\n",
    "    for t in range(len(vessels[v].log[\"Message\"])):\n",
    "        if t == 0:\n",
    "            turnaround_start = vessels[v].log[\"Timestamp\"][t].timestamp()\n",
    "            text = vessels[v].log[\"Message\"][t]\n",
    "            match = re.search('from node (.+?) to', text)\n",
    "            if match:\n",
    "                start_node = match.group(1)\n",
    "        if 'Waiting in anchorage stop' in vessels[v].log[\"Message\"][t]:\n",
    "            waiting_time = vessels[v].log['Value'][t]\n",
    "        if 'Sailing from node' in vessels[v].log[\"Message\"][t] and 'stop' in vessels[v].log[\"Message\"][t]:\n",
    "            sailing_time += vessels[v].log[\"Timestamp\"][t].timestamp()-vessels[v].log[\"Timestamp\"][t-1].timestamp()\n",
    "        if 'Loading stop' in vessels[v].log[\"Message\"][t]:\n",
    "            service_time = vessels[v].log[\"Timestamp\"][t].timestamp()-vessels[v].log[\"Timestamp\"][t-3].timestamp()\n",
    "            was_at_berth = True\n",
    "        if 'Deberthing start' in vessels[v].log[\"Message\"][t] and 'Waiting for tidal window stop' in vessels[v].log[\"Message\"][t-1]:\n",
    "            berth_productivity = service_time/(service_time+vessels[v].log[\"Value\"][t-1])\n",
    "        if t == len(vessels[v].log[\"Message\"])-1:\n",
    "            turnaround_end = vessels[v].log[\"Timestamp\"][t].timestamp()\n",
    "            text = vessels[v].log[\"Message\"][t]\n",
    "            match = re.search('to node (.+?) stop', text)\n",
    "            if match:\n",
    "                end_node = match.group(1)\n",
    "\n",
    "    if start_node == end_node and end_node != []:\n",
    "        turnaround_times.append(turnaround_end-turnaround_start)\n",
    "        waiting_times.append(waiting_time)\n",
    "        sailing_times.append(sailing_time)\n",
    "        if was_at_berth == True:\n",
    "            number_of_vessels_served += 1\n",
    "            service_times.append(service_time)\n",
    "        else:\n",
    "            pass\n",
    "        list_berth_productivity.append(berth_productivity)\n",
    "\n",
    "fig,(ax1,ax2,ax3,ax4) = plt.subplots(1,4,figsize=(16, 3))\n",
    "ax1.hist(turnaround_times, bins=range(0,300000,5000))\n",
    "ax1.set_title('Turnaround times \\n (Mean: '+ str(round(np.mean(turnaround_times),2)) + ' s)')\n",
    "ax1.set_xlabel('time [s]')\n",
    "\n",
    "ax2.hist(waiting_times, bins=range(0,90000,1000))\n",
    "ax2.set_title('Waiting times \\n (Mean: '+ str(round(np.mean(waiting_times),2)) + ' s)')\n",
    "ax2.set_xlabel('time [s]')\n",
    "\n",
    "ax3.hist(service_times, bins=range(50000,75000,250))\n",
    "ax3.set_title('Service times \\n (Mean: '+ str(round(np.mean(service_times),2)) + ' s)')\n",
    "ax3.set_xlabel('time [s]')\n",
    "\n",
    "ax4.hist(sailing_times, bins=range(40000,80000,100))\n",
    "ax4.set_title('Sailing times \\n (Mean: '+ str(round(np.mean(sailing_times),2)) + ' s)')\n",
    "ax4.set_xlabel('time [s]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62699bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average berth productivity:',np.mean(list_berth_productivity))\n",
    "\n",
    "counts, bins = np.histogram(waiting_times, bins=range(0,300000,5000))\n",
    "counts\n",
    "# counts, bins = np.histogram(turnaround_times, bins=range(0,300000,5000))\n",
    "# counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36b10e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The total number of vessels served is',number_of_vessels_served, 'in a time of', duration, 's.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd5101c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(waiting_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b27baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(turnaround_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16050ab1",
   "metadata": {},
   "source": [
    "## Vessel encounters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f8f162",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_encounters = 0\n",
    "for v1 in range(len(vessels)):\n",
    "    for v2 in range(len(vessels[(v1+1):])):\n",
    "        v2 = v2+(v1+1)\n",
    "        for t1 in range(len(vessels[v1].log[\"Message\"])):\n",
    "            if 'Sailing from node' in vessels[v1].log[\"Message\"][t1] and 'stop' in vessels[v1].log[\"Message\"][t1]:\n",
    "                text1 = vessels[v1].log[\"Message\"][t1]\n",
    "                match1 = re.search('from node (.+?) to', text1)\n",
    "                match2 = re.search('to node (.+?) stop', text1)\n",
    "                if match1 and match2:\n",
    "                    node1 = match1.group(1)\n",
    "                    node2 = match2.group(1)\n",
    "                    time_start1 = vessels[v1].log[\"Timestamp\"][t1-1].timestamp()\n",
    "                    time_stop1 = vessels[v1].log[\"Timestamp\"][t1].timestamp()\n",
    "                    for t2 in range(len(vessels[v2].log[\"Message\"])):\n",
    "                        if 'Sailing from node' in vessels[v2].log[\"Message\"][t2] and 'stop' in vessels[v2].log[\"Message\"][t2]:\n",
    "                            time_start2 = vessels[v2].log[\"Timestamp\"][t2-1].timestamp()\n",
    "                            time_stop2 = vessels[v2].log[\"Timestamp\"][t2].timestamp()\n",
    "                            text2 = vessels[v2].log[\"Message\"][t2]\n",
    "                            if (time_start2 <= time_stop1 and time_start2 >= time_start1) or (time_stop2 <= time_stop1 and time_stop2 >= time_start1):\n",
    "                                if node2 + ' to' in text2 and node1 + ' stop' in text2:\n",
    "                                    number_of_encounters += 1          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94965b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The total number of vessel encounters is',number_of_encounters, 'in a time of', duration, 's.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52ff4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225ea181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed2bearing(east_velocity, north_velocity, principal_direction):\n",
    "    \"\"\"\n",
    "    Function to calculate the velocity components in a reference frame parallel to the principal direction of the\n",
    "    velocity cluster.\n",
    "    :param east_velocity: velocity in Eastern direction (float)\n",
    "    :param north_velocity: velocity in Northern direction (float)\n",
    "    :param principal_direction: principal direction in degrees in fixed reference frame North-East (float)\n",
    "    :return: coordinates in a reference frame relative to the given principal direction (tup)\n",
    "    \"\"\"\n",
    "    bearing_rad = np.radians(principal_direction)\n",
    "    x_velocity = np.cos(bearing_rad) * east_velocity + np.sin(bearing_rad) * north_velocity\n",
    "    y_velocity = -1 * np.sin(bearing_rad) * east_velocity + np.cos(bearing_rad) * north_velocity\n",
    "    return x_velocity, y_velocity\n",
    "\n",
    "def fixed2principal_components(east_velocity_list, north_velocity_list):\n",
    "    \"\"\"\n",
    "    Function to calculate the principal components from a cluster of velocities.\n",
    "    :param east_velocity_list: list of velocities in Eastern direction (list)\n",
    "    :param north_velocity_list: list of velocities in Northern direction (list)\n",
    "    :return: principal direction in degrees (float)\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=2)  # whiten=True can be added\n",
    "    X = np.column_stack((east_velocity_list, north_velocity_list))\n",
    "    X_pca = pca.fit(X)\n",
    "\n",
    "    y_pca = pca.components_[:, 1][0]  # - pca.mean_[1]\n",
    "    x_pca = pca.components_[:, 0][0]  # - pca.mean[0]\n",
    "    theta = np.arctan2(y_pca, x_pca)\n",
    "    alpha = np.degrees(theta)\n",
    "\n",
    "    # Correction for positive alpha in coordinate system with positive x-direction upestuary\n",
    "    if alpha >= 0:\n",
    "        alpha = alpha - 180  # in degrees\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d9bbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = FG\n",
    "node = [14,'Node 15']\n",
    "lon_vel = []\n",
    "lat_vel = []\n",
    "t_vel = network.nodes[node[1]]['Info']['Current direction'][0]\n",
    "cur_mag = network.nodes[node[1]]['Info']['Current velocity'][1]\n",
    "cur_dir = network.nodes[node[1]]['Info']['Current direction'][1]\n",
    "for i in range(len(t_vel)):\n",
    "    lon_vel.append(cur_mag[i] * np.sin(cur_dir[i] / 180 * np.pi))\n",
    "    lat_vel.append(cur_mag[i] * np.cos(cur_dir[i] / 180 * np.pi))\n",
    "prim = fixed2principal_components(lon_vel,lat_vel)\n",
    "vel = [fixed2bearing(x, y, prim) for x, y in zip(lon_vel,lat_vel)]\n",
    "vel_prim = [x[0] for x in vel]\n",
    "interp = sc.interpolate.CubicSpline(t_vel, vel_prim)\n",
    "roots = interp.roots()\n",
    "times_tidal_periods = []\n",
    "prev_root = 0\n",
    "for root in interp.roots():\n",
    "    if root > t_vel[0] and root < t_vel[-1] and vel_prim[bisect.bisect_right(t_vel, root)] > 0 and root-prev_root > 0.25*12.5*60*60:\n",
    "        times_tidal_periods.append([root, 'Flood Start'])\n",
    "        prev_root = root\n",
    "    elif root > t_vel[0] and root < t_vel[-1] and vel_prim[bisect.bisect_right(t_vel, root)] < 0 and root-prev_root > 0.25*12.5*60*60:\n",
    "        times_tidal_periods.append([root, 'Ebb Start'])\n",
    "        prev_root = root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4c692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curvel = pd.read_csv(r'C:\\Users\\floorbakker\\OpenTNSim\\notebooks\\testdata_OSR\\6PE_magnitude.csv',delimiter=',') \n",
    "curdir = pd.read_csv(r'C:\\Users\\floorbakker\\OpenTNSim\\notebooks\\testdata_OSR\\6PE_angle.csv',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6357d2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "node = 'Node 15'\n",
    "t_vel = network.nodes[node]['Info']['Current direction'][0]\n",
    "cur_mag = network.nodes[node]['Info']['Current velocity'][1]\n",
    "cur_dir = [y/180*np.pi for y in network.nodes[node]['Info']['Current direction'][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0527b144",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_vel = []\n",
    "lat_vel = []\n",
    "for i in range(len(t_vel)):\n",
    "    lon_vel.append(cur_mag[i] * np.sin(cur_dir[i]))\n",
    "    lat_vel.append(cur_mag[i] * np.cos(cur_dir[i]))\n",
    "prim = fixed2principal_components(lon_vel,lat_vel)\n",
    "vel = [fixed2bearing(x, y, prim) for x, y in zip(lon_vel,lat_vel)]\n",
    "vel_prim = [x[0] for x in vel]\n",
    "interp = sc.interpolate.CubicSpline(t_vel, vel_prim)\n",
    "roots = interp.roots()\n",
    "times_tidal_periods = []\n",
    "prev_root = 0\n",
    "for root in interp.roots():\n",
    "    if root > t_vel[0] and root < t_vel[-1] and vel_prim[bisect.bisect_right(t_vel, root)] > 0 and root-prev_root > 0.25*12.5*60*60:\n",
    "        times_tidal_periods.append([root, 'Flood Start'])\n",
    "        prev_root = root\n",
    "    elif root > t_vel[0] and root < t_vel[-1] and vel_prim[bisect.bisect_right(t_vel, root)] < 0 and root-prev_root > 0.25*12.5*60*60:\n",
    "        times_tidal_periods.append([root, 'Ebb Start'])\n",
    "        prev_root = root\n",
    "\n",
    "plt.plot(t_vel,cur_mag,'grey')\n",
    "plt.plot(t_vel,interp(t_vel),'k')\n",
    "plt.axhline(0,color='k',linestyle='--')\n",
    "previous_time = t_vel[0]\n",
    "duration = 5*24*60*60\n",
    "xlimmin = t_vel[0]\n",
    "xlimmax = xlimmin+duration\n",
    "ylimmin = -1#1.25*np.min(vel_prim)\n",
    "ylimmax = 1.5#1.25*np.max(vel_prim)\n",
    "for times in times_tidal_periods:  \n",
    "    if times[1] == 'Flood Start':\n",
    "        plt.fill([previous_time,previous_time,times[0],times[0]],[ylimmin,ylimmax,ylimmax,ylimmin],color='grey',alpha=0.4)\n",
    "        if times[0] >= xlimmin and times[0] <= xlimmax:\n",
    "            plt.text(np.mean([previous_time,times[0]]),ylimmax*.925,'Ebb',horizontalalignment  = 'center')\n",
    "    if times[1] == 'Ebb Start':\n",
    "        plt.fill([previous_time,previous_time,times[0],times[0]],[ylimmin,ylimmax,ylimmax,ylimmin],color='k',alpha=0.4)\n",
    "        if times[0] >= xlimmin and times[0] <= xlimmax:\n",
    "            plt.text(np.mean([previous_time,times[0]]),ylimmax*1.025,'Flood',horizontalalignment  = 'center')\n",
    "    previous_time = times[0]\n",
    "plt.xlim([xlimmin,xlimmax])\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylim([ylimmin,ylimmax])\n",
    "plt.ylabel('Current velocity along \\n principle component (m/s)');\n",
    "plt.plot(network.nodes[node]['Info']['Water level'][0],\n",
    "         network.nodes[node]['Info']['Water level'][1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e18847c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    def __init__(self,start_time,network):\n",
    "        self.now = start_time\n",
    "        self.FG = network\n",
    "\n",
    "class Vessel:\n",
    "    def __init__(self,start_time,T,ukc,name,type,v,L,B,mccur,mwt,bound,network,start_node,end_node):\n",
    "        self.env = Environment(start_time,network)\n",
    "        self.T_f = T\n",
    "        self.L = L\n",
    "        self.v = v\n",
    "        self.B = B\n",
    "        self.ukc = ukc\n",
    "        self.metadata = {}\n",
    "        self.metadata['ukc'] = ukc\n",
    "        self.metadata['max_cross_current'] = mccur\n",
    "        self.metadata['max_waiting_time'] = mwt\n",
    "        self.bound = bound\n",
    "        self.name = name\n",
    "        self.type = type\n",
    "        self.route = nx.dijkstra_path(self.env.FG, start_node, end_node)\n",
    "        \n",
    "def calc_distance(node1,node2):\n",
    "    route = nx.dijkstra_path(FG,node1,node2)\n",
    "    distance = 0\n",
    "    previous_node = node1\n",
    "    for node in route:\n",
    "        distance += calculate_distance([FG.nodes[previous_node]['geometry'].x,FG.nodes[previous_node]['geometry'].y],\n",
    "                                       [FG.nodes[node]['geometry'].x,FG.nodes[node]['geometry'].y])\n",
    "        previous_node = node\n",
    "    return distance\n",
    "\n",
    "\n",
    "distance_to_anchorage = calc_distance('Node 1','Node 3')\n",
    "horizontal_tidal_restriction_distance = calc_distance('Node 1','Node 15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519800ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tidal_window_visualization(start_node,end_node,T_lower_limit,T_upper_limit,T_ticks):\n",
    "    T_list = np.arange(T_lower_limit,T_upper_limit,T_ticks)\n",
    "    route = nx.dijkstra_path(FG, start_node, end_node)\n",
    "    vesseltjes = []\n",
    "    vesseltje = []\n",
    "    print(start_node,end_node)\n",
    "    for i in range(len(T_list)):\n",
    "        vesseltje.append(Vessel(start_time = simulation_start.timestamp(),\n",
    "                                T = T_list[i],\n",
    "                                L = 149,\n",
    "                                v = 4.5,\n",
    "                                B = 27,\n",
    "                                ukc = 0,\n",
    "                                mccur = 0,\n",
    "                                mwt = 64*60*60,\n",
    "                                bound = 'in',\n",
    "                                typ = 'Handysize',\n",
    "                                network = network,\n",
    "                                start_node = start_node,\n",
    "                                end_node = end_node))\n",
    "    vesseltjes.append(vesseltje)\n",
    "    tws = []\n",
    "    for vesseltje in range(len(vesseltjes)):\n",
    "        tw = []\n",
    "        for v in range(len(vesseltjes[vesseltje])):\n",
    "            tw.append(core.VesselTrafficService.provide_sail_in_times_tidal_window(vesseltjes[vesseltje][v],\n",
    "                                                                                   route = vesseltjes[vesseltje][v].route,\n",
    "                                                                                   plot=False,\n",
    "                                                                                   sailing_time_correction=False,\n",
    "                                                                                   visualization_calculation=True,\n",
    "                                                                                   ukc_calc=False))\n",
    "        tws.append(tw)\n",
    "\n",
    "    twtjes = []\n",
    "    end =  10*12.5*60*60\n",
    "    s = simulation_start.timestamp()\n",
    "    for vesseltje in range(len(vesseltjes)):\n",
    "        twtje = []\n",
    "        for v in range(len(vesseltjes[vesseltje])):\n",
    "            if tws[vesseltje][v] != []:\n",
    "                if tws[vesseltje][v][0][1] == 'Stop':\n",
    "                    twtje.append([[tws[vesseltje][v][t[0]-1][0]-s,t[1][0]-s] for t in enumerate(tws[vesseltje][v]) if t[1][1] == 'Start'])\n",
    "                else:\n",
    "                    twtje.append([[t[1][0]-s,tws[vesseltje][v][t[0]+1][0]-s] for t in enumerate(tws[vesseltje][v]) if t[1][1] == 'Stop' and t[0] != len(tws[vesseltje][v])-1])\n",
    "            else:\n",
    "                twtje.append([[simulation_start.timestamp()-s,simulation_start.timestamp()+end-s],\n",
    "                              [simulation_start.timestamp()-s,simulation_start.timestamp()+end-s]])\n",
    "        twtjes.append(twtje)\n",
    "\n",
    "    indexes = []\n",
    "    locaties = []\n",
    "    tijdjess = []\n",
    "    waardens = []\n",
    "    for twtje in enumerate(twtjes):\n",
    "        tijd = []\n",
    "        for tw in twtje[1]:\n",
    "            for t in tw:\n",
    "                if t[1] <= end:\n",
    "                    tijd.extend([t[0],t[1]])\n",
    "                elif t[0] <= end:\n",
    "                    tijd.extend([t[0],end])\n",
    "                else:\n",
    "                    break\n",
    "        tijd.sort()\n",
    "        tijdjes = list(dict.fromkeys(tijd))\n",
    "        tijdjes.append(end)\n",
    "        waarden = np.zeros(len(tijdjes))\n",
    "        for tw in enumerate(twtje[1]):\n",
    "            for t in enumerate(tw[1]):\n",
    "                if t[0] == 0 and t[1][0] <= end and t[1][1] >= end:\n",
    "                    t[1][0] = 0\n",
    "                    t[1][1] = end\n",
    "                if t[1][1] <= end:                 \n",
    "                    indx1 = tijdjes.index(t[1][0])\n",
    "                    indx2 = tijdjes.index(t[1][1])\n",
    "                    for i in enumerate(tijdjes[indx1:indx2+1]):\n",
    "                        waarden[i[0]+indx1] = vesseltjes[twtje[0]][tw[0]].T_f\n",
    "                \n",
    "        tijdjess.extend(tijdjes)\n",
    "        waardens.extend(waarden)\n",
    "        vesseltje = vesseltjes[twtje[0]][0]         \n",
    "        route = nx.dijkstra_path(FG,'Node 1',vesseltjes[twtje[0]][0].route[-1])\n",
    "        previous_node = 'Node 1'\n",
    "        distance = 0\n",
    "        for node in route:\n",
    "            if node != previous_node:        \n",
    "                distance += calculate_distance([FG.nodes[previous_node]['geometry'].x,FG.nodes[previous_node]['geometry'].y],\n",
    "                                               [FG.nodes[node]['geometry'].x,FG.nodes[node]['geometry'].y])\n",
    "                previous_node = node\n",
    "\n",
    "        locaties.extend(list(distance*np.ones(len(tijdjes))))\n",
    "        if twtje[0] != len(twtjes)-1:\n",
    "            indexes.append(len(locaties)-1)\n",
    "\n",
    "    return indexes,locaties,tijdjess,waardens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a268b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tidal_window_visualization2(start_node,end_node,T_lower_limit,T_upper_limit,T_ticks,bound):\n",
    "    T_list = np.arange(T_lower_limit,T_upper_limit,T_ticks)\n",
    "    route = nx.dijkstra_path(FG, start_node, end_node)\n",
    "    vesseltjes = []\n",
    "    vesseltje = []\n",
    "    print(start_node,end_node)\n",
    "    for i in range(len(T_list)):\n",
    "        vesseltje.append(Vessel(start_time = simulation_start.timestamp(),\n",
    "                                T = T_list[i],\n",
    "                                L = 149,\n",
    "                                v = 4.5,\n",
    "                                B = 27,\n",
    "                                ukc = 0,\n",
    "                                mccur = 0,\n",
    "                                mwt = 64*60*60,\n",
    "                                bound = bound,\n",
    "                                typ = 'Handysize',\n",
    "                                network = network,\n",
    "                                start_node = start_node,\n",
    "                                end_node = end_node))\n",
    "    vesseltjes.append(vesseltje)\n",
    "    tws = []\n",
    "    for vesseltje in range(len(vesseltjes)):\n",
    "        tw = []\n",
    "        for v in range(len(vesseltjes[vesseltje])):\n",
    "            tw.append(core.VesselTrafficService.provide_sail_in_times_tidal_window(vesseltjes[vesseltje][v],\n",
    "                                                                                   route = vesseltjes[vesseltje][v].route,\n",
    "                                                                                   plot=False,\n",
    "                                                                                   sailing_time_correction=False,\n",
    "                                                                                   visualization_calculation=True,\n",
    "                                                                                   ukc_calc=False))\n",
    "        tws.append(tw)\n",
    "\n",
    "    twtjes = []\n",
    "    end =  10*12.5*60*60\n",
    "    s = simulation_start.timestamp()\n",
    "    for vesseltje in range(len(vesseltjes)):\n",
    "        twtje = []\n",
    "        for v in range(len(vesseltjes[vesseltje])):\n",
    "            if tws[vesseltje][v] != []:\n",
    "                if tws[vesseltje][v][0][1] == 'Stop':\n",
    "                    twtje.append([[tws[vesseltje][v][t[0]-1][0]-s,t[1][0]-s] for t in enumerate(tws[vesseltje][v]) if t[1][1] == 'Start'])\n",
    "                else:\n",
    "                    twtje.append([[t[1][0]-s,tws[vesseltje][v][t[0]+1][0]-s] for t in enumerate(tws[vesseltje][v]) if t[1][1] == 'Stop' and t[0] != len(tws[vesseltje][v])-1])\n",
    "            else:\n",
    "                twtje.append([[simulation_start.timestamp()-s,simulation_start.timestamp()+end-s],\n",
    "                              [simulation_start.timestamp()-s,simulation_start.timestamp()+end-s]])\n",
    "        twtjes.append(twtje)\n",
    "\n",
    "    indexes = []\n",
    "    locaties = []\n",
    "    tijdjess = []\n",
    "    waardens = []\n",
    "    for twtje in enumerate(twtjes):\n",
    "        tijd = []\n",
    "        for tw in twtje[1]:\n",
    "            for t in tw:\n",
    "                tijd.extend([t[0],t[1]])\n",
    "        tijd.sort()\n",
    "        tijden = list(dict.fromkeys(tijd))\n",
    "        tijdjes = []\n",
    "        tijdjes.append(0)\n",
    "        tijdjes.append(end)\n",
    "        for t in enumerate(tijden):\n",
    "            if t[0] != 0 and t[0] != len(tijden)-1:\n",
    "                tijdjes.extend([t[1],t[1]])\n",
    "            else:\n",
    "                tijdjes.append(t[1])\n",
    "        tijdjes.append(end)\n",
    "        waarden = np.zeros(len(tijdjes))       \n",
    "        for tw in enumerate(twtje[1]):\n",
    "            for t in enumerate(tw[1]):\n",
    "                if t[0] == 0 and t[1][0] <= end and t[1][1] >= end:\n",
    "                    t[1][0] = 0\n",
    "                    t[1][1] = end\n",
    "                if t[1][1] <= end:\n",
    "                    indx1 = tijdjes.index(t[1][0])\n",
    "                    indx2 = tijdjes.index(t[1][1])\n",
    "                    if indx2 != len(tijdjes)-1 and t[1][1] != end:\n",
    "                        if indx1 != 0:\n",
    "                            indx1 = indx1+1\n",
    "                        for i in enumerate(tijdjes[indx1:indx2+1]):\n",
    "                            waarden[i[0]+indx1] = vesseltjes[twtje[0]][tw[0]].T_f\n",
    "                    else:\n",
    "                        if indx1 != 0:\n",
    "                            indx1 = indx1+1\n",
    "                            for i in enumerate(tijdjes[indx1:]):\n",
    "                                waarden[i[0]+indx1] = vesseltjes[twtje[0]][tw[0]].T_f\n",
    "                        else:\n",
    "                            for i in enumerate(tijdjes):\n",
    "                                waarden[i[0]] = vesseltjes[twtje[0]][tw[0]].T_f\n",
    "                            break\n",
    "                elif t[1][0] <= end:\n",
    "                    indx1 = tijdjes.index(t[1][0])+1\n",
    "                    for i in enumerate(tijdjes[indx1:]):\n",
    "                        waarden[i[0]+indx1] = vesseltjes[twtje[0]][tw[0]].T_f\n",
    "                    \n",
    "        tijdjess.extend(tijdjes)\n",
    "        waardens.extend(waarden)\n",
    "        \n",
    "        vesseltje = vesseltjes[twtje[0]][0]\n",
    "        route = nx.dijkstra_path(FG,'Node 1',vesseltjes[twtje[0]][0].route[-1])\n",
    "        previous_node = 'Node 1'\n",
    "        distance = 0\n",
    "        for node in route:\n",
    "            if node != previous_node:        \n",
    "                distance += calculate_distance([FG.nodes[previous_node]['geometry'].x,FG.nodes[previous_node]['geometry'].y],\n",
    "                                               [FG.nodes[node]['geometry'].x,FG.nodes[node]['geometry'].y])\n",
    "                previous_node = node\n",
    "\n",
    "        locaties.extend(list(distance*np.ones(len(tijdjes))))\n",
    "        if twtje[0] != len(twtjes)-1:\n",
    "            indexes.append(len(locaties)-1)\n",
    "\n",
    "    return indexes,locaties,tijdjess,waardens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d677bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(core)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49deb8d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "I = []\n",
    "X = []\n",
    "Y = []\n",
    "Z = []\n",
    "route = nx.dijkstra_path(FG, 'Node 1', 'Node 19')\n",
    "T_lower_limit = 4.5\n",
    "T_ticks = 0.05\n",
    "T_upper_limit = 16+T_ticks\n",
    "end = 10*12.5*60*60\n",
    "for node in enumerate(route):\n",
    "    i,x,y,z = test_tidal_window_visualization(node[1],node[1],T_lower_limit,T_upper_limit,T_ticks)\n",
    "    I.append(i)\n",
    "    X.append(x)\n",
    "    Y.append(y)\n",
    "    Z.append(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32d48e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_int = []\n",
    "y_int = []\n",
    "z_int = []\n",
    "for x in enumerate(X):  \n",
    "    print(x[0])\n",
    "    intrp = sc.interpolate.interp1d(Y[x[0]],Z[x[0]])\n",
    "    y_intrp = np.linspace(start,end,1000)\n",
    "    x_intrp = x[1][0]*np.ones(1000)\n",
    "    z_intrp = intrp(y_intrp)\n",
    "    x_int.append(x_intrp)\n",
    "    y_int.append(y_intrp)\n",
    "    z_int.append(z_intrp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc83bfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "I = []\n",
    "X = []\n",
    "Y = []\n",
    "Z = []\n",
    "route = nx.dijkstra_path(FG, 'Node 15', 'Node 15')\n",
    "T_lower_limit = 4.5\n",
    "T_ticks = 0.05\n",
    "T_upper_limit = 16+T_ticks\n",
    "for node in enumerate(route):\n",
    "    i,x,y,z = test_tidal_window_visualization2(node[1],node[1],T_lower_limit,T_upper_limit,T_ticks,'inbound')\n",
    "    I.append(i)\n",
    "    X.append(x)\n",
    "    Y.append(y)\n",
    "    Z.append(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0d90c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_int2 = []\n",
    "y_int2 = []\n",
    "z_int2 = []\n",
    "for x in enumerate(X):  \n",
    "    intrp = sc.interpolate.interp1d(Y[x[0]],Z[x[0]])\n",
    "    y_intrp = np.linspace(start,end,1000)\n",
    "    x_intrp = x[1][0]*np.ones(1000)\n",
    "    z_intrp = intrp(y_intrp)\n",
    "    x_int2.append(x_intrp)\n",
    "    y_int2.append(y_intrp)\n",
    "    z_int2.append(z_intrp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110cd1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "I = []\n",
    "X = []\n",
    "Y = []\n",
    "Z = []\n",
    "route = nx.dijkstra_path(FG, 'Node 15', 'Node 15')\n",
    "T_lower_limit = 4.5\n",
    "T_ticks = 0.05\n",
    "T_upper_limit = 16+T_ticks\n",
    "for node in enumerate(route):\n",
    "    i,x,y,z = test_tidal_window_visualization2(node[1],node[1],T_lower_limit,T_upper_limit,T_ticks,'outbound')\n",
    "    I.append(i)\n",
    "    X.append(x)\n",
    "    Y.append(y)\n",
    "    Z.append(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6806c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_int3 = []\n",
    "y_int3 = []\n",
    "z_int3 = []\n",
    "for x in enumerate(X):  \n",
    "    intrp = sc.interpolate.interp1d(Y[x[0]],Z[x[0]])\n",
    "    y_intrp = np.linspace(start,end,1000)\n",
    "    x_intrp = x[1][0]*np.ones(1000)\n",
    "    z_intrp = intrp(y_intrp)\n",
    "    x_int3.append(x_intrp)\n",
    "    y_int3.append(y_intrp)\n",
    "    z_int3.append(z_intrp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab6d5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "terminal = vessels[0].env.FG.edges['Node 18','Node 19']['Terminal'][0]\n",
    "if terminal.type == 'quay':\n",
    "    max_available_quay_length = terminal.length.capacity\n",
    "if terminal.type == 'jetty':\n",
    "    max_available_quay_length = 5\n",
    "    \n",
    "def make_rgb_transparent(rgb, bg_rgb, alpha):\n",
    "    return [alpha * c1 + (1 - alpha) * c2\n",
    "            for (c1, c2) in zip(rgb, bg_rgb)]\n",
    "\n",
    "def calculate_alpha(cf, cb):\n",
    "    a = cb[-1] + cf[-1] - cb[-1] * cf[-1]\n",
    "    return a\n",
    "\n",
    "#alphas = np.linspace(0,1,50)\n",
    "#colors = [make_rgb_transparent(mpl.colors.to_rgb('lightgreen'),[1,1,1],a) for a in alphas]\n",
    "#cmap = mpl.colors.ListedColormap(colors)\n",
    "colors = []\n",
    "colors.append([1,1,1])\n",
    "for c in enumerate(mpl.colorbar.cm.tab20.colors):\n",
    "    if (c[0]-1)%2 == 0 and c[0] <= 16:\n",
    "        colors.append(c[1])\n",
    "bounds = list(vdf['T_f'])\n",
    "bounds.insert(0,0)\n",
    "cmap = mpl.colors.ListedColormap(colors)\n",
    "norm = mpl.colors.BoundaryNorm(boundaries=bounds,ncolors=9, extend='max')\n",
    "cmap_plot = mpl.colors.ListedColormap(colors[1:])\n",
    "norm_plot = mpl.colors.BoundaryNorm(boundaries=bounds[1:],ncolors=8, extend='max')\n",
    "\n",
    "vesseltje = vessels[0]\n",
    "start = 0\n",
    "end =  10*12.5*60*60\n",
    "end_cor = 0#5*12.5*60*60\n",
    "ax3xlist = [eta+depth[1][16] for eta in water_level[1][16][1]] #let's define it at node 15 to visualize when we have the critical bed level of MBL=-16.4m NAP\n",
    "ax3ylist = [t-simulation_start.timestamp() for t in water_level[1][16][0]] \n",
    "ax4xlist = current_velocity[1][13][1]\n",
    "ax4ylist = [t-simulation_start.timestamp() for t in current_velocity[1][14][0]]\n",
    "required_water_level = vesseltje.metadata['ukc'] + vesseltje.T_f\n",
    "    \n",
    "if terminal.type == 'quay':\n",
    "    time_available_quay_length = []\n",
    "    available_quay_length = []\n",
    "    quay_level = 0\n",
    "    time_available_quay_length.append(0)\n",
    "    available_quay_length.append(quay_level)\n",
    "    for t in range(len(terminal.log[\"Message\"])):\n",
    "        time_available_quay_length.append(terminal.log[\"Timestamp\"][t].timestamp()-simulation_start.timestamp())\n",
    "        available_quay_length.append(quay_level)\n",
    "        time_available_quay_length.append(terminal.log[\"Timestamp\"][t].timestamp()-simulation_start.timestamp())\n",
    "        available_quay_length.append(terminal.log[\"Value\"][t])\n",
    "        quay_level = terminal.log[\"Value\"][t]\n",
    "        \n",
    "if terminal.type == 'jetty':\n",
    "    time_available_quay_length = []\n",
    "    available_quay_length = []\n",
    "    quay_level = 0\n",
    "    time_available_quay_length.append(0)\n",
    "    available_quay_length.append(quay_level)\n",
    "    for t in range(len(terminal.log[\"Message\"])):\n",
    "        time_available_quay_length.append(terminal.log[\"Timestamp\"][t].timestamp()-simulation_start.timestamp())\n",
    "        available_quay_length.append(quay_level)\n",
    "        time_available_quay_length.append(terminal.log[\"Timestamp\"][t].timestamp()-simulation_start.timestamp())\n",
    "        available_quay_length.append(terminal.log[\"Value\"][t])\n",
    "        quay_level = terminal.log[\"Value\"][t]\n",
    "    \n",
    "anchorage = vessels[0].env.FG.nodes['Node 20']['Anchorage'][0]\n",
    "time_anchorage_occupation = []\n",
    "anchorage_occupation = []\n",
    "anchorage_capacity = 0\n",
    "time_anchorage_occupation.append(0)\n",
    "anchorage_occupation.append(anchorage_capacity)\n",
    "for t in range(len(anchorage.log[\"Message\"])):\n",
    "    time_anchorage_occupation.append(anchorage.log[\"Timestamp\"][t].timestamp()-simulation_start.timestamp())\n",
    "    anchorage_occupation.append(anchorage_capacity)\n",
    "    time_anchorage_occupation.append(anchorage.log[\"Timestamp\"][t].timestamp()-simulation_start.timestamp())\n",
    "    anchorage_occupation.append(anchorage.log[\"Value\"][t])\n",
    "    anchorage_capacity = anchorage.log[\"Value\"][t]\n",
    "\n",
    "fig, (ax1,ax2,ax3,ax4,ax5,ax6) = plt.subplots(1,6,figsize=(16, 9),gridspec_kw={'width_ratios': [3.5, 0.25, 0.25, 1, 1, 1]})\n",
    "ax1.patch.set_alpha(0)\n",
    "ax2.patch.set_alpha(0)\n",
    "ax3.patch.set_alpha(0)\n",
    "ax4.patch.set_alpha(0)\n",
    "ax1.set_xlim([0,125000])\n",
    "figxlimits = ax1.axes.get_xlim()\n",
    "for y in enumerate(y_int[0]):\n",
    "    x_intrp_old = [x[y[0]] for x in x_int]\n",
    "    z_intrp_old = [z[y[0]] for z in z_int]\n",
    "    intrp = sc.interpolate.interp1d(x_intrp_old,z_intrp_old,fill_value='extrapolate')\n",
    "    x_intrp = np.linspace(0,figxlimits[1],1000)\n",
    "    y_intrp = y[1]*np.ones(1000)\n",
    "    z_intrp = intrp(x_intrp)\n",
    "    ax1.scatter(x_intrp,y_intrp,s=2,c=z_intrp,norm=norm,cmap=cmap)\n",
    "    \n",
    "for y in enumerate(y_int2[0]):\n",
    "    x_intrp_old2 = [[x for x in x_int2][0][y[0]]-100,[x for x in x_int2][0][y[0]]+100]\n",
    "    z_intrp_old2 = [[z for z in z_int2][0][y[0]],[z for z in z_int2][0][y[0]]]\n",
    "    intrp = sc.interpolate.interp1d(x_intrp_old2,z_intrp_old2,fill_value='extrapolate')\n",
    "    x_intrp = np.linspace(-100+horizontal_tidal_restriction_distance,100+horizontal_tidal_restriction_distance,1000)\n",
    "    y_intrp = y[1]*np.ones(1000)\n",
    "    z_intrp = intrp(x_intrp)\n",
    "    ax2.scatter(x_intrp,y_intrp,s=2,c=z_intrp,norm=norm,cmap=cmap)\n",
    "    \n",
    "for y in enumerate(y_int3[0]):\n",
    "    x_intrp_old2 = [[x for x in x_int3][0][y[0]]-100,[x for x in x_int3][0][y[0]]+100]\n",
    "    z_intrp_old2 = [[z for z in z_int3][0][y[0]],[z for z in z_int3][0][y[0]]]\n",
    "    intrp = sc.interpolate.interp1d(x_intrp_old2,z_intrp_old2,fill_value='extrapolate')\n",
    "    x_intrp = np.linspace(-100+horizontal_tidal_restriction_distance,100+horizontal_tidal_restriction_distance,1000)\n",
    "    y_intrp = y[1]*np.ones(1000)\n",
    "    z_intrp = intrp(x_intrp)\n",
    "    ax3.scatter(x_intrp,y_intrp,s=2,c=z_intrp,norm=norm,cmap=cmap)\n",
    "    \n",
    "vessel_types = list(vdf['type'])\n",
    "vessel_drafts = list(vdf['T_f'])\n",
    "vessel_ukcs = list(vdf['ukc'])\n",
    "ax1.axvline(distance_to_anchorage,color = 'k',linestyle = '--')\n",
    "ax1.fill([horizontal_tidal_restriction_distance-1000,\n",
    "          horizontal_tidal_restriction_distance,\n",
    "          horizontal_tidal_restriction_distance,\n",
    "          horizontal_tidal_restriction_distance-1000],\n",
    "         [start,start,end,end],fill=False,color='k')\n",
    "ax1.axvline(122000,color = 'k',linestyle = '--')\n",
    "ax1.text(horizontal_tidal_restriction_distance-1500,0.95*(end-end_cor),'Horizontal\\n Tidal Restriction',horizontalalignment  = 'right')\n",
    "ax1.text(distance_to_anchorage,1.02*(end-end_cor),'Anchorage',horizontalalignment  = 'center')\n",
    "ax1.text(122000,1.02*(end-end_cor),'Terminal',horizontalalignment  = 'right')\n",
    "vessel_types = list(vdf['type'])\n",
    "for v in reversed(range(len(vessels))):\n",
    "    color,linewidth = color_vessels(vessels[v])\n",
    "    ax1.plot(vessel_path_x[v],vessel_path_t[v],color=color,linewidth=linewidth)\n",
    "vessel_legend(ax1,vessel_types)\n",
    "ax1.set_title(\"Tracking diagram and vertical tidal restriction for\\n vessels calling at a liquid bulk terminal\", fontweight='bold', pad = 32)\n",
    "ax1.set_xlabel('Distance [m]')\n",
    "ax1.set_xlim(figxlimits)\n",
    "ax1.set_ylabel('Time [s]')\n",
    "ax1.set_ylim([start,end-end_cor]);\n",
    "\n",
    "ax2.set_xlim([-100+horizontal_tidal_restriction_distance,100+horizontal_tidal_restriction_distance])\n",
    "for v in reversed(range(len(vessels))):\n",
    "    color,linewidth = color_vessels(vessels[v])\n",
    "    ax2.plot(vessel_path_x[v][:int(0.5*len(vessel_path_x[0]))],vessel_path_t[v][:int(0.5*len(vessel_path_x[0]))],color=color,linewidth=linewidth)\n",
    "ax2.set_ylim([start,end-end_cor])\n",
    "ax2.set_title(\"Horizontal\\n Tidal\\n Restriction\", fontweight='bold', position = [1.4,1.4],pad=26)\n",
    "ax2.text(horizontal_tidal_restriction_distance,1.01*(end-end_cor),'inbound\\n vessels',horizontalalignment  = 'center')\n",
    "ax2.yaxis.set_visible(False)\n",
    "ax2.xaxis.set_visible(False)\n",
    "\n",
    "ax3.set_xlim([-100+horizontal_tidal_restriction_distance,100+horizontal_tidal_restriction_distance])\n",
    "for v in reversed(range(len(vessels))):\n",
    "    color,linewidth = color_vessels(vessels[v])\n",
    "    ax3.plot(vessel_path_x[v][int(0.5*len(vessel_path_x[0])):],vessel_path_t[v][int(0.5*len(vessel_path_x[0])):],color=color,linewidth=linewidth)\n",
    "ax3.set_ylim([start,end-end_cor])\n",
    "ax3.text(horizontal_tidal_restriction_distance,1.01*(end-end_cor),'outbound\\n vessels',horizontalalignment  = 'center')\n",
    "ax3.yaxis.set_visible(False)\n",
    "ax3.xaxis.set_visible(False)\n",
    "\n",
    "ax4.plot([max_available_quay_length-x for x in available_quay_length],time_available_quay_length)\n",
    "ax4.set_xlim([0,1.1*max_available_quay_length])\n",
    "figxlimits = ax4.axes.get_xlim()\n",
    "if terminal.type == 'quay':\n",
    "    ax4.axvline(vessels[0].L,color = 'k', linestyle = '--')\n",
    "    ax4.set_title(\"Available quay length \\n over time\", fontweight='bold', pad = 32)\n",
    "    ax4.text(vessels[0].L,1.01*end,'Required quay \\n length',horizontalalignment = 'center') \n",
    "elif terminal.type == 'jetty':\n",
    "    ax4.axvline(1,color = 'k', linestyle = '--')\n",
    "    ax4.set_title(\"Available jetties \\n over time\", fontweight='bold', pad = 32)\n",
    "ax4.set_xlim(figxlimits)\n",
    "ax4.yaxis.set_visible(False)\n",
    "ax4.set_ylim([start,end-end_cor])\n",
    "ax4.set_xlabel('Number of jetties [-]');\n",
    "\n",
    "ax5.plot(ax3xlist,ax3ylist)\n",
    "ax5.plot([eta+depth[1][6] for eta in water_level[1][6][1]],ax3ylist,c='#1f77b4')\n",
    "ax5.set_ylim([start,end-end_cor])\n",
    "figxlimits = ax5.axes.get_xlim()\n",
    "ax5.yaxis.set_visible(False)\n",
    "ax5.set_ylim([start,end-end_cor])\n",
    "ax5.set_xlim(figxlimits)\n",
    "ax5.set_xlabel('Water depth [m]');\n",
    "ax5.set_title(\"Available water\\n depth over\\n time\", fontweight='bold', pad = 26)\n",
    "ax5.yaxis.set_visible(False)\n",
    "\n",
    "ax6.set_xlabel('Current \\n velocity [m/s]',horizontalalignment = 'center');\n",
    "ax6.plot(ax4xlist,ax4ylist)\n",
    "ax6.set_ylim([start,end-end_cor])\n",
    "figxlimits = ax6.axes.get_xlim()\n",
    "ax6.set_title(\"Current\\n velocity\\n over time\", fontweight='bold', pad = 26)\n",
    "ax6.set_ylim([start,end-end_cor])\n",
    "ax6.set_xlim(figxlimits)\n",
    "ax6.yaxis.set_visible(False)\n",
    "\n",
    "cax = fig.add_axes([0.925, 0.125, 0.01, 0.755])\n",
    "cbar = mpl.colorbar.ColorbarBase(cax, cmap=cmap_plot,norm=norm_plot, orientation='vertical')\n",
    "cbar.set_label('Maximum draught of vessel that is allowed to sail [m]')\n",
    "plt.show();\n",
    "extent = fig.get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "#fig.savefig('added_vessels1.png', dpi=300,bbox_inches=extent.expanded(1.0, 1.2));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57d15e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vesselt = Vessel(start_time = simulation_start.timestamp(),\n",
    "                    T = 10.3,\n",
    "                    L = 180,\n",
    "                    v = 4.5,\n",
    "                    B = 27,\n",
    "                    ukc = 0,\n",
    "                    mccur = 0,\n",
    "                    mwt = 24*60*60,\n",
    "                    bound = 'inbound',\n",
    "                    name = 'testship',\n",
    "                    type = 'Tanker',\n",
    "                    network = FG,\n",
    "                    start_node = 'Node 15',\n",
    "                    end_node = 'Node 15')\n",
    "\n",
    "_ = core.VesselTrafficService.provide_sail_in_times_tidal_window(vesselt,\n",
    "                                                                 route =vesselt.route,\n",
    "                                                                 plot=True,\n",
    "                                                                 sailing_time_correction = True,\n",
    "                                                                 visualization_calculation = True,\n",
    "                                                                 ukc_calc=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f476589a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tidal_periods(t_astro_tide_wlev, astro_tide_wlev):\n",
    "    \"\"\" Function: calculates the water level which is exceeded 99% of the tides for a given node in the network.\n",
    "\n",
    "        Input:\n",
    "            - t_astro_wlev: a list containing the chronological sequence of timestamps for the specific node, derived from the\n",
    "                            list of the time series containing the water level at the specific node\n",
    "            - astro_wlev: a list containing the chronological sequence of water levels for the specific node, derived from the\n",
    "                          list of the time series containing the water level at the specific node\n",
    "    \"\"\"\n",
    "\n",
    "    # Deriving some properties\n",
    "    mean_astro_wlev = np.mean(astro_tide_wlev)\n",
    "\n",
    "    # Interpolation of the variation of the water level and calculation of the zero crossing times\n",
    "    cor_astro_tide = [astro_wlev - mean_astro_wlev for astro_wlev in astro_tide_wlev]\n",
    "    intp = sc.interpolate.CubicSpline(t_astro_tide_wlev, cor_astro_tide)\n",
    "    times_tidal_periods = []\n",
    "    index_prev_root = 0\n",
    "    for root in intp.roots():\n",
    "        index_current_root = bisect.bisect_right(t_astro_tide_wlev, root)\n",
    "        if root >= t_astro_tide_wlev[0] and root <= t_astro_tide_wlev[-1] and np.max(cor_astro_tide[index_prev_root:index_current_root]) > 0:\n",
    "            index = cor_astro_tide[index_prev_root:index_current_root].index(np.max(cor_astro_tide[index_prev_root:index_current_root]))\n",
    "            time_start_next_tidal_period = t_astro_tide_wlev[index + index_prev_root]\n",
    "            times_tidal_periods.append([time_start_next_tidal_period, 'Ebb Start'])\n",
    "            index_prev_root = index_current_root\n",
    "        elif root >= t_astro_tide_wlev[0] and root <= t_astro_tide_wlev[-1] and np.min(cor_astro_tide[index_prev_root:index_current_root]) < 0:\n",
    "            index = cor_astro_tide[index_prev_root:index_current_root].index(np.min(cor_astro_tide[index_prev_root:index_current_root]))\n",
    "            time_start_next_tidal_period = t_astro_tide_wlev[index + index_prev_root]\n",
    "            times_tidal_periods.append([time_start_next_tidal_period, 'Flood Start'])\n",
    "            index_prev_root = index_current_root\n",
    "\n",
    "    return times_tidal_periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0beb45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def astronomical_tide(signal_time,signal_values):\n",
    "    signal_datetime = [datetime.datetime.fromtimestamp(y) for y in signal_time]\n",
    "    const_list = hatyan.get_const_list_hatyan('tidalcycle')\n",
    "    times_ext = signal_datetime\n",
    "    ts_meas = pd.DataFrame({'values': signal_values}, index=signal_datetime)\n",
    "    ts_meas = hatyan.crop_timeseries(ts=ts_meas, times_ext=times_ext);\n",
    "    comp_frommeas, comp_allyears = hatyan.get_components_from_ts(ts=ts_meas, const_list=const_list, nodalfactors=True, return_allyears=True, fu_alltimes=True, analysis_peryear=True)\n",
    "    ts_prediction = hatyan.prediction(comp=comp_frommeas, nodalfactors=True, xfac=True, fu_alltimes=True, times_ext=times_ext, timestep_min=5)\n",
    "    return [[index.timestamp()-3600 for index in ts_prediction.index],[value for value in ts_prediction['values']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf62704b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import hatyan\n",
    "\n",
    "x = np.linspace(0,12.5*60*60,10000)\n",
    "y = np.sin(x/(12.5*60*60)*2*np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "546746b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "cropping timeseries\n",
      "timeseries contents:\n",
      "                                  values\n",
      "1970-01-01 01:00:00.000000  0.000000e+00\n",
      "1970-01-01 01:00:04.500450  6.283813e-04\n",
      "1970-01-01 01:00:09.000900  1.256762e-03\n",
      "1970-01-01 01:00:13.501350  1.885143e-03\n",
      "1970-01-01 01:00:18.001800  2.513523e-03\n",
      "...                                  ...\n",
      "1970-01-01 13:29:41.998200 -2.513523e-03\n",
      "1970-01-01 13:29:46.498650 -1.885143e-03\n",
      "1970-01-01 13:29:50.999100 -1.256762e-03\n",
      "1970-01-01 13:29:55.499550 -6.283813e-04\n",
      "1970-01-01 13:30:00.000000 -2.449294e-16\n",
      "\n",
      "[10000 rows x 1 columns]\n",
      "timeseries # unique timesteps: 2\n",
      "timeseries unique timesteps (minutes):\n",
      "{0.07500749999999999, 0.07500751666666666}\n",
      "timeseries validity: all time intervals are in increasing order and are never equal\n",
      "timeseries length: 10000\n",
      "timeseries # nonan: 10000\n",
      "timeseries % nonan: 100.0%\n",
      "timeseries # nan: 0\n",
      "timeseries % nan: 0.0%\n",
      "--------------------------------------------------\n",
      "running: get_components_from_ts\n",
      "analysis_peryear=True, separate years are automatically determined from unique calendar years in timeseries\n",
      "analyzing 1970 of sequence [1970]\n",
      "--------------------------------------------------\n",
      "ANALYSIS initializing\n",
      "source               = schureman\n",
      "nodalfactors         = True\n",
      "fu_alltimes          = True\n",
      "xfac                 = False\n",
      "CS_comps             = None\n",
      "analysis_peryear     = True\n",
      "analysis_permonth    = False\n",
      "return_allyears      = True\n",
      "return_prediction    = False\n",
      "\n",
      "#timesteps           = 10000\n",
      "tstart               = 1970-01-01 01:00:00\n",
      "tstop                = 1970-01-01 13:30:00\n",
      "timestep             = None\n",
      "components analyzed  = 7\n",
      "percentage_nan in values_meas_sel: 0.00%\n",
      "freq is calculated at mid of period: 1970-01-01 07:15:02.250225\n",
      "v0 is calculated for start of period: 1970-01-01 01:00:00\n",
      "nodal factors (f and u) are calculated for all timesteps\n",
      "Rayleigh criterion OK (always>0.99, minimum is 805.11)\n",
      "Frequencies are far enough apart (always >0.000099, minimum is 0.080511)\n",
      "calculating xTx matrix\n",
      "xTx matrix calculated\n",
      "condition of xTx matrix before center adjustment for A0: 38905509057847264.00\n",
      "condition of xTx matrix: 3.11\n",
      "matrix system solved, elapsed time: 0:00:00\n",
      "ANALYSIS finished\n",
      "vector averaging analysis results\n",
      "--------------------------------------------------\n",
      "PREDICTION initializing\n",
      "source               = schureman\n",
      "nodalfactors         = True\n",
      "fu_alltimes          = True\n",
      "xfac                 = True\n",
      "CS_comps             = None\n",
      "analysis_peryear     = False\n",
      "analysis_permonth    = False\n",
      "return_allyears      = False\n",
      "return_prediction    = False\n",
      "\n",
      "components used      = 7\n",
      "tstart               = 1970-01-01 01:00:00\n",
      "tstop                = 1970-01-01 13:30:00\n",
      "timestep             = <5 * Minutes>\n",
      "freq is calculated at mid of period: 1970-01-01 07:15:00\n",
      "v0 is calculated for start of period: 1970-01-01 01:00:00\n",
      "nodal factors (f and u) are calculated for all timesteps\n",
      "PREDICTION started\n",
      "PREDICTION finished\n"
     ]
    }
   ],
   "source": [
    "a = astronomical_tide(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aec9fb83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f6bf4d9940>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAy1klEQVR4nO3dd3RU1drH8e8zJYVQQiD0EkCqiBiigPTeBcSCFcuVi2JBvQqWa33tBcEOWFAUEBWJFEFQKSol9N4RQhBCDSGkzMx+/8jgjTFAQmZyMpnns9asmdPm/Oa4zMM+Z5+zxRiDUkqp4GWzOoBSSilraSFQSqkgp4VAKaWCnBYCpZQKcloIlFIqyDmsDnAhKlasaGJiYqyOoZRSAWXlypWHjTHRuecHZCGIiYkhISHB6hhKKRVQROSPvObrqSGllApyWgiUUirIaSFQSqkgp4VAKaWCnBYCpZQKcloIlFIqyGkhUEqpIOeT+whE5GOgL3DIGNM0j+UCjAF6A2nAbcaYVd5lPb3L7MAEY8zLvsikLkDaUTi0GY7tgbQjkJkKYgNHKJSuAuWqQ6WLIaKC1UmVUj7kqxvKPgXeAT47y/JeQH3vqyXwPtBSROzAu0A3IBFYISLxxphNPsqlzsWVCTvmw/a5sHsRHN2Vv+3K1YQ6HeCiLtCgB4RE+DenUsqvfFIIjDGLRCTmHKv0Bz4z2aPgLBWRSBGpCsQAO4wxuwBEZIp3XS0E/nR4Byz/ENZ9BenHIbQsWTWvZF/ta9lJLTZlRrMvszRHMhx4jKGcI4sq9hQahh6lgdlDTPomSm/5HlkzCZwR0LgvXDEUasRZ/cuUUhegqB4xUR3Yl2M60Tsvr/kt8/oCERkKDAWoVauWf1KWdIc2w0//B1tmgj2ElDq9medoz+eH6rJ+Yxoe72B1pUOhYulMyoQZbDbhYJZhxekwxqdEYUwUEEv5sFu5qdoBrgn5jdpbZyPrpkKNK6DjSKjXBUQs/alKqfwrqkKQ118Fc475/5xpzDhgHEBcXJyOr1kQp47A/Kdg9ReYkAg2XjSUFw615fcNDmwCcTFh3Ne5OpfHRNGgSmmiS4ciefwhz3C52Xc0jdV7j7Niz1G+2urknZOViXL05qmaa+h9/BtCJg2CWldCzxeh2mUW/FilVEEVVSFIBGrmmK4BJAEhZ5mvfMEYWPMFzHsSk3GStTVu5KGkruzaEMrF1cryXP+a9L6kKhVLh+br60Iddi6qVIaLKpXh2riaeDyGlXuP8e2q/YxaHc4jWS14ospybjo0Bee4TtDiNuj6DIRH+vNXKqUKqagKQTxwr/caQEvghDHmgIgkA/VFpA6wHxgM3FhEmUq21GT4/n7YOpvkqBY84LqF33ZUomPDaF5oX49WdaPy/Fd/QdhswuUxUVweE8Wono2YvGIvYxaG80Zac96qPIfOqz5Dts2Fq96G+l199MOUUr7mq+6jk4GOQEURSQSeBpwAxpgPgNlkdx3dQXb30du9y1wici8wl+zuox8bYzb6IlNQ++M3mHYbntPH+bzMUJ5Jak+zmlFMvaERLev6p+tnuVJOhnWox00ta/HRkt3cu7AMl0gsH7onUP6LQdDqHuj6LDhC/LJ/pdSFk+yOPIElLi7O6HgEeTAGln2AmfsEKWHVufnkvexxxPDfPk24Nq5GoVsABZF4LI2nZ2xkyZZE3ij/LX1Px0O1WLjuM4isef4vUEr5nIisNMb8o3tfQA5Mo/LgccPcJ2DZ+6wu1YZbj95O6yZ1mDCgKZXLhhV5nBrlSzFhSByz1lfn8W9LMd/U57VDH+Ic3wmu/wJq5dk5TCllAX3EREmQlQ7TboNl7zPV3o/BJ+7h0f6XM+6WFpYUgTNEhL7NqjFnRHv2V+1Kz1NPc8QVipnYFzZ8Y1kupdTfaYsg0KUdhSk3wd7feNF9C7PCrmbabbFcWjPS6mR/qR4ZzuS7WvHKD5F0XlyOqWXH0vDrO5GMk9k9i5RSltJCEMhOHcZM7IcneTsPZN3P/uo9ib81jgr57A5alBx2G0/0aUKDymW4bnoo48LG0ur7B+D0cWg7wup4SgU1LQSBKu0o5rP+uJJ3MCTjEcpf3I3J111KmNNudbJzujauJnUqRjD0Uyev2N6l2/ynsx9z0eVpvRtZKYtoIQhE6Scwk67GfWgrd2Y8RINWfXmqbxNstsD4QxoXE8WXw9oxZIKDE55wrlkyOvtid/fnrY6mVFDSQhBoMk5iJl2D+8B6hmaMoHG7gYzq2ahIu4b6QqMqZfnq7rbcPMGBK83G4N/GQqkoaPug1dGUCjpaCAKJKwMzeTCexJUMz7yfpp2u58Gu9QOuCJxRu0IEU/99Jdd/YCiXfope85+B8PJ6AVmpIqaFIFAYg5kxHNmzhAczh9Og4w081K2B1akKrVpkOF8OvZIbP3BRJjONNt+PQMLKwcUDrY6mVNDQ+wgCxc8vIuun8WrW9US2vLFEFIEzakaVYuJdbRnleIR10hDzzV2w6xerYykVNLQQBILVX8CiV5ni6sj+psN4pt/FAXs66GzqRpdm/J3tGOYZyR9UxXw1BI7stDqWUkFBC0Fxt2shnvj7WeJpytw6I3n9uuYB0zuooBpXLcurN7fj9vSHSM10YybfAOkpVsdSqsTTQlCcHd2Fe+ot7DJVeT3yCcbcdDlOe8n+T9aufjTDB3VjaPr9eA7vwHzzr+yupUopvynZf1UCWWYarsk3cyrDzQjbKN6+rSNlw5xWpyoS17SoQcvOA3g661Zk+1z4Se8vUMqftBAUR8bg+X4EtuRNPOQazjO39qZmVCmrUxWp+zvXJ7nhTXzp7gJLRutD6pTyI58UAhHpKSJbRWSHiIzKY/kjIrLG+9ogIm4RifIu2yMi673LdJABgBUTsK2fyltZg+gx4BbiYqKsTlTkbDbhjesv4/PIe1hDQzwz7tOLx0r5SaELgYjYgXeBXkAT4AYRaZJzHWPMa8aY5saY5sBjwEJjzNEcq3TyLv/HgAlBZ99yPHMeY4H7Mg7H3s+1ccE7iEvpUAfvDWnNIzzAKZfgmXY7uDKsjqVUieOLFsEVwA5jzC5jTCYwBeh/jvVvACb7YL8lz6kjuKbcyn4TxfiKI3nqqqZWJ7JcnYoRPD64Gw9n3IXtz7Xw49NWR1KqxPFFIagO7Msxneid9w8iUgroCeQ84WuAeSKyUkSGnm0nIjJURBJEJCE5OdkHsYsZY3DPuBdzKpn/8DCv3dKh2D9JtKh0alSJuu0G84mrByx7H7bMtjqSUiWKLwpBXp3azzYQcj/g11ynhdoYY2LJPrU0XETa57WhMWacMSbOGBMXHR1duMTFUcLH2LfN5uWs6/n34AFBd3H4fB7u3oA5Ve9hk6mD+7t74ESi1ZGUKjF8UQgSgZwnsmsASWdZdzC5TgsZY5K874eA6WSfagouh7bg/uFxFrkvQVrdQ+dGla1OVOw47TbevPEKHpURZKSn4/l2GHg8VsdSqkTwRSFYAdQXkToiEkL2H/v43CuJSDmgAzAjx7wIESlz5jPQHdjgg0yBIyudrGl3cMIdwvvlH+GRXo2tTlRs1Shfivuu7clzWTdh+2MxJHxkdSSlSoRCFwJjjAu4F5gLbAa+MsZsFJFhIjIsx6oDgXnGmFM55lUGlojIWmA5MMsY80NhMwUSM/8ZnMkbGeUexrM3dSbUodcFzqXHxVVwxA1hoacZ7nn/1S6lSvmAGHO20/nFV1xcnElIKAG3HOxaCJ9dxaeu7tj6vMatrWOsThQQ0jJd3Dp6Op+cvp/wGs1w3DEHbHpvpFLnIyIr8+qmr//3WCUjlazpw9ltqrC07v3c0qq21YkCRqkQB48N7sKzWbfiSFya3ZNIKXXBtBBYxDP/GewnE3lW7uG5ay8vcY+V9rcWtaOo1PY2fnTH4p7/LBzebnUkpQKWFgIr7F6MbcV4PnH1pH//QVQqE2Z1ooA0oltDPokawUm3k6zp92gvIqUukBaCopZ5iqzp9/CHqUxC3eEMaJ7nvXcqH0IcNv47uBMvuW7CuX85rP7c6khKBSQtBEXMzH8Ge8o+npJ7eHqQnhIqrMZVy1K53R0s8zQia+5/IbUE3nWulJ9pIShKe5chy8cx0dWdPn0HUaWcnhLyheFd6vN+6fsg8xSuOY9ZHUepgKOFoKi4s8iKf4ADpgK/xQzn2hY1rE5UYoQ67Nx7XW/ec/XDsXEa7PzZ6khKBRQtBEVl6Xs4D2/mec/tPHW1nhLytbiYKI7H3sduT2XSZ4yArHSrIykVMLQQFIXje3H/9BLz3C1o1vVGfaCcnzzUuxlvht5NWMoe3AtftzqOUgFDC0ERcM16hEy3h4mR93Bn2zpWxymxyoQ56T/wRr5zX4n5bQwc3W11JKUCghYCf9syC8f2H3gzaxAjBnXGaddD7k9dm1RmScz9ZLqF9Fl64Vip/NC/Sv6UkUrWzP+w2VOL1OZ3cXkQjj1shQcGduA9z9WE7ZwDOxZYHUepYk8LgR+ZxaNxpibximMoj/bWYSeLSs2oUoS3v489nsqkxT8C7iyrIylVrGkh8Jdje/D8NpZv3W3p03sA5SNCrE4UVO7s2IgPw/9FqZSduJZ+YHUcpYo1LQR+kvXDk2R6hFmVhjIoVu8ZKGphTjs9Bg7hF/eluH96CVIPWR1JqWLLJ4VARHqKyFYR2SEio/JY3lFETojIGu/rqfxuG5B2L8K59XveyerP/QM6YLPpPQNW6NioMj/HPIjNlc6p2U+dfwOlglShC4GI2IF3yR58vglwg4g0yWPVxcaY5t7XcwXcNnC4XWTMHMk+E82RZndxac1IqxMFtaGDejLJ9CR80xT4M7hGQVUqv3zRIrgC2GGM2WWMyQSmAP2LYNviadVEQo9s4g1u4aHezaxOE/SqR4aT1vohUkwpTsSXjAanUr7mi0JQHdiXYzrROy+31iKyVkTmiMjFBdw2MJw+RtaPz/O7uwmNO92k4wwUE7d3ac4njusol7QYz7b5VsdRqtjxRSHI6wR47oGQVwG1jTGXAm8D3xVg2+wVRYaKSIKIJCQnF89HDbsXvYk98zgflb6L29vWtTqO8ioV4iCm1/3s8VTm5PejwOO2OpJSxYovCkEiUDPHdA0gKecKxpgUY0yq9/NswCkiFfOzbY7vGGeMiTPGxEVHR/sgto+dSMQs+4Dp7rbccFUfQhzaIas46R9bh6mRd1Lu5HYyVnxmdRylihVf/LVaAdQXkToiEgIMBuJzriAiVcT7uE0RucK73yP52TZQZPz4PG6PYUnNYXRuVMnqOCoXm03oevVdJHgakDX/echItTqSUsVGoQuBMcYF3AvMBTYDXxljNorIMBEZ5l3tGmCDiKwFxgKDTbY8ty1spiJ3cCMhG6Yy0dWdu/t30EdMF1MtYqJYFPMApbOOkPLTG1bHUarYEGPyPCVfrMXFxZmEhASrY/wl7ZOrydqzlLeafMXT17e1Oo46h/3HT7PuzQF0tq8h9OH1UFpbbyp4iMhKY0xc7vl6Iruwdi+m1B8LGGcGcHevfxxfVcxUjwznQIuHsXsySZ79otVxlCoWtBAUhjGcmvUE+00FQtrcTaWy2l00EFzboxPxts6U3/Q55tgeq+MoZTktBIVgNs0g4vBaxtlv4F8dG1sdR+VTmTAn7naP4jLCnzOesTqOUpbTQnChPG5S5z7PNk91Gna/k4hQh9WJVAH0b38500P6UHnPd7j/DLz+CUr5khaCC+RaN40yKTuYEnET110eY3UcVUAhDhtR3R8l1YTx5/QnrY6jlKW0EFwIt4u0eS+wyVObK/vegUOHnwxI3eOaEB9xDdUP/kTGnqVWx1HKMvoX7AKcXvkFZdP2MrPCbXRpUsXqOOoCiQj1r3qUZFOWI989DgHYlVopX9BCUFCuTLIWvMQaT116DLxdbx4LcC0b1WJu1C1UO76S1E1zrY6jlCW0EBTQqWWfUjbjAIuqD+XSWuWtjqN8IO6ah9hnojk56ynweKyOo1SR00JQEFnpuH95lQRPA3r1v8nqNMpHGlWvyOIaQ6matpWjCV9ZHUepIqeFoABO/DaBslnJLK9zD/WrlLU6jvKhDoPuYZupgXv+/4HbZXUcpYqUFoL8cmViloxhhacR/fpfb3Ua5WPVo0qzqt5wojP3kfz7JKvjKFWktBDk0+FfPyUy6xCb6w+lZlQpq+MoP+gy4A42mRhY+Aq4s6yOo1SR0UKQH24XLBnNelOXnv1vtDqN8pPosmFsanQv0VlJJC36xOo4ShUZLQT5kLjkCypmJbGt4TAqlQ23Oo7yo65X3coG6uH89Q1tFaigoYXgfDwebEteZxu16Nr/NqvTKD+LjAhl18X3Ee36k70/jbc6jlJFwieFQER6ishWEdkhIqPyWH6TiKzzvn4TkUtzLNsjIutFZI2IFJ/RZrx2Lp5Mtay97G58N+UiQq2Oo4pA5343s576lFo6GlyZVsdRyu8KXQhExA68C/QCmgA3iEiTXKvtBjoYY5oBzwPjci3vZIxpntfIOVYyHg+2xW/wB9Vo1/9Oq+OoIlI6zEli8xFUdB9i548fWB1HKb/zRYvgCmCHMWaXMSYTmAL0z7mCMeY3Y8wx7+RSoIYP9ut3Gxd+TR3XTvZePIxSYdoaCCadeg9mnTSk3IoxmKzTVsdRyq98UQiqA/tyTCd6553NncCcHNMGmCciK0Vk6Nk2EpGhIpIgIgnJycmFCpwfxuPB+evrJEklrrjq337fnypewkIcHIp7mIqew2yb867VcZTyK18UgryeupbnYxxFpBPZhWBkjtltjDGxZJ9aGi4i7fPa1hgzzhgTZ4yJi46OLmzm81q7KJ6Grq0kXvxvQkN1CMpg1KHHNayxXUzF1e/iyUizOo5SfuOLQpAI1MwxXQNIyr2SiDQDJgD9jTFHzsw3xiR53w8B08k+1WQpYwy2X18nmSgu6zfc6jjKIk6HnZRW/6GCOcqWWW9bHUcpv/FFIVgB1BeROiISAgwG4nOuICK1gG+BW4wx23LMjxCRMmc+A92BDT7IVCgrF8+hWdZ6Epv8C2eo3jcQzNp0Hchq+yVUWf8enoxTVsdRyi8KXQiMMS7gXmAusBn4yhizUUSGicgw72pPARWA93J1E60MLBGRtcByYJYx5ofCZioMYwzuxaM5Thma9rvfyiiqGLDbhNTWjxBljrNl5ltWx1HKL8QE4KhMcXFxJiHBP7cc/Pr7EtrM7cOGBvfQ9MaX/LIPFVjcHsOaFzpQ17OHsiM3YQ8rbXUkpS6IiKzMq5u+3lmcgzGG1J/fIp0QGvV7yOo4qpiw24T0tiMpb06w5fs3rY6jlM9pIcjhl4R1dMr4icSYQTjK+L9nkgocrTv0ZoUjlhqbxuE+nWJ1HKV8SguBl8djODR/DHYxxPR91Oo4qpix2YTMdqMoZ06y5fvRVsdRyqe0EHgtWLODXumzOVCtO46Kda2Oo4qh1u26s9zRghqbxuPSVoEqQbQQkN0a2D3vPcrKaar2Hnn+DVRQstkEd7tHKcdJtsTrtQJVcmghAH5Yt5d+p78juWJL7DVirY6jirGW7XqwwtGCmpsnaKtAlRhBXwg8HsOGuR9TVY4S1e0/VsdRxZzNJrjbZ7cKNs3QVoEqGYK+EMxal8RVp74hpWx97A26WR1HBYCW7XqQ4GxBrS0TyNJWgSoBgroQuD2G3+ZOoZFtH6U7PQSS1/PzlPo7EcHTfiSRnGTTDO1BpAJfUBeCmeuSuCr1a06HV8F2yTVWx1EB5PK23VnpbEFtbRWoEiBoC4HbY/hh3mxa2zcR2nY4OEKsjqQCiIhgOowkkhQ2fqfXClRgC9pCEL92P31OTiPLWQZbi9usjqMCUIs23VnlbEHtrR+RmaatAhW4grIQuNwevv5xMb3sK3BcfieElbU6kgpAIoLpOJLypLBRexCpABaUhWDGmiR6pHyD2OxIq2Hn30Cps4i9sjurQloQo60CFcCCrhC43B4+W5DAdY5FSLProWxVqyOpACYiSIfsVsEGbRUof/PTsAE+KQQi0lNEtorIDhEZlcdyEZGx3uXrRCQ2v9v62vTV++mUMoMwMpA2OvCMKrzmV3ZndUgL6mz9iAxtFSh/OZEIb8fCniU+/+pCFwIRsQPvkj34fBPgBhFpkmu1XkB972so8H4BtvWZLLeHcQs2crtzPqZBT4hu6K9dqSAiIoj3WsEG7UGk/GXp+3DsD4is5fOv9kWL4ApghzFmlzEmE5gC9M+1Tn/gM5NtKRApIlXzua3PTF+1n1YpcyhnUpA2I/y1GxWELm3dnTUhsdTd9hHpp7RVoHws/QRm5af8FtaeDafK+fzrfVEIqgP7ckwneuflZ538bAuAiAwVkQQRSUhOTr6goMkpqdwb9gOmxuVQq9UFfYdSeRERbJ1GaatA+UfCJ0hmKi+c6IbT7vtLu774xryey5D7isbZ1snPttkzjRlnjIkzxsRFR1/Y6GHDK2+msvtPpM0D+jgJ5XOXtPK2CrZrq0D5kCsTz9L3+d00JaZpaxpWKePzXfiiECQCNXNM1wCS8rlOfrb1nX3LocJF0LC333ahgpeIYO80iihSWK+tAuUr66dhS/2TD7L6cH/n+n7ZhS8KwQqgvojUEZEQYDAQn2udeOBWb++hVsAJY8yBfG7rO71ehrt+Apvdb7tQwe2S1j1YGxJLPW0VKF8wBvevY9lqalP64h5+aQ2ADwqBMcYF3AvMBTYDXxljNorIMBE5c7fWbGAXsAMYD9xzrm0Lm+mcwnx/oUWpnOydHyOKFNZqq0AV1vYfsR/ewoeu3jzQtYHfduPwxZcYY2aT/cc+57wPcnw2wPD8bqtUIGvaqjvrfo6l/vaPOJ36EOGl9REm6sJkLX6Lw6YCriZX06Cyf1oDEIR3FitVFBzeVsE6bRWoC7V/Fc59v/Kxuyf3dW3s111pIVDKD5q07M760Fjq7/iItNQTVsdRAShj0VucNOGcaHQj9f3YGgAtBEr5jfOvawU6ipkqoKO7cW79ni/dXRnavbnfd6eFQCk/aeRtFTTY8bG2ClSBnF78Ni4j7G84hIsqlfb7/rQQKOVHzi6PU4ETrJmurQKVT2lHsa/9gnhPG27r2bpIdqmFQCk/anRFNzaExdJw58ecOqmtAnV+p5Z8QIgnnZ3176ButP9bA6CFQCm/C+n8WHarQHsQqfPJOg3Lx/GzuznX9e5eZLvVQqCUnzW4ojsbwmJptPMTUlP1bmN1dinLPifCdYxNdW+jTsWIItuvFgKlikDomWsF32qrQJ2Fx03W4rGs89SlT99ri3TXWgiUKgL1L+/GxrBYGu/6mJN6rUDl4cTq76iQsY+1tW4lpoiuDZyhhUCpIhLaVVsF6iyMIXXBq/xhKtO+/x1FvnstBEoVkYviurEp7DKa7P6EFG0VqByOrp9H9bQtrKh+K7Wji/7BmFoIlCpCYdoqUHk4Pu9l/jTlaTkgz2dz+p0WAqWKUN247mwKj+Xi3Z9wIkVbBQoOb1lC3dRVJFS9kZqVyluSQQuBUkUsvGv2fQWrv9W7jRUkz36JY6Y0zQc8aFmGQhUCEYkSkR9FZLv3/R/lTERqisjPIrJZRDaKyAM5lj0jIvtFZI33pWNIqhKvTovubA6PpenujzlxQlsFwezP7atonLKElVWuo0aVCxuL3RcK2yIYBSwwxtQHFninc3MBDxtjGgOtgOEi0iTH8tHGmObelw5Qo4JCeLfHqSgnWD1drxUEs/0zX+SUCaXp1Y9YmqOwhaA/MNH7eSIwIPcKxpgDxphV3s8nyR6Ssnoh96tUQIuJ7caW8MtouvsTjp84bnUcZYE92zfS/Ph81lW5miqVq1mapbCFoLJ3EHq875XOtbKIxACXActyzL5XRNaJyMd5nVrKse1QEUkQkYTk5ORCxlbKemdaBav0WkFQ2jfzJdzYaTjwMaujnL8QiMh8EdmQx6t/QXYkIqWBb4ARxpgzD1x5H6gHNAcOAG+cbXtjzDhjTJwxJi462rpzaUr5Su3Y7mwNv4xmez4h+egxq+OoIrR1xzauOD6HzZX7EVWlttVxzl8IjDFdjTFN83jNAA6KSFUA7/uhvL5DRJxkF4EvjDHf5vjug8YYtzHGA4wHrvDFj1IqUJTp+SQV5QQrv9FrBcFkd/yrOMRN3QGPWx0FKPypoXhgiPfzEGBG7hVERICPgM3GmDdzLauaY3IgsKGQeZQKKNUu7cqOiFhiEz8jMfmI1XFUEVi7fTftTsSzs1J3ylRrYHUcoPCF4GWgm4hsB7p5pxGRaiJypgdQG+AWoHMe3URfFZH1IrIO6ARY15FWKYtE9vovleS4tgqCxI7414mQDGr0e8LqKH8RY4zVGQosLi7OJCQkWB1DKZ/Z/UZnIlJ2cvLfK6hX7Zx9LlQAW7ZpF42ntuFopVbEDJ9e5PsXkZXGmLjc8/XOYqWKgaje2a0C7UFUchlj2D3zNcpKGlWvetrqOH+jhUCpYqBc407sLRdHh+QvWb/nT6vjKD9YtG4HvU99x77KXQit2dzqOH+jhUCpYqJin6eoJMdZP/2svahVgPJ4DPvmvEFZSaNKMWsNgBYCpYqNUg06kBjVmp7Hv2TZ5t1Wx1E+NCdhC1ednkFS1a44q19qdZx/0EKgVDESPeAFoiSVPd+/QiB25FD/lOFyc3De6OzWQL+nrI6TJy0EShUjobVasLdKd/qe+paFqzZZHUf5wNRFG7gm63sO1+yOrVrxaw2AFgKlip1qA/+PMMni2NyXcHu0VRDITpzO4vSiMZSVNCr2/q/Vcc5KC4FSxYyjckP2xwyid8YcZi9edv4NVLH12fwV3GxmcqJOH6jazOo4Z6WFQKliqObAZxAR+OVl0jJdVsdRF+DPE+mUWTGWcMmiXJ9nrY5zTloIlCqGpFwNjl48hN6eX/jmhwVWx1EX4JNZi7lRfiStyfVQsb7Vcc5JC4FSxVSVPk+QaS9FlZWvcehkutVxVAFsP3iSepvfwWYTSncvPs8UOhstBEoVV6WiSL/8HrrJCr6e8Z3VaVQBTIyfxyDbQlyxd0BkTavjnJcWAqWKsfKdR3DKEUnzbWPY/mfK+TdQllu66wit936A2xFOWOdHrY6TL1oIlCrOQktDh0e50raJ+OlfWJ1GnYfbY5j8XTx97MuR1sMhoqLVkfJFC4FSxVxE63+RElad3gfe47dtB62Oo87hm5X7uO7YeDJCInG2vd/qOPlWqEIgIlEi8qOIbPe+5zn4vIjs8Q5As0ZEEgq6vVJBzRFKWK/naGzby7IZ7+LRm8yKpdQMF7//8CVt7BsJ6fI4hJW1OlK+FbZFMApYYIypDyzwTp9NJ2NM81yDIhRke6WCVkizQRwt34wbUj9j+vJtVsdRefjwpy0Mz5pIerm6SNwdVscpkMIWgv7ARO/nicCAIt5eqeAgQuSA16gixzg0701OpmdZnUjlkHgsjdTfJnCRLYmwXi+A3Wl1pAIpbCGobIw5AOB9P9sYewaYJyIrRWToBWyvVNCz1W7F8Tq9udU9nY9/0EdPFCdvzUzgPtvXZNS4Ehr2sjpOgZ23EIjIfBHZkMerfwH208YYEwv0AoaLSPuCBhWRoSKSICIJycnJBd1cqRIhsu//EWpzU3nlG+xMTrU6jgIS9hzloq3jKC+phPZ+CUSsjlRg5y0ExpiuxpimebxmAAdFpCqA9/3QWb4jyft+CJgOXOFdlK/tvduOM8bEGWPioqOjC/IblSo5KtQj87I7udb2Mx9/O8vqNEHP7TF8OOMn7nDMwX3J9VCtudWRLkhhTw3FA0O8n4cAM3KvICIRIlLmzGegO7Ahv9srpf6uVNdRZDnL0CtxDD9t1vGNrTRlxV4GHP4Qm92Bo2vxHHQmPwpbCF4GuonIdqCbdxoRqSYis73rVAaWiMhaYDkwyxjzw7m2V0qdQ6koHF2eoK19Iz/P+IQMl9vqREHp6KlMFs6ZRh/7cuztHoJy1a2OdMEkEIfDi4uLMwkJCedfUamSyu0idWxrjh07xg8dZ3BX54utThR0npi2kjs23EzNck5C7lsOzjCrI52XiKzM1YUf0DuLlQpMdgelB7xBTVsyp395i/3HT1udKKis2nuM0mvGU0+SCOn7WkAUgXPRQqBUoKrTnrSL+nGXfMfYb3+yOk3QcHsMY779hQec03Fd1BMa9LA6UqFpIVAqgJXq+yJOu9Bu91jmbdQLx0Xhy+V7uebIB4TaPDh6l4zLmloIlApkkbWQtg/S176UGd9N5VSGDmvpT8knM/jlh6/pZ1+Krd2DEFXH6kg+oYVAqQBnbzeCjNI1GJHxIWPmbrQ6Ton2fzNW84SZQFbZ7AJcUmghUCrQOcMJvWo09W37CV3+DhuTTlidqESav+kg9ba8T11JwnnVW+AMtzqSz2ghUKokaNCdzIb9uNcxnbFfz8Otj6r2qZPpWXw6fRb3OL7HfclguKiL1ZF8SguBUiVESJ/XsDlCuCl5DJ8s2WV1nBLl9R828Z+MdzBhkdh7vWR1HJ/TQqBUSVG2Ko5uz9Devp7NP37MLn0onU8k7DmKLWE8zW07cfZ5FUpFWR3J57QQKFWCyOV3klXlMh63f86zX/2qp4gKKT3Lzeiv5/OIYxquet2g6SCrI/mFFgKlShKbHWf/sZSXVHofeI9Pf9tjdaKA9sbcLfz7xFhCHTYc/UYH5COm80MLgVIlTdVmyJX3c73jF5bNnczuw6esThSQlu46Qvrv42lvX4+9x/MQWdPqSH6jhUCpEkg6PYarQkOet4/j2a+W6CmiAkrNcDFm6myecH6Bu25niLvT6kh+pYVAqZLIEYpj0IdESwr9Dozlg4U7rU4UUF78fh2Pnn4LR0g49gHvldhTQmdoIVCqpKp2GdLuYQbZl7Bu/pes3nvM6kQB4actB4la/R6X2XbguGo0lK1qdSS/00KgVAkm7R/BXekSXnJO4KnJi0jVZxGd08GUdD76ajojnN/ivnhQie0llFuhCoGIRInIjyKy3ftePo91GorImhyvFBEZ4V32jIjsz7Gsd2HyKKVycYRgv/oDIm1pDE99m6e/23D+bYKU22MY+eXvPOceAxEVsfd53epIRaawLYJRwAJjTH1ggXf6b4wxW40xzY0xzYEWQBrZA9ifMfrMcmPM7NzbK6UKqUpTbJ2fpKd9BeHrPiV+bZLViYqldxZsp9/+16kjf+K4ZkKJvHHsbApbCPoDE72fJwIDzrN+F2CnMeaPQu5XKVUQV96Pp14XnnJO4tNv4tlx6KTViYqVZbuOsP+X8QyyL0E6PAp12lsdqUgVthBUNsYcAPC+VzrP+oOBybnm3Ssi60Tk47xOLZ0hIkNFJEFEEpKTkwuXWqlgY7NhG/gh9ogo3rSNYcTnv+rYBV6HUzN468t4nnN+iqt2u+xCEGTOWwhEZL6IbMjj1b8gOxKREOAqYFqO2e8D9YDmwAHgjbNtb4wZZ4yJM8bERUdHF2TXSimA0tHYB42nNge47fi7PPrNOowJ7vsLstweHvz8N57Peg17eDkc13wENrvVsYrceQuBMaarMaZpHq8ZwEERqQrgfT90jq/qBawyxhzM8d0HjTFuY4wHGA9cUbifo5Q6p7odkPaPcI19EaEbpvLJr3usTmSpF2ZuYkDSG9STJJzXToAyla2OZInCnhqKB4Z4Pw8BZpxj3RvIdVroTBHxGgholwal/K3DSEztNrwc+jEz5szi1x2HrU5kiWkJ+7At/4BB9sVIx1FQt6PVkSxT2ELwMtBNRLYD3bzTiEg1EfmrB5CIlPIu/zbX9q+KyHoRWQd0AkrO2G9KFVd2B3LtRBxlKjEh5E2enLSAHYeC65HVq/ceY/aML3jS+QWeRv2gffBdF8hJAvEcYVxcnElISLA6hlKB7cA6PB91Z4OrJg+VeoGvhnckKiLE6lR+98eRUzzw7td87nmM8OgYHP+aB6GlrY5VJERkpTEmLvd8vbNYqWBVtRm2qz+kGdu4O/Udhn2WQIbLbXUqvzp6KpPhH//MaM/LlAoLxXHj5KApAueihUCpYNakP3QYxSDbQpolTuLBqWtK7JNK07Pc3D1xKY+efJXacgj74ElQvrbVsYoFLQRKBbsOI6FJf550fkHIxq95/Nv1Ja5baabLw72TErj+wCu0t63F1vdNiGljdaxiQwuBUsHOZoOB4yCmHW+GfMjhVd/x4uzNJaYYuNweRkxZRaudo7navgQ6Pwkthpx/wyCihUApBc4wuGEyUu1SPgh9m7VLZvPGvG0BXww8HsMjX6+j1ubx/MsxB1oOg3b/sTpWsaOFQCmVLbQMctPXOCrU4bPwN/n5lx8DumWQ5fbw8LS1ONdNYpRzCjS9Bnq8VOIHmbkQWgiUUv8TUQG5ZTqhZcozrdQrLF/yI0/N2IgnwC4gp2e5uXvSKpzrJvGKcwLU6wID3s8+Dab+QY+KUurvylVHhswkvGwUX4W/zI7ls7lvymrSswKja2lKeha3f7KCats+41XneKReZ7h+EjhK/j0SF0oLgVLqn6LqILf/QEiF2nwe9hoZG2Zy4/ilHEnNsDrZOe05fIqB7/5K872f8pxzIjTqCzdMhpBSVkcr1rQQKKXyVrYqcvtsHFUvYVzoW1x0YCYD3vuVjUknrE6Wp992HmbAu0u47uTnjHRMzh5m8tpPwRFqdbRiTwuBUursSkXBrTOwxbThVft73J4+iavfW8IXy/4oNheR3R7D2AXbuX3Cr7zs+JB/8zU0vxmuHg92p9XxAoLD6gBKqWIutAzc9A3Meog7Vn9O8zJJ3Db9dn7feYTn+je19PlEScdP89BXa9i+azczy39A/dNroeNj2TfJae+gfNMWgVLq/BwhcNXb0OtVLstYwZLIZ0jauIRuby4kfm1SkbcO3B7Dp7/upvvoRdgTl7Ek8mkuytqa3QroOEqLQAFpi0AplT8i0PLfSLVYyn59O99kPsuUkOt4eHIa0xKqMLJnI5pWL+f3GEt3HeHF2ZvZlHiEVyv9yMCTXyLhteD6b6HKJX7ff0mkj6FWShXc6WMwZySsm8qR0g146NStLDxdl/7Nq3F3x3o0qlLW57tctfcYY+ZvZ+G2ZNqWTuLt0hMpf3w9XHId9H4NwiN9vs+S5myPoS5UIRCRa4FngMbAFcaYPP86i0hPYAxgByYYY84MYBMFTAVigD3AdcaYY+fbrxYCpYqJzTNh9iNwMokNFXvxwMHe7MyqQNuLKnJTy1p0alSJMOeFjwGcmuFi7oY/+WzpH6zdd5yY8NO8XX0+TfdPRcKjsgtA06t9+INKNn8VgsaAB/gQ+E9ehUBE7MA2skcoSwRWADcYYzaJyKvAUWPMyyIyCihvjBl5vv1qIVCqGMlIhcWvw+/vYYyHjVX682xyR1acjKJ0qIPOjSpxZb0KtKxbgdpRpbDZzn7+3uMxbDt0khW7j7Jo+2EWbksm0+WheQU3z1b5lWb7JiGZpyDuDujyXwgvX4Q/NPD5pRDk+PJfOHshaA08Y4zp4Z1+DMAY85KIbAU6GmMOeMcv/sUY0/B8+9NCoFQxdGI/LHoNVk/CeFwcq9aROfaOvLv/IpLSsv/4hzvtxFSMoGq5MCJCHYQ6bJzOcnMqw8X+Y6f542gamS4PANXKhvCvmEP0MwupuHsG4krPvkGs83+hUiMrf2nAOlshKIqLxdWBfTmmE4GW3s+VjTEHALzFoNLZvkREhgJDAWrVquWnqEqpC1auOvR7Czo+hiR8RNSqz7jp5M/c6IwgrWErtpaKZb2nDstPOfkjxXAq00NGlpuwEDsRIQ4aVHRyXS0XzR37aJy5jojERci2/eAIh2bXZz85tHITq39liXTeQiAi84EqeSx6whgzIx/7yKsdWOBmiDFmHDAOslsEBd1eKVVEylSGTo9n9+XfswTZHE/Ezp+I/WMBscAQAGcERFSEUO8NX6ePwZGj/PWnISwSYtpC12egYW8dTtLPzlsIjDFdC7mPRKBmjukaQJL380ERqZrj1NChQu5LKVVc2OxQt0P2CyDlABzcAIc2w8k/4VQyeFzZy8LLQ0Q0VKwPlRpDdKPs7VWRKIpTQyuA+iJSB9gPDAZu9C6LJ/sfCC973/PTwlBKBaKyVbNf9btZnUTlUqg7i0VkoIgkAq2BWSIy1zu/mojMBjDGuIB7gbnAZuArY8xG71e8DHQTke1k9yp6uTB5lFJKFZzeUKaUUkHibL2G9FlDSikV5LQQKKVUkNNCoJRSQU4LgVJKBTktBEopFeS0ECilVJALyO6jIpIM/HGBm1cEDvswTqDT4/E/eiz+To/H35WE41HbGBOde2ZAFoLCEJGEvPrRBis9Hv+jx+Lv9Hj8XUk+HnpqSCmlgpwWAqWUCnLBWAjGWR2gmNHj8T96LP5Oj8ffldjjEXTXCJRSSv1dMLYIlFJK5aCFQCmlglxQFQIR6SkiW0Vkh4iMsjqPr4jIxyJySEQ25JgXJSI/ish273v5HMse8x6DrSLSI8f8FiKy3rtsrIiId36oiEz1zl8mIjFF+gMLQERqisjPIrJZRDaKyAPe+cF6PMJEZLmIrPUej2e984PyeACIiF1EVovITO900B6LvxhjguIF2IGdQF0gBFgLNLE6l49+W3sgFtiQY96rwCjv51HAK97PTby/PRSo4z0mdu+y5WQPMiTAHKCXd/49wAfez4OBqVb/5nMci6pArPdzGWCb9zcH6/EQoLT3sxNYBrQK1uPhzfgQ8CUw0zsdtMfir2NidYAi/I/fGpibY/ox4DGrc/nw98XkKgRbgarez1WBrXn9brJHjmvtXWdLjvk3AB/mXMf72UH23ZVi9W/O53GZQfbod0F/PIBSwCqgZbAeD7LHTF8AdM5RCILyWOR8BdOpoerAvhzTid55JVVlY8wBAO97Je/8sx2H6t7Puef/bRuTPfToCaCC35L7iLdZfhnZ/woO2uPhPRWyBjgE/GiMCebj8RbwKODJMS9Yj8VfgqkQSB7zgrHv7NmOw7mOT8AdOxEpDXwDjDDGpJxr1TzmlajjYYxxG2Oak/2v4StEpOk5Vi+xx0NE+gKHjDEr87tJHvNKxLHILZgKQSJQM8d0DSDJoixF4aCIVAXwvh/yzj/bcUj0fs49/2/biIgDKAcc9VvyQhIRJ9lF4AtjzLfe2UF7PM4wxhwHfgF6EpzHow1wlYjsAaYAnUVkEsF5LP4mmArBCqC+iNQRkRCyL+TEW5zJn+KBId7PQ8g+V35m/mBv74Y6QH1gubdJfFJEWnl7QNyaa5sz33UN8JPxngQtbrzZPwI2G2PezLEoWI9HtIhEej+HA12BLQTh8TDGPGaMqWGMiSH7//+fjDE3E4TH4h+svkhRlC+gN9m9SHYCT1idx4e/azJwAMgi+18kd5J9XnIBsN37HpVj/Se8x2Ar3t4O3vlxwAbvsnf4353nYcA0YAfZvSXqWv2bz3Es2pLdFF8HrPG+egfx8WgGrPYejw3AU975QXk8cvyWjvzvYnFQHwtjjD5iQimlgl0wnRpSSimVBy0ESikV5LQQKKVUkNNCoJRSQU4LgVJKBTktBEopFeS0ECilVJD7f6TxPrlWl+uSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x,y)\n",
    "plt.plot(a[0],a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f53535e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b51a3fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.datetime(1970, 1, 1, 1, 0),\n",
       " datetime.datetime(1970, 1, 1, 1, 0, 4, 500450),\n",
       " datetime.datetime(1970, 1, 1, 1, 0, 9, 900),\n",
       " datetime.datetime(1970, 1, 1, 1, 0, 13, 501350),\n",
       " datetime.datetime(1970, 1, 1, 1, 0, 18, 1800),\n",
       " datetime.datetime(1970, 1, 1, 1, 0, 22, 502250),\n",
       " datetime.datetime(1970, 1, 1, 1, 0, 27, 2700),\n",
       " datetime.datetime(1970, 1, 1, 1, 0, 31, 503150),\n",
       " datetime.datetime(1970, 1, 1, 1, 0, 36, 3600),\n",
       " datetime.datetime(1970, 1, 1, 1, 0, 40, 504050),\n",
       " datetime.datetime(1970, 1, 1, 1, 0, 45, 4500),\n",
       " datetime.datetime(1970, 1, 1, 1, 0, 49, 504950),\n",
       " datetime.datetime(1970, 1, 1, 1, 0, 54, 5401),\n",
       " datetime.datetime(1970, 1, 1, 1, 0, 58, 505851),\n",
       " datetime.datetime(1970, 1, 1, 1, 1, 3, 6301),\n",
       " datetime.datetime(1970, 1, 1, 1, 1, 7, 506751),\n",
       " datetime.datetime(1970, 1, 1, 1, 1, 12, 7201),\n",
       " datetime.datetime(1970, 1, 1, 1, 1, 16, 507651),\n",
       " datetime.datetime(1970, 1, 1, 1, 1, 21, 8101),\n",
       " datetime.datetime(1970, 1, 1, 1, 1, 25, 508551),\n",
       " datetime.datetime(1970, 1, 1, 1, 1, 30, 9001),\n",
       " datetime.datetime(1970, 1, 1, 1, 1, 34, 509451),\n",
       " datetime.datetime(1970, 1, 1, 1, 1, 39, 9901),\n",
       " datetime.datetime(1970, 1, 1, 1, 1, 43, 510351),\n",
       " datetime.datetime(1970, 1, 1, 1, 1, 48, 10801),\n",
       " datetime.datetime(1970, 1, 1, 1, 1, 52, 511251),\n",
       " datetime.datetime(1970, 1, 1, 1, 1, 57, 11701),\n",
       " datetime.datetime(1970, 1, 1, 1, 2, 1, 512151),\n",
       " datetime.datetime(1970, 1, 1, 1, 2, 6, 12601),\n",
       " datetime.datetime(1970, 1, 1, 1, 2, 10, 513051),\n",
       " datetime.datetime(1970, 1, 1, 1, 2, 15, 13501),\n",
       " datetime.datetime(1970, 1, 1, 1, 2, 19, 513951),\n",
       " datetime.datetime(1970, 1, 1, 1, 2, 24, 14401),\n",
       " datetime.datetime(1970, 1, 1, 1, 2, 28, 514851),\n",
       " datetime.datetime(1970, 1, 1, 1, 2, 33, 15302),\n",
       " datetime.datetime(1970, 1, 1, 1, 2, 37, 515752),\n",
       " datetime.datetime(1970, 1, 1, 1, 2, 42, 16202),\n",
       " datetime.datetime(1970, 1, 1, 1, 2, 46, 516652),\n",
       " datetime.datetime(1970, 1, 1, 1, 2, 51, 17102),\n",
       " datetime.datetime(1970, 1, 1, 1, 2, 55, 517552),\n",
       " datetime.datetime(1970, 1, 1, 1, 3, 0, 18002),\n",
       " datetime.datetime(1970, 1, 1, 1, 3, 4, 518452),\n",
       " datetime.datetime(1970, 1, 1, 1, 3, 9, 18902),\n",
       " datetime.datetime(1970, 1, 1, 1, 3, 13, 519352),\n",
       " datetime.datetime(1970, 1, 1, 1, 3, 18, 19802),\n",
       " datetime.datetime(1970, 1, 1, 1, 3, 22, 520252),\n",
       " datetime.datetime(1970, 1, 1, 1, 3, 27, 20702),\n",
       " datetime.datetime(1970, 1, 1, 1, 3, 31, 521152),\n",
       " datetime.datetime(1970, 1, 1, 1, 3, 36, 21602),\n",
       " datetime.datetime(1970, 1, 1, 1, 3, 40, 522052),\n",
       " datetime.datetime(1970, 1, 1, 1, 3, 45, 22502),\n",
       " datetime.datetime(1970, 1, 1, 1, 3, 49, 522952),\n",
       " datetime.datetime(1970, 1, 1, 1, 3, 54, 23402),\n",
       " datetime.datetime(1970, 1, 1, 1, 3, 58, 523852),\n",
       " datetime.datetime(1970, 1, 1, 1, 4, 3, 24302),\n",
       " datetime.datetime(1970, 1, 1, 1, 4, 7, 524752),\n",
       " datetime.datetime(1970, 1, 1, 1, 4, 12, 25203),\n",
       " datetime.datetime(1970, 1, 1, 1, 4, 16, 525653),\n",
       " datetime.datetime(1970, 1, 1, 1, 4, 21, 26103),\n",
       " datetime.datetime(1970, 1, 1, 1, 4, 25, 526553),\n",
       " datetime.datetime(1970, 1, 1, 1, 4, 30, 27003),\n",
       " datetime.datetime(1970, 1, 1, 1, 4, 34, 527453),\n",
       " datetime.datetime(1970, 1, 1, 1, 4, 39, 27903),\n",
       " datetime.datetime(1970, 1, 1, 1, 4, 43, 528353),\n",
       " datetime.datetime(1970, 1, 1, 1, 4, 48, 28803),\n",
       " datetime.datetime(1970, 1, 1, 1, 4, 52, 529253),\n",
       " datetime.datetime(1970, 1, 1, 1, 4, 57, 29703),\n",
       " datetime.datetime(1970, 1, 1, 1, 5, 1, 530153),\n",
       " datetime.datetime(1970, 1, 1, 1, 5, 6, 30603),\n",
       " datetime.datetime(1970, 1, 1, 1, 5, 10, 531053),\n",
       " datetime.datetime(1970, 1, 1, 1, 5, 15, 31503),\n",
       " datetime.datetime(1970, 1, 1, 1, 5, 19, 531953),\n",
       " datetime.datetime(1970, 1, 1, 1, 5, 24, 32403),\n",
       " datetime.datetime(1970, 1, 1, 1, 5, 28, 532853),\n",
       " datetime.datetime(1970, 1, 1, 1, 5, 33, 33303),\n",
       " datetime.datetime(1970, 1, 1, 1, 5, 37, 533753),\n",
       " datetime.datetime(1970, 1, 1, 1, 5, 42, 34203),\n",
       " datetime.datetime(1970, 1, 1, 1, 5, 46, 534653),\n",
       " datetime.datetime(1970, 1, 1, 1, 5, 51, 35104),\n",
       " datetime.datetime(1970, 1, 1, 1, 5, 55, 535554),\n",
       " datetime.datetime(1970, 1, 1, 1, 6, 0, 36004),\n",
       " datetime.datetime(1970, 1, 1, 1, 6, 4, 536454),\n",
       " datetime.datetime(1970, 1, 1, 1, 6, 9, 36904),\n",
       " datetime.datetime(1970, 1, 1, 1, 6, 13, 537354),\n",
       " datetime.datetime(1970, 1, 1, 1, 6, 18, 37804),\n",
       " datetime.datetime(1970, 1, 1, 1, 6, 22, 538254),\n",
       " datetime.datetime(1970, 1, 1, 1, 6, 27, 38704),\n",
       " datetime.datetime(1970, 1, 1, 1, 6, 31, 539154),\n",
       " datetime.datetime(1970, 1, 1, 1, 6, 36, 39604),\n",
       " datetime.datetime(1970, 1, 1, 1, 6, 40, 540054),\n",
       " datetime.datetime(1970, 1, 1, 1, 6, 45, 40504),\n",
       " datetime.datetime(1970, 1, 1, 1, 6, 49, 540954),\n",
       " datetime.datetime(1970, 1, 1, 1, 6, 54, 41404),\n",
       " datetime.datetime(1970, 1, 1, 1, 6, 58, 541854),\n",
       " datetime.datetime(1970, 1, 1, 1, 7, 3, 42304),\n",
       " datetime.datetime(1970, 1, 1, 1, 7, 7, 542754),\n",
       " datetime.datetime(1970, 1, 1, 1, 7, 12, 43204),\n",
       " datetime.datetime(1970, 1, 1, 1, 7, 16, 543654),\n",
       " datetime.datetime(1970, 1, 1, 1, 7, 21, 44104),\n",
       " datetime.datetime(1970, 1, 1, 1, 7, 25, 544554),\n",
       " datetime.datetime(1970, 1, 1, 1, 7, 30, 45005),\n",
       " datetime.datetime(1970, 1, 1, 1, 7, 34, 545455),\n",
       " datetime.datetime(1970, 1, 1, 1, 7, 39, 45905),\n",
       " datetime.datetime(1970, 1, 1, 1, 7, 43, 546355),\n",
       " datetime.datetime(1970, 1, 1, 1, 7, 48, 46805),\n",
       " datetime.datetime(1970, 1, 1, 1, 7, 52, 547255),\n",
       " datetime.datetime(1970, 1, 1, 1, 7, 57, 47705),\n",
       " datetime.datetime(1970, 1, 1, 1, 8, 1, 548155),\n",
       " datetime.datetime(1970, 1, 1, 1, 8, 6, 48605),\n",
       " datetime.datetime(1970, 1, 1, 1, 8, 10, 549055),\n",
       " datetime.datetime(1970, 1, 1, 1, 8, 15, 49505),\n",
       " datetime.datetime(1970, 1, 1, 1, 8, 19, 549955),\n",
       " datetime.datetime(1970, 1, 1, 1, 8, 24, 50405),\n",
       " datetime.datetime(1970, 1, 1, 1, 8, 28, 550855),\n",
       " datetime.datetime(1970, 1, 1, 1, 8, 33, 51305),\n",
       " datetime.datetime(1970, 1, 1, 1, 8, 37, 551755),\n",
       " datetime.datetime(1970, 1, 1, 1, 8, 42, 52205),\n",
       " datetime.datetime(1970, 1, 1, 1, 8, 46, 552655),\n",
       " datetime.datetime(1970, 1, 1, 1, 8, 51, 53105),\n",
       " datetime.datetime(1970, 1, 1, 1, 8, 55, 553555),\n",
       " datetime.datetime(1970, 1, 1, 1, 9, 0, 54005),\n",
       " datetime.datetime(1970, 1, 1, 1, 9, 4, 554455),\n",
       " datetime.datetime(1970, 1, 1, 1, 9, 9, 54905),\n",
       " datetime.datetime(1970, 1, 1, 1, 9, 13, 555356),\n",
       " datetime.datetime(1970, 1, 1, 1, 9, 18, 55806),\n",
       " datetime.datetime(1970, 1, 1, 1, 9, 22, 556256),\n",
       " datetime.datetime(1970, 1, 1, 1, 9, 27, 56706),\n",
       " datetime.datetime(1970, 1, 1, 1, 9, 31, 557156),\n",
       " datetime.datetime(1970, 1, 1, 1, 9, 36, 57606),\n",
       " datetime.datetime(1970, 1, 1, 1, 9, 40, 558056),\n",
       " datetime.datetime(1970, 1, 1, 1, 9, 45, 58506),\n",
       " datetime.datetime(1970, 1, 1, 1, 9, 49, 558956),\n",
       " datetime.datetime(1970, 1, 1, 1, 9, 54, 59406),\n",
       " datetime.datetime(1970, 1, 1, 1, 9, 58, 559856),\n",
       " datetime.datetime(1970, 1, 1, 1, 10, 3, 60306),\n",
       " datetime.datetime(1970, 1, 1, 1, 10, 7, 560756),\n",
       " datetime.datetime(1970, 1, 1, 1, 10, 12, 61206),\n",
       " datetime.datetime(1970, 1, 1, 1, 10, 16, 561656),\n",
       " datetime.datetime(1970, 1, 1, 1, 10, 21, 62106),\n",
       " datetime.datetime(1970, 1, 1, 1, 10, 25, 562556),\n",
       " datetime.datetime(1970, 1, 1, 1, 10, 30, 63006),\n",
       " datetime.datetime(1970, 1, 1, 1, 10, 34, 563456),\n",
       " datetime.datetime(1970, 1, 1, 1, 10, 39, 63906),\n",
       " datetime.datetime(1970, 1, 1, 1, 10, 43, 564356),\n",
       " datetime.datetime(1970, 1, 1, 1, 10, 48, 64806),\n",
       " datetime.datetime(1970, 1, 1, 1, 10, 52, 565257),\n",
       " datetime.datetime(1970, 1, 1, 1, 10, 57, 65707),\n",
       " datetime.datetime(1970, 1, 1, 1, 11, 1, 566157),\n",
       " datetime.datetime(1970, 1, 1, 1, 11, 6, 66607),\n",
       " datetime.datetime(1970, 1, 1, 1, 11, 10, 567057),\n",
       " datetime.datetime(1970, 1, 1, 1, 11, 15, 67507),\n",
       " datetime.datetime(1970, 1, 1, 1, 11, 19, 567957),\n",
       " datetime.datetime(1970, 1, 1, 1, 11, 24, 68407),\n",
       " datetime.datetime(1970, 1, 1, 1, 11, 28, 568857),\n",
       " datetime.datetime(1970, 1, 1, 1, 11, 33, 69307),\n",
       " datetime.datetime(1970, 1, 1, 1, 11, 37, 569757),\n",
       " datetime.datetime(1970, 1, 1, 1, 11, 42, 70207),\n",
       " datetime.datetime(1970, 1, 1, 1, 11, 46, 570657),\n",
       " datetime.datetime(1970, 1, 1, 1, 11, 51, 71107),\n",
       " datetime.datetime(1970, 1, 1, 1, 11, 55, 571557),\n",
       " datetime.datetime(1970, 1, 1, 1, 12, 0, 72007),\n",
       " datetime.datetime(1970, 1, 1, 1, 12, 4, 572457),\n",
       " datetime.datetime(1970, 1, 1, 1, 12, 9, 72907),\n",
       " datetime.datetime(1970, 1, 1, 1, 12, 13, 573357),\n",
       " datetime.datetime(1970, 1, 1, 1, 12, 18, 73807),\n",
       " datetime.datetime(1970, 1, 1, 1, 12, 22, 574257),\n",
       " datetime.datetime(1970, 1, 1, 1, 12, 27, 74707),\n",
       " datetime.datetime(1970, 1, 1, 1, 12, 31, 575158),\n",
       " datetime.datetime(1970, 1, 1, 1, 12, 36, 75608),\n",
       " datetime.datetime(1970, 1, 1, 1, 12, 40, 576058),\n",
       " datetime.datetime(1970, 1, 1, 1, 12, 45, 76508),\n",
       " datetime.datetime(1970, 1, 1, 1, 12, 49, 576958),\n",
       " datetime.datetime(1970, 1, 1, 1, 12, 54, 77408),\n",
       " datetime.datetime(1970, 1, 1, 1, 12, 58, 577858),\n",
       " datetime.datetime(1970, 1, 1, 1, 13, 3, 78308),\n",
       " datetime.datetime(1970, 1, 1, 1, 13, 7, 578758),\n",
       " datetime.datetime(1970, 1, 1, 1, 13, 12, 79208),\n",
       " datetime.datetime(1970, 1, 1, 1, 13, 16, 579658),\n",
       " datetime.datetime(1970, 1, 1, 1, 13, 21, 80108),\n",
       " datetime.datetime(1970, 1, 1, 1, 13, 25, 580558),\n",
       " datetime.datetime(1970, 1, 1, 1, 13, 30, 81008),\n",
       " datetime.datetime(1970, 1, 1, 1, 13, 34, 581458),\n",
       " datetime.datetime(1970, 1, 1, 1, 13, 39, 81908),\n",
       " datetime.datetime(1970, 1, 1, 1, 13, 43, 582358),\n",
       " datetime.datetime(1970, 1, 1, 1, 13, 48, 82808),\n",
       " datetime.datetime(1970, 1, 1, 1, 13, 52, 583258),\n",
       " datetime.datetime(1970, 1, 1, 1, 13, 57, 83708),\n",
       " datetime.datetime(1970, 1, 1, 1, 14, 1, 584158),\n",
       " datetime.datetime(1970, 1, 1, 1, 14, 6, 84608),\n",
       " datetime.datetime(1970, 1, 1, 1, 14, 10, 585059),\n",
       " datetime.datetime(1970, 1, 1, 1, 14, 15, 85509),\n",
       " datetime.datetime(1970, 1, 1, 1, 14, 19, 585959),\n",
       " datetime.datetime(1970, 1, 1, 1, 14, 24, 86409),\n",
       " datetime.datetime(1970, 1, 1, 1, 14, 28, 586859),\n",
       " datetime.datetime(1970, 1, 1, 1, 14, 33, 87309),\n",
       " datetime.datetime(1970, 1, 1, 1, 14, 37, 587759),\n",
       " datetime.datetime(1970, 1, 1, 1, 14, 42, 88209),\n",
       " datetime.datetime(1970, 1, 1, 1, 14, 46, 588659),\n",
       " datetime.datetime(1970, 1, 1, 1, 14, 51, 89109),\n",
       " datetime.datetime(1970, 1, 1, 1, 14, 55, 589559),\n",
       " datetime.datetime(1970, 1, 1, 1, 15, 0, 90009),\n",
       " datetime.datetime(1970, 1, 1, 1, 15, 4, 590459),\n",
       " datetime.datetime(1970, 1, 1, 1, 15, 9, 90909),\n",
       " datetime.datetime(1970, 1, 1, 1, 15, 13, 591359),\n",
       " datetime.datetime(1970, 1, 1, 1, 15, 18, 91809),\n",
       " datetime.datetime(1970, 1, 1, 1, 15, 22, 592259),\n",
       " datetime.datetime(1970, 1, 1, 1, 15, 27, 92709),\n",
       " datetime.datetime(1970, 1, 1, 1, 15, 31, 593159),\n",
       " datetime.datetime(1970, 1, 1, 1, 15, 36, 93609),\n",
       " datetime.datetime(1970, 1, 1, 1, 15, 40, 594059),\n",
       " datetime.datetime(1970, 1, 1, 1, 15, 45, 94509),\n",
       " datetime.datetime(1970, 1, 1, 1, 15, 49, 594959),\n",
       " datetime.datetime(1970, 1, 1, 1, 15, 54, 95410),\n",
       " datetime.datetime(1970, 1, 1, 1, 15, 58, 595860),\n",
       " datetime.datetime(1970, 1, 1, 1, 16, 3, 96310),\n",
       " datetime.datetime(1970, 1, 1, 1, 16, 7, 596760),\n",
       " datetime.datetime(1970, 1, 1, 1, 16, 12, 97210),\n",
       " datetime.datetime(1970, 1, 1, 1, 16, 16, 597660),\n",
       " datetime.datetime(1970, 1, 1, 1, 16, 21, 98110),\n",
       " datetime.datetime(1970, 1, 1, 1, 16, 25, 598560),\n",
       " datetime.datetime(1970, 1, 1, 1, 16, 30, 99010),\n",
       " datetime.datetime(1970, 1, 1, 1, 16, 34, 599460),\n",
       " datetime.datetime(1970, 1, 1, 1, 16, 39, 99910),\n",
       " datetime.datetime(1970, 1, 1, 1, 16, 43, 600360),\n",
       " datetime.datetime(1970, 1, 1, 1, 16, 48, 100810),\n",
       " datetime.datetime(1970, 1, 1, 1, 16, 52, 601260),\n",
       " datetime.datetime(1970, 1, 1, 1, 16, 57, 101710),\n",
       " datetime.datetime(1970, 1, 1, 1, 17, 1, 602160),\n",
       " datetime.datetime(1970, 1, 1, 1, 17, 6, 102610),\n",
       " datetime.datetime(1970, 1, 1, 1, 17, 10, 603060),\n",
       " datetime.datetime(1970, 1, 1, 1, 17, 15, 103510),\n",
       " datetime.datetime(1970, 1, 1, 1, 17, 19, 603960),\n",
       " datetime.datetime(1970, 1, 1, 1, 17, 24, 104410),\n",
       " datetime.datetime(1970, 1, 1, 1, 17, 28, 604860),\n",
       " datetime.datetime(1970, 1, 1, 1, 17, 33, 105311),\n",
       " datetime.datetime(1970, 1, 1, 1, 17, 37, 605761),\n",
       " datetime.datetime(1970, 1, 1, 1, 17, 42, 106211),\n",
       " datetime.datetime(1970, 1, 1, 1, 17, 46, 606661),\n",
       " datetime.datetime(1970, 1, 1, 1, 17, 51, 107111),\n",
       " datetime.datetime(1970, 1, 1, 1, 17, 55, 607561),\n",
       " datetime.datetime(1970, 1, 1, 1, 18, 0, 108011),\n",
       " datetime.datetime(1970, 1, 1, 1, 18, 4, 608461),\n",
       " datetime.datetime(1970, 1, 1, 1, 18, 9, 108911),\n",
       " datetime.datetime(1970, 1, 1, 1, 18, 13, 609361),\n",
       " datetime.datetime(1970, 1, 1, 1, 18, 18, 109811),\n",
       " datetime.datetime(1970, 1, 1, 1, 18, 22, 610261),\n",
       " datetime.datetime(1970, 1, 1, 1, 18, 27, 110711),\n",
       " datetime.datetime(1970, 1, 1, 1, 18, 31, 611161),\n",
       " datetime.datetime(1970, 1, 1, 1, 18, 36, 111611),\n",
       " datetime.datetime(1970, 1, 1, 1, 18, 40, 612061),\n",
       " datetime.datetime(1970, 1, 1, 1, 18, 45, 112511),\n",
       " datetime.datetime(1970, 1, 1, 1, 18, 49, 612961),\n",
       " datetime.datetime(1970, 1, 1, 1, 18, 54, 113411),\n",
       " datetime.datetime(1970, 1, 1, 1, 18, 58, 613861),\n",
       " datetime.datetime(1970, 1, 1, 1, 19, 3, 114311),\n",
       " datetime.datetime(1970, 1, 1, 1, 19, 7, 614761),\n",
       " datetime.datetime(1970, 1, 1, 1, 19, 12, 115212),\n",
       " datetime.datetime(1970, 1, 1, 1, 19, 16, 615662),\n",
       " datetime.datetime(1970, 1, 1, 1, 19, 21, 116112),\n",
       " datetime.datetime(1970, 1, 1, 1, 19, 25, 616562),\n",
       " datetime.datetime(1970, 1, 1, 1, 19, 30, 117012),\n",
       " datetime.datetime(1970, 1, 1, 1, 19, 34, 617462),\n",
       " datetime.datetime(1970, 1, 1, 1, 19, 39, 117912),\n",
       " datetime.datetime(1970, 1, 1, 1, 19, 43, 618362),\n",
       " datetime.datetime(1970, 1, 1, 1, 19, 48, 118812),\n",
       " datetime.datetime(1970, 1, 1, 1, 19, 52, 619262),\n",
       " datetime.datetime(1970, 1, 1, 1, 19, 57, 119712),\n",
       " datetime.datetime(1970, 1, 1, 1, 20, 1, 620162),\n",
       " datetime.datetime(1970, 1, 1, 1, 20, 6, 120612),\n",
       " datetime.datetime(1970, 1, 1, 1, 20, 10, 621062),\n",
       " datetime.datetime(1970, 1, 1, 1, 20, 15, 121512),\n",
       " datetime.datetime(1970, 1, 1, 1, 20, 19, 621962),\n",
       " datetime.datetime(1970, 1, 1, 1, 20, 24, 122412),\n",
       " datetime.datetime(1970, 1, 1, 1, 20, 28, 622862),\n",
       " datetime.datetime(1970, 1, 1, 1, 20, 33, 123312),\n",
       " datetime.datetime(1970, 1, 1, 1, 20, 37, 623762),\n",
       " datetime.datetime(1970, 1, 1, 1, 20, 42, 124212),\n",
       " datetime.datetime(1970, 1, 1, 1, 20, 46, 624662),\n",
       " datetime.datetime(1970, 1, 1, 1, 20, 51, 125113),\n",
       " datetime.datetime(1970, 1, 1, 1, 20, 55, 625563),\n",
       " datetime.datetime(1970, 1, 1, 1, 21, 0, 126013),\n",
       " datetime.datetime(1970, 1, 1, 1, 21, 4, 626463),\n",
       " datetime.datetime(1970, 1, 1, 1, 21, 9, 126913),\n",
       " datetime.datetime(1970, 1, 1, 1, 21, 13, 627363),\n",
       " datetime.datetime(1970, 1, 1, 1, 21, 18, 127813),\n",
       " datetime.datetime(1970, 1, 1, 1, 21, 22, 628263),\n",
       " datetime.datetime(1970, 1, 1, 1, 21, 27, 128713),\n",
       " datetime.datetime(1970, 1, 1, 1, 21, 31, 629163),\n",
       " datetime.datetime(1970, 1, 1, 1, 21, 36, 129613),\n",
       " datetime.datetime(1970, 1, 1, 1, 21, 40, 630063),\n",
       " datetime.datetime(1970, 1, 1, 1, 21, 45, 130513),\n",
       " datetime.datetime(1970, 1, 1, 1, 21, 49, 630963),\n",
       " datetime.datetime(1970, 1, 1, 1, 21, 54, 131413),\n",
       " datetime.datetime(1970, 1, 1, 1, 21, 58, 631863),\n",
       " datetime.datetime(1970, 1, 1, 1, 22, 3, 132313),\n",
       " datetime.datetime(1970, 1, 1, 1, 22, 7, 632763),\n",
       " datetime.datetime(1970, 1, 1, 1, 22, 12, 133213),\n",
       " datetime.datetime(1970, 1, 1, 1, 22, 16, 633663),\n",
       " datetime.datetime(1970, 1, 1, 1, 22, 21, 134113),\n",
       " datetime.datetime(1970, 1, 1, 1, 22, 25, 634563),\n",
       " datetime.datetime(1970, 1, 1, 1, 22, 30, 135014),\n",
       " datetime.datetime(1970, 1, 1, 1, 22, 34, 635464),\n",
       " datetime.datetime(1970, 1, 1, 1, 22, 39, 135914),\n",
       " datetime.datetime(1970, 1, 1, 1, 22, 43, 636364),\n",
       " datetime.datetime(1970, 1, 1, 1, 22, 48, 136814),\n",
       " datetime.datetime(1970, 1, 1, 1, 22, 52, 637264),\n",
       " datetime.datetime(1970, 1, 1, 1, 22, 57, 137714),\n",
       " datetime.datetime(1970, 1, 1, 1, 23, 1, 638164),\n",
       " datetime.datetime(1970, 1, 1, 1, 23, 6, 138614),\n",
       " datetime.datetime(1970, 1, 1, 1, 23, 10, 639064),\n",
       " datetime.datetime(1970, 1, 1, 1, 23, 15, 139514),\n",
       " datetime.datetime(1970, 1, 1, 1, 23, 19, 639964),\n",
       " datetime.datetime(1970, 1, 1, 1, 23, 24, 140414),\n",
       " datetime.datetime(1970, 1, 1, 1, 23, 28, 640864),\n",
       " datetime.datetime(1970, 1, 1, 1, 23, 33, 141314),\n",
       " datetime.datetime(1970, 1, 1, 1, 23, 37, 641764),\n",
       " datetime.datetime(1970, 1, 1, 1, 23, 42, 142214),\n",
       " datetime.datetime(1970, 1, 1, 1, 23, 46, 642664),\n",
       " datetime.datetime(1970, 1, 1, 1, 23, 51, 143114),\n",
       " datetime.datetime(1970, 1, 1, 1, 23, 55, 643564),\n",
       " datetime.datetime(1970, 1, 1, 1, 24, 0, 144014),\n",
       " datetime.datetime(1970, 1, 1, 1, 24, 4, 644464),\n",
       " datetime.datetime(1970, 1, 1, 1, 24, 9, 144914),\n",
       " datetime.datetime(1970, 1, 1, 1, 24, 13, 645365),\n",
       " datetime.datetime(1970, 1, 1, 1, 24, 18, 145815),\n",
       " datetime.datetime(1970, 1, 1, 1, 24, 22, 646265),\n",
       " datetime.datetime(1970, 1, 1, 1, 24, 27, 146715),\n",
       " datetime.datetime(1970, 1, 1, 1, 24, 31, 647165),\n",
       " datetime.datetime(1970, 1, 1, 1, 24, 36, 147615),\n",
       " datetime.datetime(1970, 1, 1, 1, 24, 40, 648065),\n",
       " datetime.datetime(1970, 1, 1, 1, 24, 45, 148515),\n",
       " datetime.datetime(1970, 1, 1, 1, 24, 49, 648965),\n",
       " datetime.datetime(1970, 1, 1, 1, 24, 54, 149415),\n",
       " datetime.datetime(1970, 1, 1, 1, 24, 58, 649865),\n",
       " datetime.datetime(1970, 1, 1, 1, 25, 3, 150315),\n",
       " datetime.datetime(1970, 1, 1, 1, 25, 7, 650765),\n",
       " datetime.datetime(1970, 1, 1, 1, 25, 12, 151215),\n",
       " datetime.datetime(1970, 1, 1, 1, 25, 16, 651665),\n",
       " datetime.datetime(1970, 1, 1, 1, 25, 21, 152115),\n",
       " datetime.datetime(1970, 1, 1, 1, 25, 25, 652565),\n",
       " datetime.datetime(1970, 1, 1, 1, 25, 30, 153015),\n",
       " datetime.datetime(1970, 1, 1, 1, 25, 34, 653465),\n",
       " datetime.datetime(1970, 1, 1, 1, 25, 39, 153915),\n",
       " datetime.datetime(1970, 1, 1, 1, 25, 43, 654365),\n",
       " datetime.datetime(1970, 1, 1, 1, 25, 48, 154815),\n",
       " datetime.datetime(1970, 1, 1, 1, 25, 52, 655266),\n",
       " datetime.datetime(1970, 1, 1, 1, 25, 57, 155716),\n",
       " datetime.datetime(1970, 1, 1, 1, 26, 1, 656166),\n",
       " datetime.datetime(1970, 1, 1, 1, 26, 6, 156616),\n",
       " datetime.datetime(1970, 1, 1, 1, 26, 10, 657066),\n",
       " datetime.datetime(1970, 1, 1, 1, 26, 15, 157516),\n",
       " datetime.datetime(1970, 1, 1, 1, 26, 19, 657966),\n",
       " datetime.datetime(1970, 1, 1, 1, 26, 24, 158416),\n",
       " datetime.datetime(1970, 1, 1, 1, 26, 28, 658866),\n",
       " datetime.datetime(1970, 1, 1, 1, 26, 33, 159316),\n",
       " datetime.datetime(1970, 1, 1, 1, 26, 37, 659766),\n",
       " datetime.datetime(1970, 1, 1, 1, 26, 42, 160216),\n",
       " datetime.datetime(1970, 1, 1, 1, 26, 46, 660666),\n",
       " datetime.datetime(1970, 1, 1, 1, 26, 51, 161116),\n",
       " datetime.datetime(1970, 1, 1, 1, 26, 55, 661566),\n",
       " datetime.datetime(1970, 1, 1, 1, 27, 0, 162016),\n",
       " datetime.datetime(1970, 1, 1, 1, 27, 4, 662466),\n",
       " datetime.datetime(1970, 1, 1, 1, 27, 9, 162916),\n",
       " datetime.datetime(1970, 1, 1, 1, 27, 13, 663366),\n",
       " datetime.datetime(1970, 1, 1, 1, 27, 18, 163816),\n",
       " datetime.datetime(1970, 1, 1, 1, 27, 22, 664266),\n",
       " datetime.datetime(1970, 1, 1, 1, 27, 27, 164716),\n",
       " datetime.datetime(1970, 1, 1, 1, 27, 31, 665167),\n",
       " datetime.datetime(1970, 1, 1, 1, 27, 36, 165617),\n",
       " datetime.datetime(1970, 1, 1, 1, 27, 40, 666067),\n",
       " datetime.datetime(1970, 1, 1, 1, 27, 45, 166517),\n",
       " datetime.datetime(1970, 1, 1, 1, 27, 49, 666967),\n",
       " datetime.datetime(1970, 1, 1, 1, 27, 54, 167417),\n",
       " datetime.datetime(1970, 1, 1, 1, 27, 58, 667867),\n",
       " datetime.datetime(1970, 1, 1, 1, 28, 3, 168317),\n",
       " datetime.datetime(1970, 1, 1, 1, 28, 7, 668767),\n",
       " datetime.datetime(1970, 1, 1, 1, 28, 12, 169217),\n",
       " datetime.datetime(1970, 1, 1, 1, 28, 16, 669667),\n",
       " datetime.datetime(1970, 1, 1, 1, 28, 21, 170117),\n",
       " datetime.datetime(1970, 1, 1, 1, 28, 25, 670567),\n",
       " datetime.datetime(1970, 1, 1, 1, 28, 30, 171017),\n",
       " datetime.datetime(1970, 1, 1, 1, 28, 34, 671467),\n",
       " datetime.datetime(1970, 1, 1, 1, 28, 39, 171917),\n",
       " datetime.datetime(1970, 1, 1, 1, 28, 43, 672367),\n",
       " datetime.datetime(1970, 1, 1, 1, 28, 48, 172817),\n",
       " datetime.datetime(1970, 1, 1, 1, 28, 52, 673267),\n",
       " datetime.datetime(1970, 1, 1, 1, 28, 57, 173717),\n",
       " datetime.datetime(1970, 1, 1, 1, 29, 1, 674167),\n",
       " datetime.datetime(1970, 1, 1, 1, 29, 6, 174617),\n",
       " datetime.datetime(1970, 1, 1, 1, 29, 10, 675068),\n",
       " datetime.datetime(1970, 1, 1, 1, 29, 15, 175518),\n",
       " datetime.datetime(1970, 1, 1, 1, 29, 19, 675968),\n",
       " datetime.datetime(1970, 1, 1, 1, 29, 24, 176418),\n",
       " datetime.datetime(1970, 1, 1, 1, 29, 28, 676868),\n",
       " datetime.datetime(1970, 1, 1, 1, 29, 33, 177318),\n",
       " datetime.datetime(1970, 1, 1, 1, 29, 37, 677768),\n",
       " datetime.datetime(1970, 1, 1, 1, 29, 42, 178218),\n",
       " datetime.datetime(1970, 1, 1, 1, 29, 46, 678668),\n",
       " datetime.datetime(1970, 1, 1, 1, 29, 51, 179118),\n",
       " datetime.datetime(1970, 1, 1, 1, 29, 55, 679568),\n",
       " datetime.datetime(1970, 1, 1, 1, 30, 0, 180018),\n",
       " datetime.datetime(1970, 1, 1, 1, 30, 4, 680468),\n",
       " datetime.datetime(1970, 1, 1, 1, 30, 9, 180918),\n",
       " datetime.datetime(1970, 1, 1, 1, 30, 13, 681368),\n",
       " datetime.datetime(1970, 1, 1, 1, 30, 18, 181818),\n",
       " datetime.datetime(1970, 1, 1, 1, 30, 22, 682268),\n",
       " datetime.datetime(1970, 1, 1, 1, 30, 27, 182718),\n",
       " datetime.datetime(1970, 1, 1, 1, 30, 31, 683168),\n",
       " datetime.datetime(1970, 1, 1, 1, 30, 36, 183618),\n",
       " datetime.datetime(1970, 1, 1, 1, 30, 40, 684068),\n",
       " datetime.datetime(1970, 1, 1, 1, 30, 45, 184518),\n",
       " datetime.datetime(1970, 1, 1, 1, 30, 49, 684968),\n",
       " datetime.datetime(1970, 1, 1, 1, 30, 54, 185419),\n",
       " datetime.datetime(1970, 1, 1, 1, 30, 58, 685869),\n",
       " datetime.datetime(1970, 1, 1, 1, 31, 3, 186319),\n",
       " datetime.datetime(1970, 1, 1, 1, 31, 7, 686769),\n",
       " datetime.datetime(1970, 1, 1, 1, 31, 12, 187219),\n",
       " datetime.datetime(1970, 1, 1, 1, 31, 16, 687669),\n",
       " datetime.datetime(1970, 1, 1, 1, 31, 21, 188119),\n",
       " datetime.datetime(1970, 1, 1, 1, 31, 25, 688569),\n",
       " datetime.datetime(1970, 1, 1, 1, 31, 30, 189019),\n",
       " datetime.datetime(1970, 1, 1, 1, 31, 34, 689469),\n",
       " datetime.datetime(1970, 1, 1, 1, 31, 39, 189919),\n",
       " datetime.datetime(1970, 1, 1, 1, 31, 43, 690369),\n",
       " datetime.datetime(1970, 1, 1, 1, 31, 48, 190819),\n",
       " datetime.datetime(1970, 1, 1, 1, 31, 52, 691269),\n",
       " datetime.datetime(1970, 1, 1, 1, 31, 57, 191719),\n",
       " datetime.datetime(1970, 1, 1, 1, 32, 1, 692169),\n",
       " datetime.datetime(1970, 1, 1, 1, 32, 6, 192619),\n",
       " datetime.datetime(1970, 1, 1, 1, 32, 10, 693069),\n",
       " datetime.datetime(1970, 1, 1, 1, 32, 15, 193519),\n",
       " datetime.datetime(1970, 1, 1, 1, 32, 19, 693969),\n",
       " datetime.datetime(1970, 1, 1, 1, 32, 24, 194419),\n",
       " datetime.datetime(1970, 1, 1, 1, 32, 28, 694869),\n",
       " datetime.datetime(1970, 1, 1, 1, 32, 33, 195320),\n",
       " datetime.datetime(1970, 1, 1, 1, 32, 37, 695770),\n",
       " datetime.datetime(1970, 1, 1, 1, 32, 42, 196220),\n",
       " datetime.datetime(1970, 1, 1, 1, 32, 46, 696670),\n",
       " datetime.datetime(1970, 1, 1, 1, 32, 51, 197120),\n",
       " datetime.datetime(1970, 1, 1, 1, 32, 55, 697570),\n",
       " datetime.datetime(1970, 1, 1, 1, 33, 0, 198020),\n",
       " datetime.datetime(1970, 1, 1, 1, 33, 4, 698470),\n",
       " datetime.datetime(1970, 1, 1, 1, 33, 9, 198920),\n",
       " datetime.datetime(1970, 1, 1, 1, 33, 13, 699370),\n",
       " datetime.datetime(1970, 1, 1, 1, 33, 18, 199820),\n",
       " datetime.datetime(1970, 1, 1, 1, 33, 22, 700270),\n",
       " datetime.datetime(1970, 1, 1, 1, 33, 27, 200720),\n",
       " datetime.datetime(1970, 1, 1, 1, 33, 31, 701170),\n",
       " datetime.datetime(1970, 1, 1, 1, 33, 36, 201620),\n",
       " datetime.datetime(1970, 1, 1, 1, 33, 40, 702070),\n",
       " datetime.datetime(1970, 1, 1, 1, 33, 45, 202520),\n",
       " datetime.datetime(1970, 1, 1, 1, 33, 49, 702970),\n",
       " datetime.datetime(1970, 1, 1, 1, 33, 54, 203420),\n",
       " datetime.datetime(1970, 1, 1, 1, 33, 58, 703870),\n",
       " datetime.datetime(1970, 1, 1, 1, 34, 3, 204320),\n",
       " datetime.datetime(1970, 1, 1, 1, 34, 7, 704770),\n",
       " datetime.datetime(1970, 1, 1, 1, 34, 12, 205221),\n",
       " datetime.datetime(1970, 1, 1, 1, 34, 16, 705671),\n",
       " datetime.datetime(1970, 1, 1, 1, 34, 21, 206121),\n",
       " datetime.datetime(1970, 1, 1, 1, 34, 25, 706571),\n",
       " datetime.datetime(1970, 1, 1, 1, 34, 30, 207021),\n",
       " datetime.datetime(1970, 1, 1, 1, 34, 34, 707471),\n",
       " datetime.datetime(1970, 1, 1, 1, 34, 39, 207921),\n",
       " datetime.datetime(1970, 1, 1, 1, 34, 43, 708371),\n",
       " datetime.datetime(1970, 1, 1, 1, 34, 48, 208821),\n",
       " datetime.datetime(1970, 1, 1, 1, 34, 52, 709271),\n",
       " datetime.datetime(1970, 1, 1, 1, 34, 57, 209721),\n",
       " datetime.datetime(1970, 1, 1, 1, 35, 1, 710171),\n",
       " datetime.datetime(1970, 1, 1, 1, 35, 6, 210621),\n",
       " datetime.datetime(1970, 1, 1, 1, 35, 10, 711071),\n",
       " datetime.datetime(1970, 1, 1, 1, 35, 15, 211521),\n",
       " datetime.datetime(1970, 1, 1, 1, 35, 19, 711971),\n",
       " datetime.datetime(1970, 1, 1, 1, 35, 24, 212421),\n",
       " datetime.datetime(1970, 1, 1, 1, 35, 28, 712871),\n",
       " datetime.datetime(1970, 1, 1, 1, 35, 33, 213321),\n",
       " datetime.datetime(1970, 1, 1, 1, 35, 37, 713771),\n",
       " datetime.datetime(1970, 1, 1, 1, 35, 42, 214221),\n",
       " datetime.datetime(1970, 1, 1, 1, 35, 46, 714671),\n",
       " datetime.datetime(1970, 1, 1, 1, 35, 51, 215122),\n",
       " datetime.datetime(1970, 1, 1, 1, 35, 55, 715572),\n",
       " datetime.datetime(1970, 1, 1, 1, 36, 0, 216022),\n",
       " datetime.datetime(1970, 1, 1, 1, 36, 4, 716472),\n",
       " datetime.datetime(1970, 1, 1, 1, 36, 9, 216922),\n",
       " datetime.datetime(1970, 1, 1, 1, 36, 13, 717372),\n",
       " datetime.datetime(1970, 1, 1, 1, 36, 18, 217822),\n",
       " datetime.datetime(1970, 1, 1, 1, 36, 22, 718272),\n",
       " datetime.datetime(1970, 1, 1, 1, 36, 27, 218722),\n",
       " datetime.datetime(1970, 1, 1, 1, 36, 31, 719172),\n",
       " datetime.datetime(1970, 1, 1, 1, 36, 36, 219622),\n",
       " datetime.datetime(1970, 1, 1, 1, 36, 40, 720072),\n",
       " datetime.datetime(1970, 1, 1, 1, 36, 45, 220522),\n",
       " datetime.datetime(1970, 1, 1, 1, 36, 49, 720972),\n",
       " datetime.datetime(1970, 1, 1, 1, 36, 54, 221422),\n",
       " datetime.datetime(1970, 1, 1, 1, 36, 58, 721872),\n",
       " datetime.datetime(1970, 1, 1, 1, 37, 3, 222322),\n",
       " datetime.datetime(1970, 1, 1, 1, 37, 7, 722772),\n",
       " datetime.datetime(1970, 1, 1, 1, 37, 12, 223222),\n",
       " datetime.datetime(1970, 1, 1, 1, 37, 16, 723672),\n",
       " datetime.datetime(1970, 1, 1, 1, 37, 21, 224122),\n",
       " datetime.datetime(1970, 1, 1, 1, 37, 25, 724572),\n",
       " datetime.datetime(1970, 1, 1, 1, 37, 30, 225023),\n",
       " datetime.datetime(1970, 1, 1, 1, 37, 34, 725473),\n",
       " datetime.datetime(1970, 1, 1, 1, 37, 39, 225923),\n",
       " datetime.datetime(1970, 1, 1, 1, 37, 43, 726373),\n",
       " datetime.datetime(1970, 1, 1, 1, 37, 48, 226823),\n",
       " datetime.datetime(1970, 1, 1, 1, 37, 52, 727273),\n",
       " datetime.datetime(1970, 1, 1, 1, 37, 57, 227723),\n",
       " datetime.datetime(1970, 1, 1, 1, 38, 1, 728173),\n",
       " datetime.datetime(1970, 1, 1, 1, 38, 6, 228623),\n",
       " datetime.datetime(1970, 1, 1, 1, 38, 10, 729073),\n",
       " datetime.datetime(1970, 1, 1, 1, 38, 15, 229523),\n",
       " datetime.datetime(1970, 1, 1, 1, 38, 19, 729973),\n",
       " datetime.datetime(1970, 1, 1, 1, 38, 24, 230423),\n",
       " datetime.datetime(1970, 1, 1, 1, 38, 28, 730873),\n",
       " datetime.datetime(1970, 1, 1, 1, 38, 33, 231323),\n",
       " datetime.datetime(1970, 1, 1, 1, 38, 37, 731773),\n",
       " datetime.datetime(1970, 1, 1, 1, 38, 42, 232223),\n",
       " datetime.datetime(1970, 1, 1, 1, 38, 46, 732673),\n",
       " datetime.datetime(1970, 1, 1, 1, 38, 51, 233123),\n",
       " datetime.datetime(1970, 1, 1, 1, 38, 55, 733573),\n",
       " datetime.datetime(1970, 1, 1, 1, 39, 0, 234023),\n",
       " datetime.datetime(1970, 1, 1, 1, 39, 4, 734473),\n",
       " datetime.datetime(1970, 1, 1, 1, 39, 9, 234923),\n",
       " datetime.datetime(1970, 1, 1, 1, 39, 13, 735374),\n",
       " datetime.datetime(1970, 1, 1, 1, 39, 18, 235824),\n",
       " datetime.datetime(1970, 1, 1, 1, 39, 22, 736274),\n",
       " datetime.datetime(1970, 1, 1, 1, 39, 27, 236724),\n",
       " datetime.datetime(1970, 1, 1, 1, 39, 31, 737174),\n",
       " datetime.datetime(1970, 1, 1, 1, 39, 36, 237624),\n",
       " datetime.datetime(1970, 1, 1, 1, 39, 40, 738074),\n",
       " datetime.datetime(1970, 1, 1, 1, 39, 45, 238524),\n",
       " datetime.datetime(1970, 1, 1, 1, 39, 49, 738974),\n",
       " datetime.datetime(1970, 1, 1, 1, 39, 54, 239424),\n",
       " datetime.datetime(1970, 1, 1, 1, 39, 58, 739874),\n",
       " datetime.datetime(1970, 1, 1, 1, 40, 3, 240324),\n",
       " datetime.datetime(1970, 1, 1, 1, 40, 7, 740774),\n",
       " datetime.datetime(1970, 1, 1, 1, 40, 12, 241224),\n",
       " datetime.datetime(1970, 1, 1, 1, 40, 16, 741674),\n",
       " datetime.datetime(1970, 1, 1, 1, 40, 21, 242124),\n",
       " datetime.datetime(1970, 1, 1, 1, 40, 25, 742574),\n",
       " datetime.datetime(1970, 1, 1, 1, 40, 30, 243024),\n",
       " datetime.datetime(1970, 1, 1, 1, 40, 34, 743474),\n",
       " datetime.datetime(1970, 1, 1, 1, 40, 39, 243924),\n",
       " datetime.datetime(1970, 1, 1, 1, 40, 43, 744374),\n",
       " datetime.datetime(1970, 1, 1, 1, 40, 48, 244824),\n",
       " datetime.datetime(1970, 1, 1, 1, 40, 52, 745275),\n",
       " datetime.datetime(1970, 1, 1, 1, 40, 57, 245725),\n",
       " datetime.datetime(1970, 1, 1, 1, 41, 1, 746175),\n",
       " datetime.datetime(1970, 1, 1, 1, 41, 6, 246625),\n",
       " datetime.datetime(1970, 1, 1, 1, 41, 10, 747075),\n",
       " datetime.datetime(1970, 1, 1, 1, 41, 15, 247525),\n",
       " datetime.datetime(1970, 1, 1, 1, 41, 19, 747975),\n",
       " datetime.datetime(1970, 1, 1, 1, 41, 24, 248425),\n",
       " datetime.datetime(1970, 1, 1, 1, 41, 28, 748875),\n",
       " datetime.datetime(1970, 1, 1, 1, 41, 33, 249325),\n",
       " datetime.datetime(1970, 1, 1, 1, 41, 37, 749775),\n",
       " datetime.datetime(1970, 1, 1, 1, 41, 42, 250225),\n",
       " datetime.datetime(1970, 1, 1, 1, 41, 46, 750675),\n",
       " datetime.datetime(1970, 1, 1, 1, 41, 51, 251125),\n",
       " datetime.datetime(1970, 1, 1, 1, 41, 55, 751575),\n",
       " datetime.datetime(1970, 1, 1, 1, 42, 0, 252025),\n",
       " datetime.datetime(1970, 1, 1, 1, 42, 4, 752475),\n",
       " datetime.datetime(1970, 1, 1, 1, 42, 9, 252925),\n",
       " datetime.datetime(1970, 1, 1, 1, 42, 13, 753375),\n",
       " datetime.datetime(1970, 1, 1, 1, 42, 18, 253825),\n",
       " datetime.datetime(1970, 1, 1, 1, 42, 22, 754275),\n",
       " datetime.datetime(1970, 1, 1, 1, 42, 27, 254725),\n",
       " datetime.datetime(1970, 1, 1, 1, 42, 31, 755176),\n",
       " datetime.datetime(1970, 1, 1, 1, 42, 36, 255626),\n",
       " datetime.datetime(1970, 1, 1, 1, 42, 40, 756076),\n",
       " datetime.datetime(1970, 1, 1, 1, 42, 45, 256526),\n",
       " datetime.datetime(1970, 1, 1, 1, 42, 49, 756976),\n",
       " datetime.datetime(1970, 1, 1, 1, 42, 54, 257426),\n",
       " datetime.datetime(1970, 1, 1, 1, 42, 58, 757876),\n",
       " datetime.datetime(1970, 1, 1, 1, 43, 3, 258326),\n",
       " datetime.datetime(1970, 1, 1, 1, 43, 7, 758776),\n",
       " datetime.datetime(1970, 1, 1, 1, 43, 12, 259226),\n",
       " datetime.datetime(1970, 1, 1, 1, 43, 16, 759676),\n",
       " datetime.datetime(1970, 1, 1, 1, 43, 21, 260126),\n",
       " datetime.datetime(1970, 1, 1, 1, 43, 25, 760576),\n",
       " datetime.datetime(1970, 1, 1, 1, 43, 30, 261026),\n",
       " datetime.datetime(1970, 1, 1, 1, 43, 34, 761476),\n",
       " datetime.datetime(1970, 1, 1, 1, 43, 39, 261926),\n",
       " datetime.datetime(1970, 1, 1, 1, 43, 43, 762376),\n",
       " datetime.datetime(1970, 1, 1, 1, 43, 48, 262826),\n",
       " datetime.datetime(1970, 1, 1, 1, 43, 52, 763276),\n",
       " datetime.datetime(1970, 1, 1, 1, 43, 57, 263726),\n",
       " datetime.datetime(1970, 1, 1, 1, 44, 1, 764176),\n",
       " datetime.datetime(1970, 1, 1, 1, 44, 6, 264626),\n",
       " datetime.datetime(1970, 1, 1, 1, 44, 10, 765077),\n",
       " datetime.datetime(1970, 1, 1, 1, 44, 15, 265527),\n",
       " datetime.datetime(1970, 1, 1, 1, 44, 19, 765977),\n",
       " datetime.datetime(1970, 1, 1, 1, 44, 24, 266427),\n",
       " datetime.datetime(1970, 1, 1, 1, 44, 28, 766877),\n",
       " datetime.datetime(1970, 1, 1, 1, 44, 33, 267327),\n",
       " datetime.datetime(1970, 1, 1, 1, 44, 37, 767777),\n",
       " datetime.datetime(1970, 1, 1, 1, 44, 42, 268227),\n",
       " datetime.datetime(1970, 1, 1, 1, 44, 46, 768677),\n",
       " datetime.datetime(1970, 1, 1, 1, 44, 51, 269127),\n",
       " datetime.datetime(1970, 1, 1, 1, 44, 55, 769577),\n",
       " datetime.datetime(1970, 1, 1, 1, 45, 0, 270027),\n",
       " datetime.datetime(1970, 1, 1, 1, 45, 4, 770477),\n",
       " datetime.datetime(1970, 1, 1, 1, 45, 9, 270927),\n",
       " datetime.datetime(1970, 1, 1, 1, 45, 13, 771377),\n",
       " datetime.datetime(1970, 1, 1, 1, 45, 18, 271827),\n",
       " datetime.datetime(1970, 1, 1, 1, 45, 22, 772277),\n",
       " datetime.datetime(1970, 1, 1, 1, 45, 27, 272727),\n",
       " datetime.datetime(1970, 1, 1, 1, 45, 31, 773177),\n",
       " datetime.datetime(1970, 1, 1, 1, 45, 36, 273627),\n",
       " datetime.datetime(1970, 1, 1, 1, 45, 40, 774077),\n",
       " datetime.datetime(1970, 1, 1, 1, 45, 45, 274527),\n",
       " datetime.datetime(1970, 1, 1, 1, 45, 49, 774977),\n",
       " datetime.datetime(1970, 1, 1, 1, 45, 54, 275428),\n",
       " datetime.datetime(1970, 1, 1, 1, 45, 58, 775878),\n",
       " datetime.datetime(1970, 1, 1, 1, 46, 3, 276328),\n",
       " datetime.datetime(1970, 1, 1, 1, 46, 7, 776778),\n",
       " datetime.datetime(1970, 1, 1, 1, 46, 12, 277228),\n",
       " datetime.datetime(1970, 1, 1, 1, 46, 16, 777678),\n",
       " datetime.datetime(1970, 1, 1, 1, 46, 21, 278128),\n",
       " datetime.datetime(1970, 1, 1, 1, 46, 25, 778578),\n",
       " datetime.datetime(1970, 1, 1, 1, 46, 30, 279028),\n",
       " datetime.datetime(1970, 1, 1, 1, 46, 34, 779478),\n",
       " datetime.datetime(1970, 1, 1, 1, 46, 39, 279928),\n",
       " datetime.datetime(1970, 1, 1, 1, 46, 43, 780378),\n",
       " datetime.datetime(1970, 1, 1, 1, 46, 48, 280828),\n",
       " datetime.datetime(1970, 1, 1, 1, 46, 52, 781278),\n",
       " datetime.datetime(1970, 1, 1, 1, 46, 57, 281728),\n",
       " datetime.datetime(1970, 1, 1, 1, 47, 1, 782178),\n",
       " datetime.datetime(1970, 1, 1, 1, 47, 6, 282628),\n",
       " datetime.datetime(1970, 1, 1, 1, 47, 10, 783078),\n",
       " datetime.datetime(1970, 1, 1, 1, 47, 15, 283528),\n",
       " datetime.datetime(1970, 1, 1, 1, 47, 19, 783978),\n",
       " datetime.datetime(1970, 1, 1, 1, 47, 24, 284428),\n",
       " datetime.datetime(1970, 1, 1, 1, 47, 28, 784878),\n",
       " datetime.datetime(1970, 1, 1, 1, 47, 33, 285329),\n",
       " datetime.datetime(1970, 1, 1, 1, 47, 37, 785779),\n",
       " datetime.datetime(1970, 1, 1, 1, 47, 42, 286229),\n",
       " datetime.datetime(1970, 1, 1, 1, 47, 46, 786679),\n",
       " datetime.datetime(1970, 1, 1, 1, 47, 51, 287129),\n",
       " datetime.datetime(1970, 1, 1, 1, 47, 55, 787579),\n",
       " datetime.datetime(1970, 1, 1, 1, 48, 0, 288029),\n",
       " datetime.datetime(1970, 1, 1, 1, 48, 4, 788479),\n",
       " datetime.datetime(1970, 1, 1, 1, 48, 9, 288929),\n",
       " datetime.datetime(1970, 1, 1, 1, 48, 13, 789379),\n",
       " datetime.datetime(1970, 1, 1, 1, 48, 18, 289829),\n",
       " datetime.datetime(1970, 1, 1, 1, 48, 22, 790279),\n",
       " datetime.datetime(1970, 1, 1, 1, 48, 27, 290729),\n",
       " datetime.datetime(1970, 1, 1, 1, 48, 31, 791179),\n",
       " datetime.datetime(1970, 1, 1, 1, 48, 36, 291629),\n",
       " datetime.datetime(1970, 1, 1, 1, 48, 40, 792079),\n",
       " datetime.datetime(1970, 1, 1, 1, 48, 45, 292529),\n",
       " datetime.datetime(1970, 1, 1, 1, 48, 49, 792979),\n",
       " datetime.datetime(1970, 1, 1, 1, 48, 54, 293429),\n",
       " datetime.datetime(1970, 1, 1, 1, 48, 58, 793879),\n",
       " datetime.datetime(1970, 1, 1, 1, 49, 3, 294329),\n",
       " datetime.datetime(1970, 1, 1, 1, 49, 7, 794779),\n",
       " datetime.datetime(1970, 1, 1, 1, 49, 12, 295230),\n",
       " datetime.datetime(1970, 1, 1, 1, 49, 16, 795680),\n",
       " datetime.datetime(1970, 1, 1, 1, 49, 21, 296130),\n",
       " datetime.datetime(1970, 1, 1, 1, 49, 25, 796580),\n",
       " datetime.datetime(1970, 1, 1, 1, 49, 30, 297030),\n",
       " datetime.datetime(1970, 1, 1, 1, 49, 34, 797480),\n",
       " datetime.datetime(1970, 1, 1, 1, 49, 39, 297930),\n",
       " datetime.datetime(1970, 1, 1, 1, 49, 43, 798380),\n",
       " datetime.datetime(1970, 1, 1, 1, 49, 48, 298830),\n",
       " datetime.datetime(1970, 1, 1, 1, 49, 52, 799280),\n",
       " datetime.datetime(1970, 1, 1, 1, 49, 57, 299730),\n",
       " datetime.datetime(1970, 1, 1, 1, 50, 1, 800180),\n",
       " datetime.datetime(1970, 1, 1, 1, 50, 6, 300630),\n",
       " datetime.datetime(1970, 1, 1, 1, 50, 10, 801080),\n",
       " datetime.datetime(1970, 1, 1, 1, 50, 15, 301530),\n",
       " datetime.datetime(1970, 1, 1, 1, 50, 19, 801980),\n",
       " datetime.datetime(1970, 1, 1, 1, 50, 24, 302430),\n",
       " datetime.datetime(1970, 1, 1, 1, 50, 28, 802880),\n",
       " datetime.datetime(1970, 1, 1, 1, 50, 33, 303330),\n",
       " datetime.datetime(1970, 1, 1, 1, 50, 37, 803780),\n",
       " datetime.datetime(1970, 1, 1, 1, 50, 42, 304230),\n",
       " datetime.datetime(1970, 1, 1, 1, 50, 46, 804680),\n",
       " datetime.datetime(1970, 1, 1, 1, 50, 51, 305131),\n",
       " datetime.datetime(1970, 1, 1, 1, 50, 55, 805581),\n",
       " datetime.datetime(1970, 1, 1, 1, 51, 0, 306031),\n",
       " datetime.datetime(1970, 1, 1, 1, 51, 4, 806481),\n",
       " datetime.datetime(1970, 1, 1, 1, 51, 9, 306931),\n",
       " datetime.datetime(1970, 1, 1, 1, 51, 13, 807381),\n",
       " datetime.datetime(1970, 1, 1, 1, 51, 18, 307831),\n",
       " datetime.datetime(1970, 1, 1, 1, 51, 22, 808281),\n",
       " datetime.datetime(1970, 1, 1, 1, 51, 27, 308731),\n",
       " datetime.datetime(1970, 1, 1, 1, 51, 31, 809181),\n",
       " datetime.datetime(1970, 1, 1, 1, 51, 36, 309631),\n",
       " datetime.datetime(1970, 1, 1, 1, 51, 40, 810081),\n",
       " datetime.datetime(1970, 1, 1, 1, 51, 45, 310531),\n",
       " datetime.datetime(1970, 1, 1, 1, 51, 49, 810981),\n",
       " datetime.datetime(1970, 1, 1, 1, 51, 54, 311431),\n",
       " datetime.datetime(1970, 1, 1, 1, 51, 58, 811881),\n",
       " datetime.datetime(1970, 1, 1, 1, 52, 3, 312331),\n",
       " datetime.datetime(1970, 1, 1, 1, 52, 7, 812781),\n",
       " datetime.datetime(1970, 1, 1, 1, 52, 12, 313231),\n",
       " datetime.datetime(1970, 1, 1, 1, 52, 16, 813681),\n",
       " datetime.datetime(1970, 1, 1, 1, 52, 21, 314131),\n",
       " datetime.datetime(1970, 1, 1, 1, 52, 25, 814581),\n",
       " datetime.datetime(1970, 1, 1, 1, 52, 30, 315032),\n",
       " datetime.datetime(1970, 1, 1, 1, 52, 34, 815482),\n",
       " datetime.datetime(1970, 1, 1, 1, 52, 39, 315932),\n",
       " datetime.datetime(1970, 1, 1, 1, 52, 43, 816382),\n",
       " datetime.datetime(1970, 1, 1, 1, 52, 48, 316832),\n",
       " datetime.datetime(1970, 1, 1, 1, 52, 52, 817282),\n",
       " datetime.datetime(1970, 1, 1, 1, 52, 57, 317732),\n",
       " datetime.datetime(1970, 1, 1, 1, 53, 1, 818182),\n",
       " datetime.datetime(1970, 1, 1, 1, 53, 6, 318632),\n",
       " datetime.datetime(1970, 1, 1, 1, 53, 10, 819082),\n",
       " datetime.datetime(1970, 1, 1, 1, 53, 15, 319532),\n",
       " datetime.datetime(1970, 1, 1, 1, 53, 19, 819982),\n",
       " datetime.datetime(1970, 1, 1, 1, 53, 24, 320432),\n",
       " datetime.datetime(1970, 1, 1, 1, 53, 28, 820882),\n",
       " datetime.datetime(1970, 1, 1, 1, 53, 33, 321332),\n",
       " datetime.datetime(1970, 1, 1, 1, 53, 37, 821782),\n",
       " datetime.datetime(1970, 1, 1, 1, 53, 42, 322232),\n",
       " datetime.datetime(1970, 1, 1, 1, 53, 46, 822682),\n",
       " datetime.datetime(1970, 1, 1, 1, 53, 51, 323132),\n",
       " datetime.datetime(1970, 1, 1, 1, 53, 55, 823582),\n",
       " datetime.datetime(1970, 1, 1, 1, 54, 0, 324032),\n",
       " datetime.datetime(1970, 1, 1, 1, 54, 4, 824482),\n",
       " datetime.datetime(1970, 1, 1, 1, 54, 9, 324932),\n",
       " datetime.datetime(1970, 1, 1, 1, 54, 13, 825383),\n",
       " datetime.datetime(1970, 1, 1, 1, 54, 18, 325833),\n",
       " datetime.datetime(1970, 1, 1, 1, 54, 22, 826283),\n",
       " datetime.datetime(1970, 1, 1, 1, 54, 27, 326733),\n",
       " datetime.datetime(1970, 1, 1, 1, 54, 31, 827183),\n",
       " datetime.datetime(1970, 1, 1, 1, 54, 36, 327633),\n",
       " datetime.datetime(1970, 1, 1, 1, 54, 40, 828083),\n",
       " datetime.datetime(1970, 1, 1, 1, 54, 45, 328533),\n",
       " datetime.datetime(1970, 1, 1, 1, 54, 49, 828983),\n",
       " datetime.datetime(1970, 1, 1, 1, 54, 54, 329433),\n",
       " datetime.datetime(1970, 1, 1, 1, 54, 58, 829883),\n",
       " datetime.datetime(1970, 1, 1, 1, 55, 3, 330333),\n",
       " datetime.datetime(1970, 1, 1, 1, 55, 7, 830783),\n",
       " datetime.datetime(1970, 1, 1, 1, 55, 12, 331233),\n",
       " datetime.datetime(1970, 1, 1, 1, 55, 16, 831683),\n",
       " datetime.datetime(1970, 1, 1, 1, 55, 21, 332133),\n",
       " datetime.datetime(1970, 1, 1, 1, 55, 25, 832583),\n",
       " datetime.datetime(1970, 1, 1, 1, 55, 30, 333033),\n",
       " datetime.datetime(1970, 1, 1, 1, 55, 34, 833483),\n",
       " datetime.datetime(1970, 1, 1, 1, 55, 39, 333933),\n",
       " datetime.datetime(1970, 1, 1, 1, 55, 43, 834383),\n",
       " datetime.datetime(1970, 1, 1, 1, 55, 48, 334833),\n",
       " datetime.datetime(1970, 1, 1, 1, 55, 52, 835284),\n",
       " datetime.datetime(1970, 1, 1, 1, 55, 57, 335734),\n",
       " datetime.datetime(1970, 1, 1, 1, 56, 1, 836184),\n",
       " datetime.datetime(1970, 1, 1, 1, 56, 6, 336634),\n",
       " datetime.datetime(1970, 1, 1, 1, 56, 10, 837084),\n",
       " datetime.datetime(1970, 1, 1, 1, 56, 15, 337534),\n",
       " datetime.datetime(1970, 1, 1, 1, 56, 19, 837984),\n",
       " datetime.datetime(1970, 1, 1, 1, 56, 24, 338434),\n",
       " datetime.datetime(1970, 1, 1, 1, 56, 28, 838884),\n",
       " datetime.datetime(1970, 1, 1, 1, 56, 33, 339334),\n",
       " datetime.datetime(1970, 1, 1, 1, 56, 37, 839784),\n",
       " datetime.datetime(1970, 1, 1, 1, 56, 42, 340234),\n",
       " datetime.datetime(1970, 1, 1, 1, 56, 46, 840684),\n",
       " datetime.datetime(1970, 1, 1, 1, 56, 51, 341134),\n",
       " datetime.datetime(1970, 1, 1, 1, 56, 55, 841584),\n",
       " datetime.datetime(1970, 1, 1, 1, 57, 0, 342034),\n",
       " datetime.datetime(1970, 1, 1, 1, 57, 4, 842484),\n",
       " datetime.datetime(1970, 1, 1, 1, 57, 9, 342934),\n",
       " datetime.datetime(1970, 1, 1, 1, 57, 13, 843384),\n",
       " datetime.datetime(1970, 1, 1, 1, 57, 18, 343834),\n",
       " datetime.datetime(1970, 1, 1, 1, 57, 22, 844284),\n",
       " datetime.datetime(1970, 1, 1, 1, 57, 27, 344734),\n",
       " datetime.datetime(1970, 1, 1, 1, 57, 31, 845185),\n",
       " datetime.datetime(1970, 1, 1, 1, 57, 36, 345635),\n",
       " datetime.datetime(1970, 1, 1, 1, 57, 40, 846085),\n",
       " datetime.datetime(1970, 1, 1, 1, 57, 45, 346535),\n",
       " datetime.datetime(1970, 1, 1, 1, 57, 49, 846985),\n",
       " datetime.datetime(1970, 1, 1, 1, 57, 54, 347435),\n",
       " datetime.datetime(1970, 1, 1, 1, 57, 58, 847885),\n",
       " datetime.datetime(1970, 1, 1, 1, 58, 3, 348335),\n",
       " datetime.datetime(1970, 1, 1, 1, 58, 7, 848785),\n",
       " datetime.datetime(1970, 1, 1, 1, 58, 12, 349235),\n",
       " datetime.datetime(1970, 1, 1, 1, 58, 16, 849685),\n",
       " datetime.datetime(1970, 1, 1, 1, 58, 21, 350135),\n",
       " datetime.datetime(1970, 1, 1, 1, 58, 25, 850585),\n",
       " datetime.datetime(1970, 1, 1, 1, 58, 30, 351035),\n",
       " datetime.datetime(1970, 1, 1, 1, 58, 34, 851485),\n",
       " datetime.datetime(1970, 1, 1, 1, 58, 39, 351935),\n",
       " datetime.datetime(1970, 1, 1, 1, 58, 43, 852385),\n",
       " datetime.datetime(1970, 1, 1, 1, 58, 48, 352835),\n",
       " datetime.datetime(1970, 1, 1, 1, 58, 52, 853285),\n",
       " datetime.datetime(1970, 1, 1, 1, 58, 57, 353735),\n",
       " datetime.datetime(1970, 1, 1, 1, 59, 1, 854185),\n",
       " datetime.datetime(1970, 1, 1, 1, 59, 6, 354635),\n",
       " datetime.datetime(1970, 1, 1, 1, 59, 10, 855086),\n",
       " datetime.datetime(1970, 1, 1, 1, 59, 15, 355536),\n",
       " datetime.datetime(1970, 1, 1, 1, 59, 19, 855986),\n",
       " datetime.datetime(1970, 1, 1, 1, 59, 24, 356436),\n",
       " datetime.datetime(1970, 1, 1, 1, 59, 28, 856886),\n",
       " datetime.datetime(1970, 1, 1, 1, 59, 33, 357336),\n",
       " datetime.datetime(1970, 1, 1, 1, 59, 37, 857786),\n",
       " datetime.datetime(1970, 1, 1, 1, 59, 42, 358236),\n",
       " datetime.datetime(1970, 1, 1, 1, 59, 46, 858686),\n",
       " datetime.datetime(1970, 1, 1, 1, 59, 51, 359136),\n",
       " datetime.datetime(1970, 1, 1, 1, 59, 55, 859586),\n",
       " datetime.datetime(1970, 1, 1, 2, 0, 0, 360036),\n",
       " datetime.datetime(1970, 1, 1, 2, 0, 4, 860486),\n",
       " datetime.datetime(1970, 1, 1, 2, 0, 9, 360936),\n",
       " datetime.datetime(1970, 1, 1, 2, 0, 13, 861386),\n",
       " datetime.datetime(1970, 1, 1, 2, 0, 18, 361836),\n",
       " datetime.datetime(1970, 1, 1, 2, 0, 22, 862286),\n",
       " datetime.datetime(1970, 1, 1, 2, 0, 27, 362736),\n",
       " datetime.datetime(1970, 1, 1, 2, 0, 31, 863186),\n",
       " datetime.datetime(1970, 1, 1, 2, 0, 36, 363636),\n",
       " datetime.datetime(1970, 1, 1, 2, 0, 40, 864086),\n",
       " datetime.datetime(1970, 1, 1, 2, 0, 45, 364536),\n",
       " datetime.datetime(1970, 1, 1, 2, 0, 49, 864986),\n",
       " datetime.datetime(1970, 1, 1, 2, 0, 54, 365437),\n",
       " datetime.datetime(1970, 1, 1, 2, 0, 58, 865887),\n",
       " datetime.datetime(1970, 1, 1, 2, 1, 3, 366337),\n",
       " datetime.datetime(1970, 1, 1, 2, 1, 7, 866787),\n",
       " datetime.datetime(1970, 1, 1, 2, 1, 12, 367237),\n",
       " datetime.datetime(1970, 1, 1, 2, 1, 16, 867687),\n",
       " datetime.datetime(1970, 1, 1, 2, 1, 21, 368137),\n",
       " datetime.datetime(1970, 1, 1, 2, 1, 25, 868587),\n",
       " datetime.datetime(1970, 1, 1, 2, 1, 30, 369037),\n",
       " datetime.datetime(1970, 1, 1, 2, 1, 34, 869487),\n",
       " datetime.datetime(1970, 1, 1, 2, 1, 39, 369937),\n",
       " datetime.datetime(1970, 1, 1, 2, 1, 43, 870387),\n",
       " datetime.datetime(1970, 1, 1, 2, 1, 48, 370837),\n",
       " datetime.datetime(1970, 1, 1, 2, 1, 52, 871287),\n",
       " datetime.datetime(1970, 1, 1, 2, 1, 57, 371737),\n",
       " datetime.datetime(1970, 1, 1, 2, 2, 1, 872187),\n",
       " datetime.datetime(1970, 1, 1, 2, 2, 6, 372637),\n",
       " datetime.datetime(1970, 1, 1, 2, 2, 10, 873087),\n",
       " datetime.datetime(1970, 1, 1, 2, 2, 15, 373537),\n",
       " datetime.datetime(1970, 1, 1, 2, 2, 19, 873987),\n",
       " datetime.datetime(1970, 1, 1, 2, 2, 24, 374437),\n",
       " datetime.datetime(1970, 1, 1, 2, 2, 28, 874887),\n",
       " datetime.datetime(1970, 1, 1, 2, 2, 33, 375338),\n",
       " datetime.datetime(1970, 1, 1, 2, 2, 37, 875788),\n",
       " datetime.datetime(1970, 1, 1, 2, 2, 42, 376238),\n",
       " datetime.datetime(1970, 1, 1, 2, 2, 46, 876688),\n",
       " datetime.datetime(1970, 1, 1, 2, 2, 51, 377138),\n",
       " datetime.datetime(1970, 1, 1, 2, 2, 55, 877588),\n",
       " datetime.datetime(1970, 1, 1, 2, 3, 0, 378038),\n",
       " datetime.datetime(1970, 1, 1, 2, 3, 4, 878488),\n",
       " datetime.datetime(1970, 1, 1, 2, 3, 9, 378938),\n",
       " datetime.datetime(1970, 1, 1, 2, 3, 13, 879388),\n",
       " datetime.datetime(1970, 1, 1, 2, 3, 18, 379838),\n",
       " datetime.datetime(1970, 1, 1, 2, 3, 22, 880288),\n",
       " datetime.datetime(1970, 1, 1, 2, 3, 27, 380738),\n",
       " datetime.datetime(1970, 1, 1, 2, 3, 31, 881188),\n",
       " datetime.datetime(1970, 1, 1, 2, 3, 36, 381638),\n",
       " datetime.datetime(1970, 1, 1, 2, 3, 40, 882088),\n",
       " datetime.datetime(1970, 1, 1, 2, 3, 45, 382538),\n",
       " datetime.datetime(1970, 1, 1, 2, 3, 49, 882988),\n",
       " datetime.datetime(1970, 1, 1, 2, 3, 54, 383438),\n",
       " datetime.datetime(1970, 1, 1, 2, 3, 58, 883888),\n",
       " datetime.datetime(1970, 1, 1, 2, 4, 3, 384338),\n",
       " datetime.datetime(1970, 1, 1, 2, 4, 7, 884788),\n",
       " datetime.datetime(1970, 1, 1, 2, 4, 12, 385239),\n",
       " datetime.datetime(1970, 1, 1, 2, 4, 16, 885689),\n",
       " datetime.datetime(1970, 1, 1, 2, 4, 21, 386139),\n",
       " datetime.datetime(1970, 1, 1, 2, 4, 25, 886589),\n",
       " datetime.datetime(1970, 1, 1, 2, 4, 30, 387039),\n",
       " datetime.datetime(1970, 1, 1, 2, 4, 34, 887489),\n",
       " datetime.datetime(1970, 1, 1, 2, 4, 39, 387939),\n",
       " datetime.datetime(1970, 1, 1, 2, 4, 43, 888389),\n",
       " datetime.datetime(1970, 1, 1, 2, 4, 48, 388839),\n",
       " datetime.datetime(1970, 1, 1, 2, 4, 52, 889289),\n",
       " datetime.datetime(1970, 1, 1, 2, 4, 57, 389739),\n",
       " datetime.datetime(1970, 1, 1, 2, 5, 1, 890189),\n",
       " datetime.datetime(1970, 1, 1, 2, 5, 6, 390639),\n",
       " datetime.datetime(1970, 1, 1, 2, 5, 10, 891089),\n",
       " datetime.datetime(1970, 1, 1, 2, 5, 15, 391539),\n",
       " datetime.datetime(1970, 1, 1, 2, 5, 19, 891989),\n",
       " datetime.datetime(1970, 1, 1, 2, 5, 24, 392439),\n",
       " datetime.datetime(1970, 1, 1, 2, 5, 28, 892889),\n",
       " datetime.datetime(1970, 1, 1, 2, 5, 33, 393339),\n",
       " datetime.datetime(1970, 1, 1, 2, 5, 37, 893789),\n",
       " datetime.datetime(1970, 1, 1, 2, 5, 42, 394239),\n",
       " datetime.datetime(1970, 1, 1, 2, 5, 46, 894689),\n",
       " datetime.datetime(1970, 1, 1, 2, 5, 51, 395140),\n",
       " datetime.datetime(1970, 1, 1, 2, 5, 55, 895590),\n",
       " datetime.datetime(1970, 1, 1, 2, 6, 0, 396040),\n",
       " datetime.datetime(1970, 1, 1, 2, 6, 4, 896490),\n",
       " datetime.datetime(1970, 1, 1, 2, 6, 9, 396940),\n",
       " datetime.datetime(1970, 1, 1, 2, 6, 13, 897390),\n",
       " datetime.datetime(1970, 1, 1, 2, 6, 18, 397840),\n",
       " datetime.datetime(1970, 1, 1, 2, 6, 22, 898290),\n",
       " datetime.datetime(1970, 1, 1, 2, 6, 27, 398740),\n",
       " datetime.datetime(1970, 1, 1, 2, 6, 31, 899190),\n",
       " datetime.datetime(1970, 1, 1, 2, 6, 36, 399640),\n",
       " datetime.datetime(1970, 1, 1, 2, 6, 40, 900090),\n",
       " datetime.datetime(1970, 1, 1, 2, 6, 45, 400540),\n",
       " datetime.datetime(1970, 1, 1, 2, 6, 49, 900990),\n",
       " datetime.datetime(1970, 1, 1, 2, 6, 54, 401440),\n",
       " datetime.datetime(1970, 1, 1, 2, 6, 58, 901890),\n",
       " datetime.datetime(1970, 1, 1, 2, 7, 3, 402340),\n",
       " datetime.datetime(1970, 1, 1, 2, 7, 7, 902790),\n",
       " datetime.datetime(1970, 1, 1, 2, 7, 12, 403240),\n",
       " datetime.datetime(1970, 1, 1, 2, 7, 16, 903690),\n",
       " datetime.datetime(1970, 1, 1, 2, 7, 21, 404140),\n",
       " datetime.datetime(1970, 1, 1, 2, 7, 25, 904590),\n",
       " datetime.datetime(1970, 1, 1, 2, 7, 30, 405041),\n",
       " datetime.datetime(1970, 1, 1, 2, 7, 34, 905491),\n",
       " datetime.datetime(1970, 1, 1, 2, 7, 39, 405941),\n",
       " datetime.datetime(1970, 1, 1, 2, 7, 43, 906391),\n",
       " datetime.datetime(1970, 1, 1, 2, 7, 48, 406841),\n",
       " datetime.datetime(1970, 1, 1, 2, 7, 52, 907291),\n",
       " datetime.datetime(1970, 1, 1, 2, 7, 57, 407741),\n",
       " datetime.datetime(1970, 1, 1, 2, 8, 1, 908191),\n",
       " datetime.datetime(1970, 1, 1, 2, 8, 6, 408641),\n",
       " datetime.datetime(1970, 1, 1, 2, 8, 10, 909091),\n",
       " datetime.datetime(1970, 1, 1, 2, 8, 15, 409541),\n",
       " datetime.datetime(1970, 1, 1, 2, 8, 19, 909991),\n",
       " datetime.datetime(1970, 1, 1, 2, 8, 24, 410441),\n",
       " datetime.datetime(1970, 1, 1, 2, 8, 28, 910891),\n",
       " datetime.datetime(1970, 1, 1, 2, 8, 33, 411341),\n",
       " datetime.datetime(1970, 1, 1, 2, 8, 37, 911791),\n",
       " datetime.datetime(1970, 1, 1, 2, 8, 42, 412241),\n",
       " datetime.datetime(1970, 1, 1, 2, 8, 46, 912691),\n",
       " datetime.datetime(1970, 1, 1, 2, 8, 51, 413141),\n",
       " datetime.datetime(1970, 1, 1, 2, 8, 55, 913591),\n",
       " datetime.datetime(1970, 1, 1, 2, 9, 0, 414041),\n",
       " datetime.datetime(1970, 1, 1, 2, 9, 4, 914491),\n",
       " datetime.datetime(1970, 1, 1, 2, 9, 9, 414941),\n",
       " datetime.datetime(1970, 1, 1, 2, 9, 13, 915392),\n",
       " datetime.datetime(1970, 1, 1, 2, 9, 18, 415842),\n",
       " datetime.datetime(1970, 1, 1, 2, 9, 22, 916292),\n",
       " datetime.datetime(1970, 1, 1, 2, 9, 27, 416742),\n",
       " datetime.datetime(1970, 1, 1, 2, 9, 31, 917192),\n",
       " datetime.datetime(1970, 1, 1, 2, 9, 36, 417642),\n",
       " datetime.datetime(1970, 1, 1, 2, 9, 40, 918092),\n",
       " datetime.datetime(1970, 1, 1, 2, 9, 45, 418542),\n",
       " datetime.datetime(1970, 1, 1, 2, 9, 49, 918992),\n",
       " datetime.datetime(1970, 1, 1, 2, 9, 54, 419442),\n",
       " datetime.datetime(1970, 1, 1, 2, 9, 58, 919892),\n",
       " datetime.datetime(1970, 1, 1, 2, 10, 3, 420342),\n",
       " datetime.datetime(1970, 1, 1, 2, 10, 7, 920792),\n",
       " datetime.datetime(1970, 1, 1, 2, 10, 12, 421242),\n",
       " datetime.datetime(1970, 1, 1, 2, 10, 16, 921692),\n",
       " datetime.datetime(1970, 1, 1, 2, 10, 21, 422142),\n",
       " datetime.datetime(1970, 1, 1, 2, 10, 25, 922592),\n",
       " datetime.datetime(1970, 1, 1, 2, 10, 30, 423042),\n",
       " datetime.datetime(1970, 1, 1, 2, 10, 34, 923492),\n",
       " datetime.datetime(1970, 1, 1, 2, 10, 39, 423942),\n",
       " datetime.datetime(1970, 1, 1, 2, 10, 43, 924392),\n",
       " datetime.datetime(1970, 1, 1, 2, 10, 48, 424842),\n",
       " datetime.datetime(1970, 1, 1, 2, 10, 52, 925293),\n",
       " datetime.datetime(1970, 1, 1, 2, 10, 57, 425743),\n",
       " datetime.datetime(1970, 1, 1, 2, 11, 1, 926193),\n",
       " datetime.datetime(1970, 1, 1, 2, 11, 6, 426643),\n",
       " datetime.datetime(1970, 1, 1, 2, 11, 10, 927093),\n",
       " datetime.datetime(1970, 1, 1, 2, 11, 15, 427543),\n",
       " datetime.datetime(1970, 1, 1, 2, 11, 19, 927993),\n",
       " datetime.datetime(1970, 1, 1, 2, 11, 24, 428443),\n",
       " datetime.datetime(1970, 1, 1, 2, 11, 28, 928893),\n",
       " datetime.datetime(1970, 1, 1, 2, 11, 33, 429343),\n",
       " datetime.datetime(1970, 1, 1, 2, 11, 37, 929793),\n",
       " datetime.datetime(1970, 1, 1, 2, 11, 42, 430243),\n",
       " datetime.datetime(1970, 1, 1, 2, 11, 46, 930693),\n",
       " datetime.datetime(1970, 1, 1, 2, 11, 51, 431143),\n",
       " datetime.datetime(1970, 1, 1, 2, 11, 55, 931593),\n",
       " datetime.datetime(1970, 1, 1, 2, 12, 0, 432043),\n",
       " datetime.datetime(1970, 1, 1, 2, 12, 4, 932493),\n",
       " datetime.datetime(1970, 1, 1, 2, 12, 9, 432943),\n",
       " datetime.datetime(1970, 1, 1, 2, 12, 13, 933393),\n",
       " datetime.datetime(1970, 1, 1, 2, 12, 18, 433843),\n",
       " datetime.datetime(1970, 1, 1, 2, 12, 22, 934293),\n",
       " datetime.datetime(1970, 1, 1, 2, 12, 27, 434743),\n",
       " datetime.datetime(1970, 1, 1, 2, 12, 31, 935194),\n",
       " datetime.datetime(1970, 1, 1, 2, 12, 36, 435644),\n",
       " datetime.datetime(1970, 1, 1, 2, 12, 40, 936094),\n",
       " datetime.datetime(1970, 1, 1, 2, 12, 45, 436544),\n",
       " datetime.datetime(1970, 1, 1, 2, 12, 49, 936994),\n",
       " datetime.datetime(1970, 1, 1, 2, 12, 54, 437444),\n",
       " datetime.datetime(1970, 1, 1, 2, 12, 58, 937894),\n",
       " datetime.datetime(1970, 1, 1, 2, 13, 3, 438344),\n",
       " datetime.datetime(1970, 1, 1, 2, 13, 7, 938794),\n",
       " datetime.datetime(1970, 1, 1, 2, 13, 12, 439244),\n",
       " datetime.datetime(1970, 1, 1, 2, 13, 16, 939694),\n",
       " datetime.datetime(1970, 1, 1, 2, 13, 21, 440144),\n",
       " datetime.datetime(1970, 1, 1, 2, 13, 25, 940594),\n",
       " datetime.datetime(1970, 1, 1, 2, 13, 30, 441044),\n",
       " datetime.datetime(1970, 1, 1, 2, 13, 34, 941494),\n",
       " datetime.datetime(1970, 1, 1, 2, 13, 39, 441944),\n",
       " datetime.datetime(1970, 1, 1, 2, 13, 43, 942394),\n",
       " datetime.datetime(1970, 1, 1, 2, 13, 48, 442844),\n",
       " datetime.datetime(1970, 1, 1, 2, 13, 52, 943294),\n",
       " datetime.datetime(1970, 1, 1, 2, 13, 57, 443744),\n",
       " datetime.datetime(1970, 1, 1, 2, 14, 1, 944194),\n",
       " datetime.datetime(1970, 1, 1, 2, 14, 6, 444644),\n",
       " datetime.datetime(1970, 1, 1, 2, 14, 10, 945095),\n",
       " datetime.datetime(1970, 1, 1, 2, 14, 15, 445545),\n",
       " datetime.datetime(1970, 1, 1, 2, 14, 19, 945995),\n",
       " datetime.datetime(1970, 1, 1, 2, 14, 24, 446445),\n",
       " datetime.datetime(1970, 1, 1, 2, 14, 28, 946895),\n",
       " datetime.datetime(1970, 1, 1, 2, 14, 33, 447345),\n",
       " datetime.datetime(1970, 1, 1, 2, 14, 37, 947795),\n",
       " datetime.datetime(1970, 1, 1, 2, 14, 42, 448245),\n",
       " datetime.datetime(1970, 1, 1, 2, 14, 46, 948695),\n",
       " datetime.datetime(1970, 1, 1, 2, 14, 51, 449145),\n",
       " datetime.datetime(1970, 1, 1, 2, 14, 55, 949595),\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[datetime.datetime.fromtimestamp(y) for y in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a4beff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
