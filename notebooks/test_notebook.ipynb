{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "828b9bd9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Installed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c7f1513",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e8a619edb40d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0menum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msimpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gdal\\lib\\site-packages\\scipy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[1;31m# Allow distributors to run custom init code\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_pep440\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gdal\\lib\\site-packages\\scipy\\_distributor_init.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlibs_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlibs_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'*dll'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m                 \u001b[0mWinDLL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mowd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gdal\\lib\\ctypes\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# package(s) related to time, space and id\n",
    "import datetime, time\n",
    "import os\n",
    "import io\n",
    "import functools\n",
    "import logging\n",
    "import pickle\n",
    "import random\n",
    "import math\n",
    "\n",
    "# package(s) related to the simulation\n",
    "import enum\n",
    "import simpy\n",
    "import scipy as sc\n",
    "import math\n",
    "import networkx as nx  \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import yaml as yaml\n",
    "import time\n",
    "import bisect\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as tri\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "from scipy import interpolate\n",
    "from scipy.signal import correlate\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "\n",
    "# OpenTNSim\n",
    "from opentnsim import core\n",
    "from opentnsim import plot\n",
    "from opentnsim import model\n",
    "\n",
    "# spatial libraries \n",
    "import shapely.geometry\n",
    "import shapely.wkt\n",
    "import pyproj\n",
    "import shapely.geometry\n",
    "import folium\n",
    "import datetime\n",
    "import time as timepy\n",
    "\n",
    "# package(s) for data handling\n",
    "import requests\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# define the coorinate systemb\n",
    "geod = pyproj.Geod(ellps=\"WGS84\")\n",
    "\n",
    "location_vessel_database = \"Vessels/richtlijnen-vaarwegen-2017.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a603b08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "core.__file__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ea83ea",
   "metadata": {},
   "source": [
    "# Load data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0081a438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_wlevel= pd.read_csv(r'C:\\Users\\floorbakker\\OpenTNSim\\notebooks\\WL_dataset.csv',delimiter=',')\n",
    "# df_VM= pd.read_csv(r'C:\\Users\\floorbakker\\OpenTNSim\\notebooks\\VM_dataset.csv',delimiter=',')\n",
    "# df_Van= pd.read_csv(r'C:\\Users\\floorbakker\\OpenTNSim\\notebooks\\Van_dataset.csv',delimiter=',')\n",
    "\n",
    "df_wlevel= pd.read_csv(r'C:\\Users\\floorbakker\\OpenTNSim\\notebooks\\WL_dataset.csv',delimiter=',')\n",
    "df_VM= pd.read_csv(r'C:\\Users\\floorbakker\\OpenTNSim\\notebooks\\VM_dataset.csv',delimiter=',')\n",
    "df_Van= pd.read_csv(r'C:\\Users\\floorbakker\\OpenTNSim\\notebooks\\Van_dataset.csv',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e87926",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Node = type('Site', (core.Identifiable, core.Log, core.Locatable, core.HasResource), {})\n",
    "nodes = []\n",
    "path = []\n",
    "coords = []\n",
    "\n",
    "coords.append([2.68276,51.84278]) #node_1 origin\n",
    "coords.append([2.76847,51.8981])#node_2\n",
    "coords.append([2.89251,51.94136])#node_3\n",
    "coords.append([2.91627,51.94957])#node_4\n",
    "coords.append([3.88419,52.02922])#node_5\n",
    "coords.append([3.93995795592471,52.0219158335973]) #node_6\n",
    "coords.append([4.04961843717028,51.9913123648208]) #node_7\n",
    "coords.append([4.1187846584378,51.9756279862634]) #node_8\n",
    "coords.append([4.15471631295706,51.9596283586068]) #node_9\n",
    "coords.append([4.19884102088863,51.9382313719035]) #node_10\n",
    "coords.append([4.22030870030092,51.9302898518613]) #node_11\n",
    "coords.append([4.24286991304305,51.9141858383526]) #node_12\n",
    "coords.append([4.27537465881064,51.9015756264453]) #node_13\n",
    "coords.append([4.29337962495028,51.8968867771695]) #node_14\n",
    "coords.append([4.30388786112617,51.8947760348761]) #node_15\n",
    "coords.append([4.308557,51.889522]) #node_16 turning basin\n",
    "coords.append([4.308335,51.884692])#node_17 \n",
    "coords.append([4.306804,51.879432]) #node_18\n",
    "coords.append([4.312392,51.874262]) #node_19, destination\n",
    "coords.append([2.9054,51.92534]) #node_20, anchorage 1 north\n",
    "coords.append([2.7474,52.08876]) #node_21, anchorage 2 south\n",
    "\n",
    "for d in range(len(coords)):\n",
    "    data_node = {\"env\": [],\n",
    "                 \"name\": \"Node \" + str(d+1),\n",
    "                 \"geometry\": shapely.geometry.Point(coords[d][0], coords[d][1])}\n",
    "    node = Node(**data_node)\n",
    "    nodes.append(node)\n",
    "    \n",
    "for i in range(len(nodes)-3):\n",
    "    path.append([nodes[i],nodes[i+1]]) \n",
    "    path.append([nodes[i+1],nodes[i]])\n",
    "    \n",
    "path.append([nodes[2],nodes[19]]) # channel - anchorage 1 \n",
    "path.append([nodes[19],nodes[2]]) # anchorage 1- channel\n",
    "path.append([nodes[2],nodes[20]])  # channel - anchorage 2\n",
    "path.append([nodes[20],nodes[2]])  # anchorage 2-channel\n",
    "\n",
    "\n",
    "FG = nx.DiGraph()\n",
    "\n",
    "positions = {}\n",
    "for node in nodes:\n",
    "    positions[node.name] = (node.geometry.x, node.geometry.y)\n",
    "    FG.add_node(node.name, geometry = node.geometry)\n",
    "\n",
    "for edge in path:\n",
    "    FG.add_edge(edge[0].name, edge[1].name, weight = 1, Info = {})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "nx.draw(FG, positions)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7645455b",
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the network \n",
    "m = folium.Map(location=[52, 3.4], zoom_start = 9, tiles=\"cartodbpositron\")\n",
    "\n",
    "line = []\n",
    "for node in list(FG.nodes())[0:19]:\n",
    "    points_x = FG.nodes[node][\"geometry\"].x\n",
    "    points_y = FG.nodes[node][\"geometry\"].y\n",
    "    line.append([points_y, points_x])\n",
    "    if node == 'Node 3':\n",
    "        line.append([FG.nodes['Node 20'][\"geometry\"].y, FG.nodes['Node 20'][\"geometry\"].x])\n",
    "        line.append([points_y, points_x])\n",
    "        line.append([FG.nodes['Node 21'][\"geometry\"].y, FG.nodes['Node 21'][\"geometry\"].x])\n",
    "        line.append([points_y, points_x])\n",
    "    \n",
    "folium.PolyLine(line, weight = 2).add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c03e66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_start = datetime.datetime.now()\n",
    "sim = model.Simulation(simulation_start,FG)\n",
    "env = sim.environment\n",
    "duration = 14*24*3600 #seconds\n",
    "#duration = 15290000 #seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0ce24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "terminal_1 = core.IsTerminal(env = env, \n",
    "                             name = 'Koole terminal',\n",
    "                             length = 700, \n",
    "                             node_start = 'Node 18', \n",
    "                             node_end = 'Node 19', \n",
    "                             type = 'quay')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc5f356",
   "metadata": {},
   "source": [
    "The Koole terminal has 5 deepsea jetties, coaster+IWT jetties, and 6 jetties dedicated for IWT. For this exercise I'll only take the 5 deepsea jetties and I'll add them to a single terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7a01af",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.FG = FG\n",
    "\n",
    "turning_basin_1 = core.IsTurningBasin(env = env, name = 'Turning Basin 1', node = 'Node 16', length = 300)\n",
    "\n",
    "origin_1 = core.IsOrigin(env = env, name = 'Origin 1')\n",
    "\n",
    "anchorage_1 = core.IsAnchorage(env = env, name = 'Anchorage 1', node = 'Node 20', type = 'sea_going_vessels',max_capacity = 50)\n",
    "anchorage_2 = core.IsAnchorage(env = env, name = 'Anchorage 2', node = 'Node 21', type = 'sea_going_vessels',max_capacity = 50)\n",
    "\n",
    "terminal_1 = core.IsTerminal(env = env, name = 'Koole terminal',length = 700, jetty_locations = [100,200,300,400,500], jetty_lengths = [300,300,300,300,300], node_start = 'Node 18', node_end = 'Node 19', type = 'jetty')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ba63c8",
   "metadata": {},
   "source": [
    "## Anchorage capacity\n",
    "\n",
    "Argument: Anchorage areas 3A + 3C seems to have around 10 ships at the same time (Marine Traffic.com and master thesis by Devillé). \n",
    "\n",
    "what is a reasonable value of the anchorage capacity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544c87ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FG.nodes[\"Node 1\"][\"Origin\"] = [origin_1]\n",
    "\n",
    "FG.nodes[\"Node 20\"][\"Anchorage\"] = [anchorage_1]\n",
    "\n",
    "FG.nodes[\"Node 21\"][\"Anchorage\"] = [anchorage_2]\n",
    "\n",
    "FG.nodes[\"Node 16\"][\"Turning Basin\"] = [turning_basin_1]\n",
    "\n",
    "# FG.nodes[\"Node 18\"][\"Turning Basin\"] = [turning_basin_2] I could add this one later on\n",
    "\n",
    "FG.nodes[\"Node 1\"][\"Junction\"] = core.IsJunction(env = [], name = [], sections = [], type = []) #origin\n",
    "FG.nodes[\"Node 1\"][\"Junction\"].name = ['waterway_access']\n",
    "FG.nodes[\"Node 1\"][\"Junction\"].type = ['two-way_traffic']\n",
    "\n",
    "FG.nodes[\"Node 16\"][\"Junction\"] = core.IsJunction(env = [], name = [], sections = [], type = []) #turn Basin acccess to 3e PH\n",
    "FG.nodes[\"Node 16\"][\"Junction\"].name = ['waterway_access','harbour_basin_access']\n",
    "FG.nodes[\"Node 16\"][\"Junction\"].type = ['two-way_traffic','one-way_traffic']\n",
    "\n",
    "#FG.nodes[\"Node 17\"][\"Junction\"] = core.IsJunction(env = [], name = [], sections = [], type = []) #start terminal\n",
    "#FG.nodes[\"Node 17\"][\"Junction\"].name = ['waterway_access','waterway_access']\n",
    "#FG.nodes[\"Node 17\"][\"Junction\"].type = ['one-way_traffic','one-way_traffic']\n",
    "\n",
    "#FG.nodes[\"Node 18\"][\"Junction\"] = core.IsJunction(env = [], name = [], sections = [], type = []) #middle part of the terminal\n",
    "#FG.nodes[\"Node 18\"][\"Junction\"].name = ['waterway_access','harbour_basin_access']\n",
    "#FG.nodes[\"Node 18\"][\"Junction\"].type = ['one-way_traffic','one-way_traffic']\n",
    "\n",
    "FG.nodes[\"Node 19\"][\"Junction\"] = core.IsJunction(env = [], name = [], sections = [], type = []) #end point route\n",
    "FG.nodes[\"Node 19\"][\"Junction\"].name = ['harbour_basin_access']\n",
    "FG.nodes[\"Node 19\"][\"Junction\"].type = ['one-way_traffic']\n",
    "\n",
    "FG.nodes[\"Node 3\"][\"Junction\"] = core.IsJunction(env = [], name = [], sections = [], type = []) #neural point\n",
    "FG.nodes[\"Node 3\"][\"Junction\"].name = ['waterway_access','waterway_access','anchorage_access','anchorage_access']\n",
    "FG.nodes[\"Node 3\"][\"Junction\"].type = ['two-way_traffic','two-way_traffic','two-way_traffic','two-way_traffic']\n",
    "\n",
    "FG.nodes[\"Node 20\"][\"Junction\"] = core.IsJunction(env = [], name = [], sections = [], type = []) #anchorage 1\n",
    "FG.nodes[\"Node 20\"][\"Junction\"].name = ['anchorage_access']\n",
    "FG.nodes[\"Node 20\"][\"Junction\"].type = ['two-way_traffic']\n",
    "\n",
    "FG.nodes[\"Node 21\"][\"Junction\"] = core.IsJunction(env = [], name = [], sections = [], type = []) #anchorage 2\n",
    "FG.nodes[\"Node 21\"][\"Junction\"].name = ['anchorage_access']\n",
    "FG.nodes[\"Node 21\"][\"Junction\"].type = ['two-way_traffic']\n",
    "\n",
    "\n",
    "junction_nodes = []\n",
    "for node in list(FG.nodes):\n",
    "    if 'Junction' in FG.nodes[node]:\n",
    "        junction_nodes.append(node)\n",
    "        \n",
    "for node1 in junction_nodes:\n",
    "    names = []\n",
    "    sections = []\n",
    "    types = []\n",
    "    for node2 in junction_nodes:\n",
    "        if node1 == node2:\n",
    "            continue\n",
    "            \n",
    "        route = nx.dijkstra_path(FG, node1, node2)\n",
    "        section = True\n",
    "        for node in route[1:-1]:\n",
    "            if 'Junction' in FG.nodes[node]:\n",
    "                section = False\n",
    "                break\n",
    "\n",
    "        if section:\n",
    "            sections.append([node1,node2])\n",
    "            names.append(FG.nodes[node1][\"Junction\"].name[len(sections)-1])\n",
    "            types.append(FG.nodes[node1][\"Junction\"].type[len(sections)-1])\n",
    "    \n",
    "    FG.nodes[node1][\"Junction\"] = [core.IsJunction(env = env, name = names, sections = sections, type = types)]\n",
    "            \n",
    "FG.edges['Node 18','Node 19'][\"Terminal\"] = [terminal_1]\n",
    "\n",
    "for edge in enumerate(FG.edges):\n",
    "    if 'Terminal' in FG.edges[edge[1]]:\n",
    "        FG.edges[edge[1][1],edge[1][0]]['Terminal'] = FG.edges[edge[1]]['Terminal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc58205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List 8 vessels\n",
    "vdf = pd.DataFrame()\n",
    "vdf[0] = ['Small coaster 1','Small coaster 2','Coaster','Handysize','Tanker MR','Tanker LR1','Tanker LR2 1','Tanker LR2 2']\n",
    "vdf[1] = [71,110,126,149,184,228,243,249] #length\n",
    "vdf[2] = [10.1,13.5,19,22,27,32,42,46] #beam\n",
    "vdf[3] = [4.5,5.45,8.5,10,11.4,12.1,13.6,15] # draught + FWA\n",
    "vdf[4] = 0.5*vdf[3] #unloaded draught\n",
    "vdf[5] = [17,17,17,17,17,17,17,17] #H_e free board empty- Update!\n",
    "vdf[6] = vdf[5]-(vdf[3]-vdf[4]) #H_f free board loaded\n",
    "vdf[7] = [60,60,60,60,60,60,60,60] #t_b in minutes - berthing time (assumed in 1hs)\n",
    "vdf[8] = [15*60,16.7*60,16.7*60,18.3*60,18.3*60,18.3*60,18.3*60,18.3*60] #t_l loading + unloading time (in minutes)\n",
    "vdf[9] = [0,0,0,0,0,0,0,0] #UKC\n",
    "vdf[10] = [4.5,4.5,4.5,4.5,4.5,4.5,4.5,4.5] # vessel speed in m/s - check with S. de Jong thesis\n",
    "# vdf[10] = [6,6,6,6,6,6,6,6] # vessel speed in m/s - own assumption\n",
    "vdf[11] = [18*60*60,18*60*60,18*60*60,18*60*60,18*60*60,18*60*60,18*60*60,18*60*60] # max waiting time in seconds\n",
    "vdf[12] = [0,0,0,0,0,0,0,0] #critical cross-current velocity in m/s\n",
    "vdf.columns = ['type','L','B','T_f','T_e','H_e','H_f','t_b','t_l','ukc','v','max_waiting_time','max_cross_current']\n",
    "vdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381f3238",
   "metadata": {},
   "source": [
    "Explanation parameters: \n",
    "- max current: for Node 15 a maximum FLOOD current of 0.5knots is defined --> I'll assume the same limit as CROSS-CURRENT for that node\n",
    "- For nodes between 15 and 19 (to destination), the same limit is applied.\n",
    "- max current: for the rest of the nodes, define a theoretical value for the open sea and another for the NWW channel --> values in PIANC Design of Harbour Approach channels --> open sea: strong current 2knots ; channel=moderate current 1.5knots\n",
    "\n",
    "\n",
    "Max waiting time:\n",
    "For liquid bulk = 18hs so it is the same as the largest value of the service time --> check with literature!\n",
    "\n",
    "Terminal occupancy, typical value for a liquid bulk terminal (van Koninsgveld et al, 2021)\n",
    "the acceptable berth occupancy lies between 40% for a single berth and 80% for four berths --> in this case, 4/5 jetties are occupied\n",
    "\n",
    "Service time --> values based on EIA deepening project\n",
    "\n",
    "Arrival time --> define value in such a way that there is a terminal occupancy of 0.6-0.8 and no port congestion.\n",
    "ASK FLOOR IF THE MODEL CAN USE STOCHASTIC ARRIVAL TIME DISTRIBUTIONS\n",
    "\n",
    "Duration of the sumlation and number of generated vessels --> number of generated vessels defines the accuracy of the generator (sampling uniform distribution) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84436c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## USE THIS CELL FOR SHIP GENERATOR WITH constant ARRIVAL RATE\n",
    "Vessel = type('Vessel', \n",
    "              (core.Identifiable, core.HasTurningBasin, core.Movable, core.Routeable, core.VesselProperties, core.ExtraMetadata), {})\n",
    "\n",
    "generator_sea = model.VesselGenerator(Vessel,vdf,random_seed=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a641e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### USE THIS CELL FOR SHIP GENERATOR WITH constant ARRIVAL RATE\n",
    "origin = 'Node 1' #coasters should enter empty and leave full (export) --> UPDATE SOMEWHERE\n",
    "destination = 'Node 19'\n",
    "vessel1 = Vessel(name='LR1',\n",
    "                 geometry=FG.nodes[origin]['geometry'],\n",
    "                 route=nx.dijkstra_path(FG,origin,destination),\n",
    "                 env=env,\n",
    "                 type='Tanker',\n",
    "                 B = vdf['B'][5],\n",
    "                 L = vdf['L'][5],\n",
    "                 T_f = vdf['T_f'][5],\n",
    "                 T_e = vdf['T_e'][5],\n",
    "                 H_e = vdf['H_e'][5],\n",
    "                 H_f = vdf['H_f'][5],\n",
    "                 t_b = vdf['t_b'][5],\n",
    "                 t_l = vdf['t_l'][5],\n",
    "                 ukc = vdf['ukc'][5],\n",
    "                 v = vdf['v'][5],\n",
    "                 max_waiting_time = vdf['max_waiting_time'][5],\n",
    "                 max_cross_current = vdf['max_cross_current'][5],\n",
    "                 start_time = 12500,)\n",
    "sim.add_vessels(origin,destination,[],vessel1)\n",
    "vessel2 = Vessel(name='MR',\n",
    "                 geometry=FG.nodes[origin]['geometry'],\n",
    "                 route=nx.dijkstra_path(FG,origin,destination),\n",
    "                 env=env,\n",
    "                 type='Tanker',\n",
    "                 B = vdf['B'][4],\n",
    "                 L = vdf['L'][4],\n",
    "                 T_f = vdf['T_f'][4],\n",
    "                 T_e = vdf['T_e'][4],\n",
    "                 H_e = vdf['H_e'][4],\n",
    "                 H_f = vdf['H_f'][4],\n",
    "                 t_b = vdf['t_b'][4],\n",
    "                 t_l = vdf['t_l'][4],\n",
    "                 ukc = vdf['ukc'][4],\n",
    "                 v = vdf['v'][4],\n",
    "                 max_waiting_time = vdf['max_waiting_time'][4],\n",
    "                 max_cross_current = vdf['max_cross_current'][4],\n",
    "                 start_time = 50000,)\n",
    "sim.add_vessels(origin,destination,[],vessel2)\n",
    "vessel3 = Vessel(name='LR2 1',\n",
    "                 geometry=FG.nodes[origin]['geometry'],\n",
    "                 route=nx.dijkstra_path(FG,origin,destination),\n",
    "                 env=env,\n",
    "                 type='Tanker',\n",
    "                 B = vdf['B'][6],\n",
    "                 L = vdf['L'][6],\n",
    "                 T_f = vdf['T_f'][6],\n",
    "                 T_e = vdf['T_e'][6],\n",
    "                 H_e = vdf['H_e'][6],\n",
    "                 H_f = vdf['H_f'][6],\n",
    "                 t_b = vdf['t_b'][6],\n",
    "                 t_l = vdf['t_l'][6],\n",
    "                 ukc = vdf['ukc'][6],\n",
    "                 v = vdf['v'][6],\n",
    "                 max_waiting_time = vdf['max_waiting_time'][6],\n",
    "                 max_cross_current = vdf['max_cross_current'][6],\n",
    "                 start_time = 240000,)\n",
    "sim.add_vessels(origin,destination,[],vessel3)\n",
    "vessel4 = Vessel(name='Handysize',\n",
    "                 geometry=FG.nodes[origin]['geometry'],\n",
    "                 route=nx.dijkstra_path(FG,origin,destination),\n",
    "                 env=env,\n",
    "                 type='Tanker',\n",
    "                 B = vdf['B'][3],\n",
    "                 L = vdf['L'][3],\n",
    "                 T_f = vdf['T_f'][2],\n",
    "                 T_e = vdf['T_e'][3],\n",
    "                 H_e = vdf['H_e'][3],\n",
    "                 H_f = vdf['H_f'][3],\n",
    "                 t_b = vdf['t_b'][3],\n",
    "                 t_l = vdf['t_l'][3],\n",
    "                 ukc = vdf['ukc'][3],\n",
    "                 v = vdf['v'][3],\n",
    "                 max_waiting_time = vdf['max_waiting_time'][3],\n",
    "                 max_cross_current = vdf['max_cross_current'][3],\n",
    "                 start_time = 285000,)\n",
    "sim.add_vessels(origin,destination,[],vessel4)\n",
    "vessel5 = Vessel(name='LR1',\n",
    "                 geometry=FG.nodes[origin]['geometry'],\n",
    "                 route=nx.dijkstra_path(FG,origin,destination),\n",
    "                 env=env,\n",
    "                 type='Tanker',\n",
    "                 B = vdf['B'][5],\n",
    "                 L = vdf['L'][5],\n",
    "                 T_f = vdf['T_f'][5],\n",
    "                 T_e = vdf['T_e'][5],\n",
    "                 H_e = vdf['H_e'][5],\n",
    "                 H_f = vdf['H_f'][5],\n",
    "                 t_b = vdf['t_b'][5],\n",
    "                 t_l = vdf['t_l'][5],\n",
    "                 ukc = vdf['ukc'][5],\n",
    "                 v = vdf['v'][5],\n",
    "                 max_waiting_time = vdf['max_waiting_time'][5],\n",
    "                 max_cross_current = vdf['max_cross_current'][5],\n",
    "                 start_time = 451000,)\n",
    "sim.add_vessels(origin,destination,[],vessel5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedd58fd",
   "metadata": {},
   "source": [
    "## WATER LEVEL AND VELOCITY FIELD + BATHYMETRY (water depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da02094c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define variables\n",
    "depth = [[],[]]\n",
    "width = [[],[]]\n",
    "MBL = [[],[]]\n",
    "water_level=[[],[]]\n",
    "current_velocity = [[],[]]\n",
    "current_direction = [[],[]]\n",
    "time = np.arange(0,duration,60)\n",
    "\n",
    "# depth according to MBL values, and waterway navigational width obtained from measuring on HavenKaart\n",
    "MBL[1] = [50,50,50,50,50,24.3,13.1,13.1,13.1,13.1,13.1,13.1,13.1,13.1,13.1,13.1,13.1,13.1,50,50,50]\n",
    "depth[1] = MBL[1]\n",
    "width[1] = [1000,1000,1000,1000,1000,600,300,300,200,200,200,200,200,200,200,200,180,180,180,1000,1000]\n",
    "\n",
    "# load water level, velocity magnitude and direction time series to each node\n",
    "for nodes in enumerate(FG.nodes):\n",
    "    MBL[0].append(FG.nodes[nodes[1]]['geometry'])\n",
    "    width[0].append(FG.nodes[nodes[1]]['geometry'])\n",
    "    depth[0].append((FG.nodes[nodes[1]]['geometry']))\n",
    "    water_level[0].append((FG.nodes[nodes[1]]['geometry']))\n",
    "    water_level[1].append([[],[]])\n",
    "    current_velocity[0].append((FG.nodes[nodes[1]]['geometry']))\n",
    "    current_velocity[1].append([[],[]])\n",
    "    current_direction[0].append((FG.nodes[nodes[1]]['geometry']))\n",
    "    current_direction[1].append([[],[]])\n",
    "    \n",
    "for col in enumerate(df_wlevel.columns[1:]): #load water level\n",
    "    water_level[1][col[0]][0]=[x-df_wlevel[df_wlevel.columns[0]][0]+simulation_start.timestamp() for x in list(df_wlevel[df_wlevel.columns[0]])]\n",
    "    water_level[1][col[0]][1]=list(df_wlevel[col[1]])    \n",
    "    \n",
    "for col in enumerate(df_VM.columns[1:]): #load velocity magnitude\n",
    "    current_velocity[1][col[0]][0]=[x-df_VM[df_VM.columns[0]][0]+simulation_start.timestamp() for x in list(df_VM[df_VM.columns[0]])]\n",
    "    current_velocity[1][col[0]][1]=list(df_VM[col[1]])\n",
    "     \n",
    "for col in enumerate(df_Van.columns[1:]): #load velocity direction\n",
    "    current_direction[1][col[0]][0]=[x-df_Van[df_Van.columns[0]][0]+simulation_start.timestamp() for x in list(df_Van[df_Van.columns[0]])]\n",
    "    current_direction[1][col[0]][1]=list(df_Van[col[1]])\n",
    "\n",
    "core.NetworkProperties.append_data_to_nodes(FG,width,depth,MBL,water_level,current_velocity,current_direction)\n",
    "knots = 0.51444444444444"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f3b543",
   "metadata": {},
   "outputs": [],
   "source": [
    "class window_method(Enum):\n",
    "    critical_cross_current = 'Critical cross-current'\n",
    "    point_based = 'Point-based'\n",
    "    \n",
    "class vessel_characteristics(Enum):\n",
    "    min_ge_Length = ['minLength','>=']\n",
    "    min_gt_Length = ['minLength','>']\n",
    "    max_le_Length = ['maxLength','<=']\n",
    "    max_lt_Length = ['maxLength','<']\n",
    "    min_ge_Draught = ['minDraught','>=']\n",
    "    min_gt_Draught = ['minDraught','>']\n",
    "    max_le_Draught = ['maxDraught','<=']\n",
    "    max_lt_Draught = ['maxDraught','<']\n",
    "    min_ge_Beam = ['minBeam','>=']\n",
    "    min_gt_Beam = ['minBeam','>']\n",
    "    max_le_Beam = ['maxBeam','<=']\n",
    "    max_lt_Beam = ['maxBeam','<']\n",
    "    min_ge_UKC = ['minUKC','>=']\n",
    "    min_gt_UKC = ['minUKC','>']\n",
    "    max_le_UKC = ['maxUKC','<=']\n",
    "    max_lt_UKC = ['maxUKC','<']\n",
    "    Type = ['Type','==']\n",
    "\n",
    "class vessel_direction(Enum):\n",
    "    inbound = 'inbound'\n",
    "    outbound = 'outbound'\n",
    "    \n",
    "class vessel_type(Enum):\n",
    "    GeneralCargo = 'GeneralCargo'\n",
    "    LiquidBulk = 'LiquidBulk'\n",
    "    Container = 'Container'\n",
    "    DryBulk = 'DryBulk'\n",
    "    MultiPurpose = 'MultiPurpose'\n",
    "    Reefer = 'Reefer'\n",
    "    RoRo = 'RoRo'\n",
    "    Barge = 'Barge'\n",
    "    \n",
    "class accessibility(Enum):\n",
    "    non_accessible = 0\n",
    "    accessible = -1\n",
    "    \n",
    "class tidal_period(Enum):\n",
    "    Flood = 'Flood'\n",
    "    Ebb = 'Ebb'\n",
    "    \n",
    "class current_velocity_type(Enum):\n",
    "    CurrentVelocity = 'Current velocity'\n",
    "    LongitudinalCurrent = 'Longitudinal current'\n",
    "    CrossCurrent = 'Cross-current'\n",
    "    \n",
    "@dataclass\n",
    "class vessel_specifications:\n",
    "    vessel_characteristics: dict #{item of vessel_characteristics class: user-defined value,...}\n",
    "    vessel_method: str #string containing the operators between the vessel characteristics (symbolized by x): e.g. '(x and x) or x'\n",
    "    vessel_direction: str #item of vessel_direction class\n",
    "\n",
    "    def characteristic_dicts(self):\n",
    "        characteristic_dicts = {}\n",
    "        for characteristic in self.vessel_characteristics:\n",
    "            characteristic_dict = {characteristic.value[0]: [characteristic.value[1],self.vessel_characteristics[characteristic]]}\n",
    "            characteristic_dicts = characteristic_dicts | characteristic_dict\n",
    "        return characteristic_dicts\n",
    "\n",
    "@dataclass\n",
    "class window_specifications:\n",
    "    window_method: str #item of window_method class\n",
    "    current_velocity_values: dict #{tidal_period.Flood.value: user-defined value or item from accessibility class,...}\n",
    "    current_velocity_ranges: dict = dict #if window_method is point-based: {tidal_period.Ebb.value: user-defined value,...}\n",
    "\n",
    "@dataclass\n",
    "class vtw_window_specifications:\n",
    "    ukc_s: dict #{tidal_period.Flood.value: user-defined value or item from accessibility class,...}\n",
    "    ukc_p: dict #{tidal_period.Flood.value: user-defined value or item from accessibility class,...}\n",
    "    fwa: dict #{tidal_period.Flood.value: user-defined value or item from accessibility class,...}\n",
    "\n",
    "@dataclass\n",
    "class vertical_tidal_window_input:\n",
    "    vessel_specifications: vessel_specifications #class\n",
    "    window_specifications: window_specifications #class     \n",
    "        \n",
    "@dataclass\n",
    "class horizontal_tidal_window_input:\n",
    "    vessel_specifications: vessel_specifications #class\n",
    "    window_specifications: window_specifications #class     \n",
    "    condition: dict #{'Origin':node, 'Destination': node}\n",
    "    data: list #Calculated input: [node,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9db3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in FG.nodes:\n",
    "    vertical_tidal_window_inputs = []\n",
    "\n",
    "    vessel_specification = vessel_specifications({vessel_characteristics.min_ge_Draught: 0},\n",
    "                                                  'x',vessel_direction.inbound.value)\n",
    "\n",
    "    window_specification = vtw_window_specifications({'ukc_s': 0.0},\n",
    "                                                     {'ukc_p': 0.1},\n",
    "                                                     {'fwa': 0.025})\n",
    "    \n",
    "    vertical_tidal_window_inputs.append(vertical_tidal_window_input(vessel_specifications = vessel_specification,\n",
    "                                                                    window_specifications = window_specification))\n",
    "\n",
    "    vessel_specification = vessel_specifications({vessel_characteristics.min_ge_Draught: 0},\n",
    "                                                  'x',vessel_direction.outbound.value)\n",
    "\n",
    "    window_specification = vtw_window_specifications({'ukc_s': 0.0},\n",
    "                                                     {'ukc_p': 0.1},\n",
    "                                                     {'fwa': 0.025})\n",
    "\n",
    "    vertical_tidal_window_inputs.append(vertical_tidal_window_input(vessel_specifications = vessel_specification,\n",
    "                                                                    window_specifications = window_specification))\n",
    "\n",
    "    core.NetworkProperties.append_vertical_tidal_restriction_to_network(FG,node,vertical_tidal_window_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b50641",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_tidal_window_inputs = []\n",
    "\n",
    "#Inbound_Vessels_Condition1\n",
    "vessel_specification = vessel_specifications({vessel_characteristics.max_lt_Draught: 14.3},\n",
    "                                              'x',vessel_direction.inbound.value)\n",
    "\n",
    "window_specification = window_specifications(window_method.point_based.value,\n",
    "                                             {tidal_period.Flood.value: 2*knots,tidal_period.Ebb.value: accessibility.accessible.value},\n",
    "                                             {tidal_period.Flood.value: 0.3,tidal_period.Ebb.value:0})\n",
    "\n",
    "horizontal_tidal_window_inputs.append(horizontal_tidal_window_input(vessel_specifications = vessel_specification,\n",
    "                                                                    window_specifications = window_specification,\n",
    "                                                                    condition = {'Origin': 'Node 11', 'Destination': 'Node 13'},\n",
    "                                                                    data = ['Node 14', current_velocity_type.CurrentVelocity.value]));\n",
    "\n",
    "#Inbound_Vessels_Condition2\n",
    "vessel_specification = vessel_specifications({vessel_characteristics.min_ge_Draught: 14.3},\n",
    "                                              'x',vessel_direction.inbound.value)\n",
    "\n",
    "window_specification = window_specifications(window_method.point_based.value,\n",
    "                                             {tidal_period.Flood.value: 0.5*knots,tidal_period.Ebb.value: accessibility.accessible.value},\n",
    "                                             {tidal_period.Flood.value: 0.3,tidal_period.Ebb.value:0})\n",
    "\n",
    "horizontal_tidal_window_inputs.append(horizontal_tidal_window_input(vessel_specifications = vessel_specification,\n",
    "                                                                    window_specifications = window_specification,\n",
    "                                                                    condition = {'Origin': 'Node 11', 'Destination': 'Node 13'},\n",
    "                                                                    data = ['Node 14', current_velocity_type.CurrentVelocity.value]));\n",
    "\n",
    "#Outbound_Vessels_Condition1\n",
    "vessel_specification = vessel_specifications({vessel_characteristics.max_lt_Draught: 14.3},\n",
    "                                              'x',vessel_direction.outbound.value)\n",
    "\n",
    "window_specification = window_specifications(window_method.point_based.value,\n",
    "                                             {tidal_period.Flood.value: 2*knots,tidal_period.Ebb.value: accessibility.accessible.value},\n",
    "                                             {tidal_period.Flood.value: 0,tidal_period.Ebb.value:0})\n",
    "\n",
    "horizontal_tidal_window_inputs.append(horizontal_tidal_window_input(vessel_specifications = vessel_specification,\n",
    "                                                                    window_specifications = window_specification,\n",
    "                                                                    condition = {'Origin': 'Node 13', 'Destination': 'Node 11'},\n",
    "                                                                    data = ['Node 14', current_velocity_type.CurrentVelocity.value]));\n",
    "\n",
    "#Outbound_Vessels_Condition2\n",
    "vessel_specification = vessel_specifications({vessel_characteristics.min_ge_Draught: 14.3},\n",
    "                                              'x',vessel_direction.outbound.value)\n",
    "\n",
    "window_specification = window_specifications(window_method.point_based.value,\n",
    "                                             {tidal_period.Flood.value: 0.5*knots,tidal_period.Ebb.value: accessibility.non_accessible.value},\n",
    "                                             {tidal_period.Flood.value: 0.3,tidal_period.Ebb.value:0})\n",
    "\n",
    "horizontal_tidal_window_inputs.append(horizontal_tidal_window_input(vessel_specifications = vessel_specification,\n",
    "                                                                    window_specifications = window_specification,\n",
    "                                                                    condition = {'Origin': 'Node 13', 'Destination': 'Node 11'},\n",
    "                                                                    data = ['Node 14', current_velocity_type.CurrentVelocity.value]));\n",
    "\n",
    "core.NetworkProperties.append_horizontal_tidal_restriction_to_network(FG,'Node 12',horizontal_tidal_window_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe0dcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_tidal_window_inputs = []\n",
    "\n",
    "#Inbound_Vessels_Condition1\n",
    "vessel_specification = vessel_specifications({vessel_characteristics.min_ge_Length: 180,\n",
    "                                              vessel_characteristics.min_ge_Draught: 11.4,\n",
    "                                              vessel_characteristics.max_lt_Draught: 14.3},\n",
    "                                              '(x and x and x)',vessel_direction.inbound.value)\n",
    "\n",
    "window_specification = window_specifications(window_method.critical_cross_current.value,\n",
    "                                             {tidal_period.Flood.value: 2*knots,tidal_period.Ebb.value: 1*knots})\n",
    "\n",
    "horizontal_tidal_window_inputs.append(horizontal_tidal_window_input(vessel_specifications = vessel_specification,\n",
    "                                                                    window_specifications = window_specification,\n",
    "                                                                    condition = {'Origin': 'Node 14', 'Destination': 'Node 17'},\n",
    "                                                                    data = ['Node 14', current_velocity_type.CurrentVelocity.value]));\n",
    "\n",
    "#Inbound_Vessels_Condition2\n",
    "vessel_specification = vessel_specifications({vessel_characteristics.min_ge_Draught: 14.3},\n",
    "                                              'x',vessel_direction.inbound.value)\n",
    "\n",
    "window_specification = window_specifications(window_method.point_based.value,\n",
    "                                             {tidal_period.Flood.value: 0.5*knots,tidal_period.Ebb.value: accessibility.accessible.value},\n",
    "                                             {tidal_period.Flood.value: 0.3,tidal_period.Ebb.value:0})\n",
    "\n",
    "horizontal_tidal_window_inputs.append(horizontal_tidal_window_input(vessel_specifications = vessel_specification,\n",
    "                                                                    window_specifications = window_specification,\n",
    "                                                                    condition = {'Origin': 'Node 14', 'Destination': 'Node 17'},\n",
    "                                                                    data = ['Node 14', current_velocity_type.CurrentVelocity.value]));\n",
    "\n",
    "#Outbound_Vessels_Condition1\n",
    "vessel_specification = vessel_specifications({vessel_characteristics.max_lt_Draught: 14.3},\n",
    "                                              'x',vessel_direction.outbound.value)\n",
    "\n",
    "window_specification = window_specifications(window_method.point_based.value,\n",
    "                                             {tidal_period.Flood.value: 2*knots,tidal_period.Ebb.value: accessibility.accessible.value},\n",
    "                                             {tidal_period.Flood.value: 0,tidal_period.Ebb.value:0})\n",
    "\n",
    "horizontal_tidal_window_inputs.append(horizontal_tidal_window_input(vessel_specifications = vessel_specification,\n",
    "                                                                    window_specifications = window_specification,\n",
    "                                                                    condition = {'Origin': 'Node 17', 'Destination': 'Node 14'},\n",
    "                                                                    data = ['Node 14', current_velocity_type.CurrentVelocity.value]));\n",
    "\n",
    "#Outbound_Vessels_Condition2\n",
    "vessel_specification = vessel_specifications({vessel_characteristics.min_ge_Draught: 14.3},\n",
    "                                              'x',vessel_direction.outbound.value)\n",
    "\n",
    "window_specification = window_specifications(window_method.point_based.value,\n",
    "                                             {tidal_period.Flood.value: 0.5*knots,tidal_period.Ebb.value: accessibility.non_accessible.value},\n",
    "                                             {tidal_period.Flood.value: 0.3,tidal_period.Ebb.value:0})\n",
    "\n",
    "horizontal_tidal_window_inputs.append(horizontal_tidal_window_input(vessel_specifications = vessel_specification,\n",
    "                                                                    window_specifications = window_specification,\n",
    "                                                                    condition = {'Origin': 'Node 17', 'Destination': 'Node 14'},\n",
    "                                                                    data = ['Node 14', current_velocity_type.CurrentVelocity.value]));\n",
    "\n",
    "core.NetworkProperties.append_horizontal_tidal_restriction_to_network(FG,'Node 15',horizontal_tidal_window_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d3552c",
   "metadata": {},
   "source": [
    "Choice about the bathymetry\n",
    "\n",
    "make all 16.4m until destination point, even if it is the MBL shown in the Haven Kaart\n",
    "Realistic MBL would be 16.4 at Node 15\n",
    "Then, 15.9 from Node 16 to 19 --> inside the basins\n",
    "\n",
    "Since the UKC policy is different in the NWW than inside the basins, it results in that the required water depth inside the basin is lower than in the NWW. UKC=0.5m for any vessel inside the basisn VS UKC=10%D for the NWW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7450e4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#water_level[1][col[0]][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf283d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(df_wlevel[df_wlevel.columns[0]])\n",
    "#print(df_wlevel[df_wlevel.columns[0]][:])\n",
    "#print(water_level[1][col[0]][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf55261",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "edge_count = []\n",
    "for edge in enumerate(FG.edges):\n",
    "    edge_count.append(FG.edges[edge[1]]['Info']['Depth'])\n",
    "\n",
    "colormap = cm.get_cmap('Blues', 256)\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.axis('off')\n",
    "ax = fig.add_axes([0, 0.4, 1, 0.3]);\n",
    "nx.draw(FG, positions, node_size = 5, node_color ='k', with_labels = False, horizontalalignment = 'right', verticalalignment = 'bottom', edge_color = edge_count, edge_cmap = colormap, edge_vmin = 0, arrows = False, width= 4)\n",
    "plt.axis('equal')\n",
    "cbar = fig.colorbar(cm.ScalarMappable(cmap=colormap), ax=ax, ticks=[0, 1])\n",
    "cbar.ax.set_yticklabels(['shallow','deep'])  # vertically oriented colorbar\n",
    "plt.title('Bathymetry of Port X',fontsize = 14, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49d2329",
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge in FG.edges:\n",
    "    print(edge,FG.edges[edge]['Info']['Tidal phase lag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25f7cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "core.Output.general_output(sim)\n",
    "core.Output.node_dependent_output(env.FG)\n",
    "core.Output.edge_dependent_output(env.FG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f8c941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(core)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f301862",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t0 = timepy.time()\n",
    "sim.run(duration = duration) # this statement runs the simulation\n",
    "t1 = timepy.time()\n",
    "total = t1-t0\n",
    "print(total) #simulation time in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9e5e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readjust_available_quay_lengths(aql,position):\n",
    "    for i in range(len(aql)):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        if aql[i - 1][1] < position and aql[i][1] > position:\n",
    "            break\n",
    "\n",
    "    if i == 1:\n",
    "        aql[i - 1][0] = 0\n",
    "        aql[i][0] = 0\n",
    "\n",
    "    elif i == len(aql) - 1:\n",
    "        aql[i - 1][0] = 0\n",
    "        aql[i][0] = 0\n",
    "\n",
    "    else:\n",
    "        aql[i - 1][0] = 0\n",
    "        aql[i][0] = 0\n",
    "\n",
    "    to_remove = []\n",
    "    for i in enumerate(aql):\n",
    "        for j in enumerate(aql):\n",
    "            if i[0] != j[0] and i[1][0] == 0 and j[1][0] == 0 and i[1][1] == j[1][1]:\n",
    "                to_remove.append(i[0])\n",
    "\n",
    "    for i in list(reversed(to_remove)):\n",
    "        aql.pop(i)\n",
    "\n",
    "    return aql\n",
    "\n",
    "def pick_minimum_length(aql,L):\n",
    "    available_quay_lengths = [0]\n",
    "    index_quay_position = 0\n",
    "    move_to_anchorage = False\n",
    "    for index in range(len(aql)):\n",
    "        if index == 0 or aql[index][1] == aql[index - 1][1] or aql[index][0] == 1:\n",
    "            if index == len(aql) - 1 and not index_quay_position:\n",
    "                move_to_anchorage = True\n",
    "            continue\n",
    "\n",
    "        available_quay_lengths.append(aql[index][1] - aql[index - 1][1])\n",
    "\n",
    "        for jndex in range(len(available_quay_lengths)):\n",
    "            if L <= available_quay_lengths[jndex]:\n",
    "                index_quay_position = index\n",
    "                print(index_quay_position)\n",
    "                break\n",
    "\n",
    "            elif jndex == len(available_quay_lengths) - 1 and not index_quay_position:\n",
    "                move_to_anchorage = True\n",
    "        \n",
    "        if index_quay_position != 0:\n",
    "            break\n",
    "\n",
    "    return index_quay_position, move_to_anchorage\n",
    "\n",
    "def adjust_available_quay_lengths(aql, L, index_quay_position):\n",
    "    if aql[index_quay_position - 1][0] == 0:\n",
    "        aql[index_quay_position - 1][0] = 1\n",
    "\n",
    "    if aql[index_quay_position][0] == 0 and aql[index_quay_position][1] == aql[index_quay_position - 1][1] + L:\n",
    "        aql[index_quay_position][0] = 1\n",
    "    else:\n",
    "        aql.insert(index_quay_position, [1, L + aql[index_quay_position - 1][1]])\n",
    "        aql.insert(index_quay_position + 1, [0, L + aql[index_quay_position - 1][1]])\n",
    "        \n",
    "    print(0.5 * L + aql[index_quay_position - 1][1])\n",
    "    return aql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d86d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vessels = sim.environment.vessels #extract vessels (entitie) from environment. It collects info while it moves through the network. That info is stored in the log file. The log file has \n",
    "env = sim.environment #extract the environment itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37aee9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', 500)\n",
    "vessel = vessels[1]\n",
    "print(vessel.type)\n",
    "df = pd.DataFrame.from_dict(vessel.log) #creates a data frame with all the info of vessels[0].\n",
    "df[20:80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b13442",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Timestamp'][51].timestamp()-df['Timestamp'][50].timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d6b3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(orig, dest):\n",
    "    wgs84 = pyproj.Geod(ellps='WGS84')\n",
    "    \n",
    "    distance = wgs84.inv(orig[0], orig[1], \n",
    "                         dest[0], dest[1])[2]\n",
    "    \n",
    "    return distance\n",
    "\n",
    "vessel_path_x = []\n",
    "vessel_path_t = []\n",
    "\n",
    "list_of_nodes = list(vessels[0].env.FG.nodes)\n",
    "\n",
    "for node in list_of_nodes:\n",
    "    if 'Origin' in vessels[0].env.FG.nodes[node].keys():\n",
    "        origin = node\n",
    "        \n",
    "    if 'Anchorage' in vessels[0].env.FG.nodes[node].keys():\n",
    "        list_of_nodes.remove(node)\n",
    "\n",
    "    if 'Junction' in vessels[0].env.FG.nodes[node].keys() and vessels[0].env.FG.nodes[node]['Junction'][0].name == ['waterway_access', 'waterway_access', 'anchorage_access', 'anchorage_access']:\n",
    "        virtual_anchorage = node\n",
    "\n",
    "for v in range(len(vessels)):\n",
    "    vessel_path_xt = []\n",
    "    vessel_path_tt = []\n",
    "    distance = 0\n",
    "    direction = 0\n",
    "    vessel_path_t0 = simulation_start.timestamp()\n",
    "    vessel_path_xt.append(distance)\n",
    "    vessel_path_tt.append(vessels[v].log[\"Timestamp\"][0].timestamp()-vessel_path_t0)\n",
    "    for t in range(1,len(vessels[v].log[\"Message\"])):  \n",
    "        if ('Deberthing stop' in vessels[v].log[\"Message\"][t] or ('Waiting in anchorage stop' in vessels[v].log[\"Message\"][t] and\n",
    "            vessels[v].log[\"Message\"][-1] == 'Sailing from node Node 2 to node Node 1 stop' and len(vessels[v].log[\"Message\"]) < 20)):\n",
    "            direction = 1\n",
    "        for node1 in list_of_nodes: \n",
    "            for node2 in list_of_nodes:\n",
    "                if (vessels[v].log[\"Message\"][t] == 'Sailing from node ' + node1 + ' to node ' + node2 + ' start' or \n",
    "                    vessels[v].log[\"Message\"][t] == 'Sailing from node ' + node1 + ' to node ' + node2 + ' stop'):\n",
    "                    if node2 == virtual_anchorage:\n",
    "                        distance_to_anchorage = calculate_distance((vessels[v].env.FG.nodes[origin]['geometry'].x,vessels[v].env.FG.nodes[origin]['geometry'].y),(vessels[v].env.FG.nodes[node2]['geometry'].x,vessels[v].env.FG.nodes[node2]['geometry'].y))\n",
    "                    if direction == 0:\n",
    "                        distance += calculate_distance((vessels[v].log[\"Geometry\"][t-1].x,vessels[v].log['Geometry'][t-1].y),(vessels[v].log[\"Geometry\"][t].x,vessels[v].log['Geometry'][t].y))\n",
    "                    elif direction == 1:\n",
    "                        distance -= calculate_distance((vessels[v].log[\"Geometry\"][t-1].x,vessels[v].log['Geometry'][t-1].y),(vessels[v].log[\"Geometry\"][t].x,vessels[v].log['Geometry'][t].y))\n",
    "                    vessel_path_xt.append(distance)\n",
    "                    vessel_path_tt.append(vessels[v].log[\"Timestamp\"][t].timestamp()-vessel_path_t0)\n",
    "                    break\n",
    "                    \n",
    "    vessel_path_x.append(vessel_path_xt)\n",
    "    vessel_path_t.append(vessel_path_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab5da1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tidal_window_start_stop_xloc(time,signal,correction,roots,start,end):\n",
    "    if roots != []:\n",
    "        for root_start in enumerate(roots):\n",
    "            if root_start[1] >= start:\n",
    "                break\n",
    "        for root_end in enumerate(roots):\n",
    "            if root_end[1] >= end:\n",
    "                break\n",
    "\n",
    "        def find_nearest(array, value):\n",
    "            array = np.asarray(array)\n",
    "            idx = (np.abs(array - value)).argmin()\n",
    "            return idx,array[idx]\n",
    "\n",
    "        idx,x = find_nearest(time,root_start[1])\n",
    "        ylim = correction\n",
    "\n",
    "        booleanlist = []\n",
    "        rootlist = []\n",
    "        rootlist.append(start)\n",
    "\n",
    "        if root_start != root_end:\n",
    "            if x >= root_start[1]:\n",
    "                if signal[idx] > ylim:\n",
    "                    booleanlist.append(0)\n",
    "                    booleanlist.append(1)\n",
    "                    rootlist.append(root_start[1])\n",
    "                else:\n",
    "                    booleanlist.append(1)\n",
    "                    booleanlist.append(0)\n",
    "                    rootlist.append(root_start[1])\n",
    "            else:\n",
    "                if signal[idx] > ylim:\n",
    "                    booleanlist.append(1)\n",
    "                    booleanlist.append(0)\n",
    "                    rootlist.append(root_start[1])\n",
    "                else:\n",
    "                    booleanlist.append(0)\n",
    "                    booleanlist.append(1)\n",
    "                    rootlist.append(root_start[1])\n",
    "\n",
    "            if booleanlist[0] == 0:\n",
    "                boolean = 1\n",
    "            else:\n",
    "                boolean = 0\n",
    "\n",
    "            for root in roots[(root_start[0]+1):root_end[0]]:\n",
    "                if boolean == 0:\n",
    "                    boolean = 1\n",
    "                elif boolean == 1:\n",
    "                    boolean = 0\n",
    "                booleanlist.append(boolean)\n",
    "                rootlist.append(root)\n",
    "        else:\n",
    "            boolean = 1\n",
    "            booleanlist.append(boolean)\n",
    "\n",
    "        rootlist.append(end)\n",
    "        if boolean == 0:\n",
    "            booleanlist.append(1)\n",
    "        elif boolean == 1:\n",
    "            booleanlist.append(0) \n",
    "    return booleanlist,rootlist\n",
    "\n",
    "def tidal_window_start_stop_polygon(booleanlist,rootlist,figylimits):\n",
    "    xfill_lists = []\n",
    "    yfill_lists = []\n",
    "    for i in range(len(booleanlist)):\n",
    "        xfill_list = []\n",
    "        yfill_list = []\n",
    "        if booleanlist[i] == 0 and i != len(booleanlist)-1:\n",
    "            xfill_list = [rootlist[i],rootlist[i],rootlist[i+1],rootlist[i+1]]\n",
    "            yfill_list = [figylimits[0],figylimits[1],figylimits[1],figylimits[0]]\n",
    "            xfill_lists.append(xfill_list)\n",
    "            yfill_lists.append(yfill_list)\n",
    "        elif i != len(booleanlist)-1:\n",
    "            xfill_list = [rootlist[i],rootlist[i],rootlist[i+1],rootlist[i+1]]\n",
    "            yfill_list = [figylimits[0],figylimits[1],figylimits[1],figylimits[0]]\n",
    "            xfill_lists.append(xfill_list)\n",
    "            yfill_lists.append(yfill_list)\n",
    "    return xfill_lists,yfill_lists\n",
    "\n",
    "def colors_tidal_window_polygons(xfill_lists,yfill_lists,booleanlist):\n",
    "    color = []\n",
    "    for i in range(len(xfill_lists)):\n",
    "        if booleanlist[i] == 0:\n",
    "            color.append('red')\n",
    "        elif booleanlist[i] == 2:\n",
    "            color.append('darkred')\n",
    "        else:\n",
    "            color.append('g')\n",
    "    return color        \n",
    "        \n",
    "def times_tidal_window(vertical_tidal_window_bools,vertical_tidal_window_roots,horizontal_tidal_window_bools,horizontal_tidal_window_roots): \n",
    "    list_of_times_vertical_tidal_window = []\n",
    "    list_of_times_horizontal_tidal_windows = []\n",
    "\n",
    "    for time in range(len(vertical_tidal_window_roots)):\n",
    "        list_of_times_vertical_tidal_window.append([vertical_tidal_window_roots[time],vertical_tidal_window_bools[time]])\n",
    "    for time in range(len(horizontal_tidal_window_roots)):\n",
    "        list_of_times_horizontal_tidal_windows.append([horizontal_tidal_window_roots[time],horizontal_tidal_window_bools[time]])\n",
    "\n",
    "    list_indexes = list(np.arange(0, len(list_of_times_horizontal_tidal_windows) + 1))\n",
    "    times_tidal_window = []\n",
    "    list_of_list_indexes = []\n",
    "\n",
    "    for time in list_of_times_vertical_tidal_window:\n",
    "        times_tidal_window.append(time)\n",
    "        list_of_list_indexes.append(0)\n",
    "    for time in list_of_times_horizontal_tidal_windows:\n",
    "        times_tidal_window.append(time)\n",
    "        list_of_list_indexes.append(1)\n",
    "\n",
    "    list_of_list_indexes = [x for _, x in sorted(zip(times_tidal_window, list_of_list_indexes))]\n",
    "    times_tidal_window.sort()\n",
    "    \n",
    "    indexes_to_be_removed = []\n",
    "    for list_index in list_indexes:\n",
    "        for time1 in range(len(times_tidal_window)):\n",
    "            if times_tidal_window[time1][1] == 0 and list_of_list_indexes[time1] == list_index:\n",
    "                for time2 in range(len(times_tidal_window)):\n",
    "                    if time2 > time1 and times_tidal_window[time2][1] == 1 and list_of_list_indexes[time2] == list_index:\n",
    "                        indexes = np.arange(time1 + 1, time2, 1)\n",
    "                        for index in indexes:\n",
    "                            indexes_to_be_removed.append(index)\n",
    "                        break\n",
    "\n",
    "    for time in range(len(times_tidal_window)):\n",
    "        if time == 0:\n",
    "            continue\n",
    "        elif times_tidal_window[time][1] == 1 and times_tidal_window[time - 1][1] == 1:\n",
    "            indexes_to_be_removed.append(time - 1)\n",
    "        elif times_tidal_window[time][1] == 0 and times_tidal_window[time - 1][1] == 0:\n",
    "            indexes_to_be_removed.append(time)\n",
    "\n",
    "    indexes_to_be_removed.sort()\n",
    "    indexes_to_be_removed = list(dict.fromkeys(indexes_to_be_removed))\n",
    "      \n",
    "    times_tidal_window_bools = []\n",
    "    times_tidal_window_roots = []\n",
    "    for time in times_tidal_window:\n",
    "        times_tidal_window_bools.append(time[1])\n",
    "        times_tidal_window_roots.append(time[0])\n",
    "    \n",
    "    return times_tidal_window_bools,times_tidal_window_roots,indexes_to_be_removed\n",
    "\n",
    "def cross_current_calculation(magnitude,direction,origin,location,destination):\n",
    "    origin_lat1 = FG.nodes[origin]['geometry'].x\n",
    "    origin_lon1 = FG.nodes[origin]['geometry'].y\n",
    "    destination_lat1 = FG.nodes[location]['geometry'].x\n",
    "    destination_lon1 = FG.nodes[location]['geometry'].y\n",
    "    fwd_azimuth1, _, _ = pyproj.Geod(ellps=\"WGS84\").inv(origin_lat1, origin_lon1,destination_lat1, destination_lon1)\n",
    "    origin_lat2 = FG.nodes[location]['geometry'].x\n",
    "    origin_lon2 = FG.nodes[location]['geometry'].y\n",
    "    destination_lat2 = FG.nodes[destination]['geometry'].x\n",
    "    destination_lon2 = FG.nodes[destination]['geometry'].y\n",
    "    fwd_azimuth2, _, _ = pyproj.Geod(ellps=\"WGS84\").inv(origin_lat2, origin_lon2,destination_lat2, destination_lon2)\n",
    "    cross_current_signal_at_node = []\n",
    "    for t in range(len(magnitude)):\n",
    "        cross_current_signal_at_node.append(np.max([abs(magnitude[t]*np.sin((direction[t]-fwd_azimuth2)/180*np.pi)),\n",
    "                                                    abs(magnitude[t]*np.sin((direction[t]-fwd_azimuth1)/180*np.pi))]))\n",
    "    return cross_current_signal_at_node\n",
    "\n",
    "def color_vessels(vessel,\n",
    "                  min_linewidth = 0.5,\n",
    "                  max_linewidth = 3,\n",
    "                  vessel_database = vdf,\n",
    "                  vessel_norm=mpl.colors.BoundaryNorm(boundaries=list(vdf['T_f']),\n",
    "                                                      ncolors=len(list(vdf['T_f'])), \n",
    "                                                      extend='max'),\n",
    "                  vessel_cmap = mpl.colorbar.cm.tab10):\n",
    "    if str(type(vessel)) == \"<class '__main__.Vessel'>\":\n",
    "        linewidth = vessel.T_f/(list(vdf['T_f'])[-1]-list(vdf['T_e'])[0])*max_linewidth+min_linewidth\n",
    "        for c in enumerate(vessel_cmap.colors[0:len(list(vdf['type']))]):\n",
    "            if vessel.T_f >= vessel_norm.boundaries[c[0]]:\n",
    "                color = c[1]\n",
    "            else:\n",
    "                break\n",
    "    else:\n",
    "        color = []\n",
    "        linewidth = []\n",
    "        for draught in vessel:\n",
    "            linewidth.append(draught/(list(vdf['T_f'])[-1]-list(vdf['T_e'])[0])*max_linewidth+min_linewidth)\n",
    "        for c in enumerate(vessel_cmap.colors[0:len(list(vdf['type']))]):\n",
    "            color.append(c[1])\n",
    "        \n",
    "    return color,linewidth\n",
    "\n",
    "def vessel_legend(axis,\n",
    "                  vessel_types=list(vdf['type']),\n",
    "                  vessel_draught=list(vdf['T_f']),\n",
    "                  min_linewidth = 0.5,\n",
    "                  max_linewidth = 3,\n",
    "                  vessel_database = vdf,\n",
    "                  vessel_norm=mpl.colors.BoundaryNorm(boundaries=list(vdf['T_f']),\n",
    "                                                      ncolors=len(list(vdf['T_f'])), \n",
    "                                                      extend='max'),\n",
    "                  vessel_cmap = mpl.colorbar.cm.tab10):\n",
    "    colors,linestyles = color_vessels(vessel_draught)\n",
    "    for vtype in enumerate(vessel_types):\n",
    "        axis.plot([0,0],[0,0],\n",
    "                  color=colors[vtype[0]],\n",
    "                  label=str(vtype[1]))\n",
    "    leg= axis.legend(loc='lower right',handlelength=8,ncol=2,bbox_to_anchor=(0.95, -0.25),frameon=False)\n",
    "    for line in leg.get_lines():\n",
    "        line.set_linewidth((max_linewidth-min_linewidth)*0.5+min_linewidth)\n",
    "        \n",
    "    plt.plot([0,0],[0,0],\n",
    "                  color='k',\n",
    "                  linewidth = list(vdf['T_e'])[0]/(list(vdf['T_f'])[-1]-list(vdf['T_e'])[0])*max_linewidth+min_linewidth,\n",
    "                  label=str(round(list(vdf['T_e'])[0],2)) +' m')\n",
    "    for vtype in enumerate(vessel_types):\n",
    "        plt.plot([0,0],[0,0],\n",
    "                  color='k',\n",
    "                  linewidth = vessel_draught[vtype[0]]/(list(vdf['T_f'])[-1]-list(vdf['T_e'])[0])*max_linewidth+min_linewidth,\n",
    "                  label=str(round(vessel_draught[vtype[0]],2)) +' m')\n",
    "    plt.legend(loc='lower right',handlelength=9,ncol=3,bbox_to_anchor=(1.35, -0.215),frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e225d8",
   "metadata": {},
   "source": [
    "# Vertical and Horizontal windows\n",
    "The model does the following:\n",
    "1) check the cross current for edges node14-node15-node16 and check the available water depth at VERY node\n",
    "2) calculates the roots (intersection to each part where required value and signal crossess)\n",
    "3) defines tidal windows and non-sailing parts --> discovers where is time available considering the overlapping of cross current and water depth requirement\n",
    "4) vessel sail if: there is room at the terminal + horizontal/vertical tidal window\n",
    "\n",
    "\n",
    "## ABOUT THE TWO PLOTS ON THE RIGHT - water levels and currents\n",
    "The green/red areas will show the tidal windows for the node that you select. For instance: \n",
    "\n",
    "    - water_level[1][7][1]]   \n",
    "  \n",
    "    - current_velocity[1][9][1],current_direction[1][9][1]\n",
    "Will show the an hypothetic vertical tidal window defined with water levels at 'node 8', and horizontal tidal window defined at 'node 10' (python starts at zero so python is always one lower).\n",
    "\n",
    "The max cross current can be modified at the input table, and it can be defined separately for each ship.\n",
    "\n",
    "The vertical tidal window can be modified with two parameters:\n",
    "- At the input table by defining the ukc + loaded draught --> required_water_level = vessels[0].metadata['ukc'] + vessels[0].T_f\n",
    "- By modifying the reference value for the water level signal (eta) with this line: ax3xlist = [eta+{h0} for eta in water_level[1][1][1]] --> the value {h0} value is the mean available water depth, which is defined from the mean water level --> as the mean water level is =0.00 m NAP, then h0 can be calculated from the MBL value by: h0=0.00-MBL --> if MBL=-16.4m NAP then h0=16.4m\n",
    "\n",
    "This means the vertical tidal window should be defined at the critical part of the NWW which is presente between node 15 and node 19 with a MBL=-15.9m NAP --> then h0=15.9m\n",
    "\n",
    "The horizontal tidal window is also shown at node 15, right at the point where the ship starts turns towards the access to 3ePH/Botlek area.\n",
    "\n",
    "Example:\n",
    "For an Aframax, required water depth is D+FWA+UKC=16.7m --> available water depth for h0+eta=15.9+0.8m meaning for high tide\n",
    "\n",
    "\n",
    "## IMPORTANT:\n",
    "The two plots on the left will never change no matter what you change in the next cell, as these visualize what the model calculates. The code calculation is done following the four steps explained before --> the ship check all nodes against required depth requirement, and checks edges 14-15-16 against the max cross current. The available water depth in each node is computed with the depth at each node and the water level at each node. If there is sufficient water depth, sufficiently low cross current, and a palce at the terminal, then it will sail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b2ac81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "terminal = vessels[0].env.FG.edges['Node 18','Node 19']['Terminal'][0]\n",
    "if terminal.type == 'quay':\n",
    "    max_available_quay_length = terminal.length.capacity\n",
    "if terminal.type == 'jetty':\n",
    "    max_available_quay_length = 5\n",
    "\n",
    "vesseltje = vessels[0]\n",
    "start = 0\n",
    "end =  10*12.5*60*60\n",
    "end_cor = 5*12.5*60*60\n",
    "ax3xlist = [eta+depth[1][16] for eta in water_level[1][16][1]] #let's define it at node 15 to visualize when we have the critical bed level of MBL=-16.4m NAP\n",
    "ax3ylist = [t-simulation_start.timestamp() for t in water_level[1][16][0]] \n",
    "ax4xlist = cross_current_calculation(current_velocity[1][14][1],current_direction[1][14][1],'Node 14','Node 15','Node 16') # let's show the cross-current at the node 15 when the ship turns towards the access to 3ePH/Botlek area. This point is subsequent to Node 14: Scheurkade\n",
    "ax4ylist = [t-simulation_start.timestamp() for t in current_velocity[1][14][0]]\n",
    "required_water_level = vesseltje.metadata['ukc'] + vesseltje.T_f\n",
    "root_interp_water_level_at_edge = sc.interpolate.CubicSpline(ax3ylist,[x-required_water_level for x in ax3xlist])\n",
    "root_interp_cross_current_at_edge = sc.interpolate.CubicSpline(ax4ylist,[abs(x)-vessels[0].metadata['max_cross_current'] for x in ax4xlist])\n",
    "if root_interp_water_level_at_edge.roots() != []:\n",
    "    stst_vtw,roots_vtw = tidal_window_start_stop_xloc(ax3ylist,ax3xlist,required_water_level,root_interp_water_level_at_edge.roots(),start,end)\n",
    "else:\n",
    "    stst_vtw,roots_vtw = [],[]\n",
    "if root_interp_cross_current_at_edge.roots() != []:\n",
    "    stst_htw,roots_htw = tidal_window_start_stop_xloc(ax4ylist,ax4xlist,-vessels[0].metadata['max_cross_current'],root_interp_cross_current_at_edge.roots(),start,end)\n",
    "else:\n",
    "    stst_htw,roots_htw = [],[]\n",
    "    \n",
    "stst_tw,roots_tw,indexes_to_be_removed = times_tidal_window(stst_vtw,roots_vtw,stst_htw,roots_htw)\n",
    "if len(roots_vtw) >= 2 and len(roots_htw) >= 2:\n",
    "    for i in indexes_to_be_removed:\n",
    "        if stst_tw[i] == 0:\n",
    "            stst_tw[i] = 2   \n",
    "        elif stst_tw[i] == 1:\n",
    "            stst_tw[i] = 0\n",
    "    \n",
    "if terminal.type == 'quay':\n",
    "    time_available_quay_length = []\n",
    "    available_quay_length = []\n",
    "    quay_level = 0\n",
    "    time_available_quay_length.append(0)\n",
    "    available_quay_length.append(quay_level)\n",
    "    for t in range(len(terminal.log[\"Message\"])):\n",
    "        time_available_quay_length.append(terminal.log[\"Timestamp\"][t].timestamp()-simulation_start.timestamp())\n",
    "        available_quay_length.append(quay_level)\n",
    "        time_available_quay_length.append(terminal.log[\"Timestamp\"][t].timestamp()-simulation_start.timestamp())\n",
    "        available_quay_length.append(terminal.log[\"Value\"][t])\n",
    "        quay_level = terminal.log[\"Value\"][t]\n",
    "        \n",
    "if terminal.type == 'jetty':\n",
    "    time_available_quay_length = []\n",
    "    available_quay_length = []\n",
    "    quay_level = 0\n",
    "    time_available_quay_length.append(0)\n",
    "    available_quay_length.append(quay_level)\n",
    "    for t in range(len(terminal.log[\"Message\"])):\n",
    "        time_available_quay_length.append(terminal.log[\"Timestamp\"][t].timestamp()-simulation_start.timestamp())\n",
    "        available_quay_length.append(quay_level)\n",
    "        time_available_quay_length.append(terminal.log[\"Timestamp\"][t].timestamp()-simulation_start.timestamp())\n",
    "        available_quay_length.append(terminal.log[\"Value\"][t])\n",
    "        quay_level = terminal.log[\"Value\"][t]\n",
    "    \n",
    "anchorage = vessels[0].env.FG.nodes['Node 20']['Anchorage'][0]\n",
    "time_anchorage_occupation = []\n",
    "anchorage_occupation = []\n",
    "anchorage_capacity = 0\n",
    "time_anchorage_occupation.append(0)\n",
    "anchorage_occupation.append(anchorage_capacity)\n",
    "for t in range(len(anchorage.log[\"Message\"])):\n",
    "    time_anchorage_occupation.append(anchorage.log[\"Timestamp\"][t].timestamp()-simulation_start.timestamp())\n",
    "    anchorage_occupation.append(anchorage_capacity)\n",
    "    time_anchorage_occupation.append(anchorage.log[\"Timestamp\"][t].timestamp()-simulation_start.timestamp())\n",
    "    anchorage_occupation.append(anchorage.log[\"Value\"][t])\n",
    "    anchorage_capacity = anchorage.log[\"Value\"][t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8445f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vessel_types = []\n",
    "for v in range(0,len(vessels)-24): # this part filters the first vessels generated with the minus sign --> use for warming-up time\n",
    "    if len(vessels[v].log['Message']) > 15: #this part filters out all vessels with a timestamp lower than X (in the line '> X') rows, meaning all vessels that do not enter the port\n",
    "        vessel_types.append(vessels[v].type)\n",
    "vessel_types\n",
    "dataframe = pd.DataFrame(vessel_types) \n",
    "dataframe.to_csv('Sim_ref_T1.1.csv',index=False) #export all vessels of the simulation, which can be usede to compute the throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd6c3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#water_level[1][14][1] #it is in fact ''node 15''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fac15e",
   "metadata": {},
   "source": [
    "## Traffic intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cc16b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_count = np.zeros(len(FG.edges))\n",
    "for v in vessels:\n",
    "    df = pd.DataFrame.from_dict(v.log)\n",
    "    for message in df['Message']:\n",
    "        if 'Sailing' in message and 'stop' in message:\n",
    "            r = re.search('Sailing from node (.+?) to node (.+?) stop', message)\n",
    "            if r:\n",
    "                node1 = r.group(1)\n",
    "                node2 = r.group(2)\n",
    "            for e in enumerate(FG.edges):\n",
    "                if (node1,node2) == e[1]:\n",
    "                    edge_count[e[0]] += 1\n",
    "\n",
    "edge_count_final = np.zeros(len(FG.edges))\n",
    "for e in enumerate(FG.edges):\n",
    "    for e2 in enumerate(FG.edges):\n",
    "        if [e[1][0],e[1][1]] == [e2[1][1],e2[1][0]]:\n",
    "            edge_count_final[e[0]] = edge_count[e[0]]+edge_count[e2[0]]\n",
    "            edge_count_final[e2[0]] = edge_count_final[e[0]] \n",
    "            break\n",
    "\n",
    "colormap = cm.get_cmap('RdYlBu_r', 256)\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "ax.axis('off')\n",
    "ax = fig.add_axes([0, 0.4, 1, 0.3]);\n",
    "nx.draw(FG, positions, node_size = 10, node_color ='k', with_labels = True, horizontalalignment = 'right', verticalalignment = 'bottom', edge_color = edge_count_final, edge_cmap = colormap, arrows = False, width= 4)\n",
    "plt.axis('equal')\n",
    "cbar = fig.colorbar(cm.ScalarMappable(cmap=colormap), ax=ax, ticks=[0, 1])\n",
    "cbar.ax.set_yticklabels(['low','high'])  # vertically oriented colorbar\n",
    "plt.title('Traffic Intensity of Port X',fontsize = 14, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd81583c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Occupancy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5801ad36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_occupancy(infrastructure,duration):\n",
    "    time_infrastructure_occupation = []\n",
    "    infrastructure_occupation = []\n",
    "    infrastructure_capacity = 0\n",
    "    time_infrastructure_occupation.append(0)\n",
    "    t = False\n",
    "    infrastructure_occupation.append(infrastructure_capacity)\n",
    "    for t in range(len(infrastructure.log[\"Message\"])):\n",
    "        time_infrastructure_occupation.append(infrastructure.log[\"Timestamp\"][t].timestamp()-simulation_start.timestamp())\n",
    "        infrastructure_occupation.append(infrastructure_capacity)\n",
    "        time_infrastructure_occupation.append(infrastructure.log[\"Timestamp\"][t].timestamp()-simulation_start.timestamp())\n",
    "        infrastructure_occupation.append(infrastructure.log[\"Value\"][t])\n",
    "        infrastructure_capacity = infrastructure.log[\"Value\"][t]\n",
    "    \n",
    "    if t:\n",
    "        time_infrastructure_occupation.append(duration)\n",
    "        infrastructure_occupation.append(infrastructure.log[\"Value\"][t])\n",
    "    return time_infrastructure_occupation,infrastructure_occupation\n",
    "\n",
    "def occupancy_calculation(infrastructure,duration):\n",
    "    time_infrastructure_occupation = []\n",
    "    infrastructure_occupation = []\n",
    "    infrastructure_capacity = 0\n",
    "    t = 0\n",
    "    for t in range(len(infrastructure.log[\"Message\"])):\n",
    "        if t == 0:\n",
    "            time_infrastructure_occupation.append(infrastructure.log[\"Timestamp\"][t].timestamp()-simulation_start.timestamp())\n",
    "            infrastructure_occupation.append(infrastructure_capacity)\n",
    "        else:\n",
    "            time_infrastructure_occupation.append(infrastructure.log[\"Timestamp\"][t].timestamp()-infrastructure.log[\"Timestamp\"][t-1].timestamp())\n",
    "            infrastructure_occupation.append(infrastructure.log[\"Value\"][t-1])\n",
    "        infrastructure_capacity = infrastructure.log[\"Value\"][t]\n",
    "    if not t:\n",
    "        time_infrastructure_occupation.append(0)\n",
    "        infrastructure_occupation.append(infrastructure_capacity)\n",
    "        time_infrastructure_occupation.append(duration)\n",
    "        infrastructure_occupation.append(infrastructure_capacity)\n",
    "    return time_infrastructure_occupation,infrastructure_occupation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d023d34",
   "metadata": {},
   "source": [
    "## Terminal occupation output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73811feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(terminal.log)\n",
    "df\n",
    "\n",
    "terminal_edges = [['Node 18','Node 19']]\n",
    "fig,ax = plt.subplots(figsize=(16, 9))\n",
    "start = 0\n",
    "end = duration\n",
    "\n",
    "for edge in enumerate(terminal_edges):\n",
    "    terminal = vessels[0].env.FG.edges[edge[1]]['Terminal'][0]\n",
    "    plt.plot(plot_occupancy(terminal,duration)[0],plot_occupancy(terminal,duration)[1])\n",
    "    if edge[0] == 0:\n",
    "        ymax = np.max(occupancy_calculation(terminal,duration)[1])\n",
    "    elif np.max(occupancy_calculation(terminal,duration)[1]) > ymax:\n",
    "        ymax = np.max(occupancy_calculation(terminal,duration)[1])\n",
    "\n",
    "plt.xlabel('Time [s]')\n",
    "plt.xlim([start,end])\n",
    "plt.ylabel('Number of vessels')\n",
    "plt.ylim([0,math.ceil(1.1*ymax)])\n",
    "plt.title(\"Terminal occupation\", fontweight='bold', pad = 12)\n",
    "plt.legend(['Terminal 1'])\n",
    "plt.show()\n",
    "\n",
    "time_quay_occupation,quay_occupation = occupancy_calculation(terminal,duration)\n",
    "\n",
    "weighted_quay_occupancy = []\n",
    "for t in range(len(quay_occupation)):\n",
    "    weighted_quay_occupancy.append(quay_occupation[t]/max_available_quay_length*time_quay_occupation[t])\n",
    "      \n",
    "terminal_occupancy = np.sum(weighted_quay_occupancy)/duration\n",
    "print('terminal occupancy:',terminal_occupancy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ea6460",
   "metadata": {},
   "source": [
    "## Anchorage occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c720b58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# anchorage = vessels[0].env.FG.nodes['Node 20']['Anchorage'][0]\n",
    "df = pd.DataFrame.from_dict(anchorage.log)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe091bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchorage_nodes = ['Node 20','Node 21']\n",
    "fig,ax = plt.subplots(figsize=(16, 9))\n",
    "start = 0\n",
    "end = duration\n",
    "for node in enumerate(anchorage_nodes):\n",
    "    anchorage = vessels[0].env.FG.nodes[node[1]]['Anchorage'][0]\n",
    "    plt.plot(plot_occupancy(anchorage,duration)[0],plot_occupancy(anchorage,duration)[1])\n",
    "    if node[0] == 0:\n",
    "        ymax = np.max(occupancy_calculation(anchorage,duration)[1])\n",
    "    elif np.max(occupancy_calculation(anchorage,duration)[1]) > ymax:\n",
    "        ymax = np.max(occupancy_calculation(anchorage,duration)[1])\n",
    "    \n",
    "plt.xlabel('Time [s]')\n",
    "plt.xlim([start,end])\n",
    "plt.ylabel('Number of vessels')\n",
    "plt.ylim([0,math.ceil(1.1*ymax)])\n",
    "plt.title(\"Anchorage occupation\", fontweight='bold', pad = 12)\n",
    "plt.legend(['Anchorage 1','Anchorage 2'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926277b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchorage = vessels[0].env.FG.nodes['Node 20']['Anchorage'][0]\n",
    "time_anchorage_occupation,anchorage_occupation = occupancy_calculation(anchorage,duration)\n",
    "\n",
    "list_anchorage_occupancy = []\n",
    "for t in range(len(time_anchorage_occupation)):\n",
    "    list_anchorage_occupancy.append(anchorage_occupation[t]*(time_anchorage_occupation[t]))\n",
    "\n",
    "print('Anchorage occupancy:', np.sum(list_anchorage_occupancy)/(duration*anchorage.anchorage_area['Node 20'].capacity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31ac4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(anchorage.log)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3955658d",
   "metadata": {},
   "source": [
    "## Output parameters plots and time-averaged values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2d7679",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "turnaround_times = []\n",
    "waiting_times = []\n",
    "sailing_times = []\n",
    "service_times = []\n",
    "list_berth_productivity = []\n",
    "number_of_vessels_served = 0\n",
    "for v in range(len(vessels)):\n",
    "    v = v\n",
    "    start_node = []\n",
    "    end_node = []\n",
    "    waiting_time = 0\n",
    "    sailing_time = 0\n",
    "    berth_productivity = 1\n",
    "    was_at_berth = False\n",
    "    for t in range(len(vessels[v].log[\"Message\"])):\n",
    "        if t == 0:\n",
    "            turnaround_start = vessels[v].log[\"Timestamp\"][t].timestamp()\n",
    "            text = vessels[v].log[\"Message\"][t]\n",
    "            match = re.search('from node (.+?) to', text)\n",
    "            if match:\n",
    "                start_node = match.group(1)\n",
    "        if 'Waiting in anchorage stop' in vessels[v].log[\"Message\"][t]:\n",
    "            waiting_time = vessels[v].log['Value'][t]\n",
    "        if 'Sailing from node' in vessels[v].log[\"Message\"][t] and 'stop' in vessels[v].log[\"Message\"][t]:\n",
    "            sailing_time += vessels[v].log[\"Timestamp\"][t].timestamp()-vessels[v].log[\"Timestamp\"][t-1].timestamp()\n",
    "        if 'Loading stop' in vessels[v].log[\"Message\"][t]:\n",
    "            service_time = vessels[v].log[\"Timestamp\"][t].timestamp()-vessels[v].log[\"Timestamp\"][t-3].timestamp()\n",
    "            was_at_berth = True\n",
    "        if 'Deberthing start' in vessels[v].log[\"Message\"][t] and 'Waiting for tidal window stop' in vessels[v].log[\"Message\"][t-1]:\n",
    "            berth_productivity = service_time/(service_time+vessels[v].log[\"Value\"][t-1])\n",
    "        if t == len(vessels[v].log[\"Message\"])-1:\n",
    "            turnaround_end = vessels[v].log[\"Timestamp\"][t].timestamp()\n",
    "            text = vessels[v].log[\"Message\"][t]\n",
    "            match = re.search('to node (.+?) stop', text)\n",
    "            if match:\n",
    "                end_node = match.group(1)\n",
    "\n",
    "    if start_node == end_node and end_node != []:\n",
    "        turnaround_times.append(turnaround_end-turnaround_start)\n",
    "        waiting_times.append(waiting_time)\n",
    "        sailing_times.append(sailing_time)\n",
    "        if was_at_berth == True:\n",
    "            number_of_vessels_served += 1\n",
    "            service_times.append(service_time)\n",
    "        else:\n",
    "            pass\n",
    "        list_berth_productivity.append(berth_productivity)\n",
    "\n",
    "fig,(ax1,ax2,ax3,ax4) = plt.subplots(1,4,figsize=(16, 3))\n",
    "ax1.hist(turnaround_times, bins=range(0,300000,5000))\n",
    "ax1.set_title('Turnaround times \\n (Mean: '+ str(round(np.mean(turnaround_times),2)) + ' s)')\n",
    "ax1.set_xlabel('time [s]')\n",
    "\n",
    "ax2.hist(waiting_times, bins=range(0,90000,1000))\n",
    "ax2.set_title('Waiting times \\n (Mean: '+ str(round(np.mean(waiting_times),2)) + ' s)')\n",
    "ax2.set_xlabel('time [s]')\n",
    "\n",
    "ax3.hist(service_times, bins=range(50000,75000,250))\n",
    "ax3.set_title('Service times \\n (Mean: '+ str(round(np.mean(service_times),2)) + ' s)')\n",
    "ax3.set_xlabel('time [s]')\n",
    "\n",
    "ax4.hist(sailing_times, bins=range(40000,80000,100))\n",
    "ax4.set_title('Sailing times \\n (Mean: '+ str(round(np.mean(sailing_times),2)) + ' s)')\n",
    "ax4.set_xlabel('time [s]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62699bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average berth productivity:',np.mean(list_berth_productivity))\n",
    "\n",
    "counts, bins = np.histogram(waiting_times, bins=range(0,300000,5000))\n",
    "counts\n",
    "# counts, bins = np.histogram(turnaround_times, bins=range(0,300000,5000))\n",
    "# counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36b10e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The total number of vessels served is',number_of_vessels_served, 'in a time of', duration, 's.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd5101c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(waiting_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b27baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(turnaround_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16050ab1",
   "metadata": {},
   "source": [
    "## Vessel encounters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f8f162",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_encounters = 0\n",
    "for v1 in range(len(vessels)):\n",
    "    for v2 in range(len(vessels[(v1+1):])):\n",
    "        v2 = v2+(v1+1)\n",
    "        for t1 in range(len(vessels[v1].log[\"Message\"])):\n",
    "            if 'Sailing from node' in vessels[v1].log[\"Message\"][t1] and 'stop' in vessels[v1].log[\"Message\"][t1]:\n",
    "                text1 = vessels[v1].log[\"Message\"][t1]\n",
    "                match1 = re.search('from node (.+?) to', text1)\n",
    "                match2 = re.search('to node (.+?) stop', text1)\n",
    "                if match1 and match2:\n",
    "                    node1 = match1.group(1)\n",
    "                    node2 = match2.group(1)\n",
    "                    time_start1 = vessels[v1].log[\"Timestamp\"][t1-1].timestamp()\n",
    "                    time_stop1 = vessels[v1].log[\"Timestamp\"][t1].timestamp()\n",
    "                    for t2 in range(len(vessels[v2].log[\"Message\"])):\n",
    "                        if 'Sailing from node' in vessels[v2].log[\"Message\"][t2] and 'stop' in vessels[v2].log[\"Message\"][t2]:\n",
    "                            time_start2 = vessels[v2].log[\"Timestamp\"][t2-1].timestamp()\n",
    "                            time_stop2 = vessels[v2].log[\"Timestamp\"][t2].timestamp()\n",
    "                            text2 = vessels[v2].log[\"Message\"][t2]\n",
    "                            if (time_start2 <= time_stop1 and time_start2 >= time_start1) or (time_stop2 <= time_stop1 and time_stop2 >= time_start1):\n",
    "                                if node2 + ' to' in text2 and node1 + ' stop' in text2:\n",
    "                                    number_of_encounters += 1          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94965b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The total number of vessel encounters is',number_of_encounters, 'in a time of', duration, 's.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52ff4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225ea181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed2bearing(east_velocity, north_velocity, principal_direction):\n",
    "    \"\"\"\n",
    "    Function to calculate the velocity components in a reference frame parallel to the principal direction of the\n",
    "    velocity cluster.\n",
    "    :param east_velocity: velocity in Eastern direction (float)\n",
    "    :param north_velocity: velocity in Northern direction (float)\n",
    "    :param principal_direction: principal direction in degrees in fixed reference frame North-East (float)\n",
    "    :return: coordinates in a reference frame relative to the given principal direction (tup)\n",
    "    \"\"\"\n",
    "    bearing_rad = np.radians(principal_direction)\n",
    "    x_velocity = np.cos(bearing_rad) * east_velocity + np.sin(bearing_rad) * north_velocity\n",
    "    y_velocity = -1 * np.sin(bearing_rad) * east_velocity + np.cos(bearing_rad) * north_velocity\n",
    "    return x_velocity, y_velocity\n",
    "\n",
    "def fixed2principal_components(east_velocity_list, north_velocity_list):\n",
    "    \"\"\"\n",
    "    Function to calculate the principal components from a cluster of velocities.\n",
    "    :param east_velocity_list: list of velocities in Eastern direction (list)\n",
    "    :param north_velocity_list: list of velocities in Northern direction (list)\n",
    "    :return: principal direction in degrees (float)\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=2)  # whiten=True can be added\n",
    "    X = np.column_stack((east_velocity_list, north_velocity_list))\n",
    "    X_pca = pca.fit(X)\n",
    "\n",
    "    y_pca = pca.components_[:, 1][0]  # - pca.mean_[1]\n",
    "    x_pca = pca.components_[:, 0][0]  # - pca.mean[0]\n",
    "    theta = np.arctan2(y_pca, x_pca)\n",
    "    alpha = np.degrees(theta)\n",
    "\n",
    "    # Correction for positive alpha in coordinate system with positive x-direction upestuary\n",
    "    if alpha >= 0:\n",
    "        alpha = alpha - 180  # in degrees\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d9bbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = FG\n",
    "node = [14,'Node 15']\n",
    "lon_vel = []\n",
    "lat_vel = []\n",
    "t_vel = network.nodes[node[1]]['Info']['Current direction'][0]\n",
    "cur_mag = network.nodes[node[1]]['Info']['Current velocity'][1]\n",
    "cur_dir = network.nodes[node[1]]['Info']['Current direction'][1]\n",
    "for i in range(len(t_vel)):\n",
    "    lon_vel.append(cur_mag[i] * np.sin(cur_dir[i] / 180 * np.pi))\n",
    "    lat_vel.append(cur_mag[i] * np.cos(cur_dir[i] / 180 * np.pi))\n",
    "prim = fixed2principal_components(lon_vel,lat_vel)\n",
    "vel = [fixed2bearing(x, y, prim) for x, y in zip(lon_vel,lat_vel)]\n",
    "vel_prim = [x[0] for x in vel]\n",
    "interp = sc.interpolate.CubicSpline(t_vel, vel_prim)\n",
    "roots = interp.roots()\n",
    "times_tidal_periods = []\n",
    "prev_root = 0\n",
    "for root in interp.roots():\n",
    "    if root > t_vel[0] and root < t_vel[-1] and vel_prim[bisect.bisect_right(t_vel, root)] > 0 and root-prev_root > 0.25*12.5*60*60:\n",
    "        times_tidal_periods.append([root, 'Flood Start'])\n",
    "        prev_root = root\n",
    "    elif root > t_vel[0] and root < t_vel[-1] and vel_prim[bisect.bisect_right(t_vel, root)] < 0 and root-prev_root > 0.25*12.5*60*60:\n",
    "        times_tidal_periods.append([root, 'Ebb Start'])\n",
    "        prev_root = root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4c692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curvel = pd.read_csv(r'C:\\Users\\floorbakker\\OpenTNSim\\notebooks\\testdata_OSR\\6PE_magnitude.csv',delimiter=',') \n",
    "curdir = pd.read_csv(r'C:\\Users\\floorbakker\\OpenTNSim\\notebooks\\testdata_OSR\\6PE_angle.csv',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6357d2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "node = 'Node 15'\n",
    "t_vel = network.nodes[node]['Info']['Current direction'][0]\n",
    "cur_mag = network.nodes[node]['Info']['Current velocity'][1]\n",
    "cur_dir = [y/180*np.pi for y in network.nodes[node]['Info']['Current direction'][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0527b144",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_vel = []\n",
    "lat_vel = []\n",
    "for i in range(len(t_vel)):\n",
    "    lon_vel.append(cur_mag[i] * np.sin(cur_dir[i]))\n",
    "    lat_vel.append(cur_mag[i] * np.cos(cur_dir[i]))\n",
    "prim = fixed2principal_components(lon_vel,lat_vel)\n",
    "vel = [fixed2bearing(x, y, prim) for x, y in zip(lon_vel,lat_vel)]\n",
    "vel_prim = [x[0] for x in vel]\n",
    "interp = sc.interpolate.CubicSpline(t_vel, vel_prim)\n",
    "roots = interp.roots()\n",
    "times_tidal_periods = []\n",
    "prev_root = 0\n",
    "for root in interp.roots():\n",
    "    if root > t_vel[0] and root < t_vel[-1] and vel_prim[bisect.bisect_right(t_vel, root)] > 0 and root-prev_root > 0.25*12.5*60*60:\n",
    "        times_tidal_periods.append([root, 'Flood Start'])\n",
    "        prev_root = root\n",
    "    elif root > t_vel[0] and root < t_vel[-1] and vel_prim[bisect.bisect_right(t_vel, root)] < 0 and root-prev_root > 0.25*12.5*60*60:\n",
    "        times_tidal_periods.append([root, 'Ebb Start'])\n",
    "        prev_root = root\n",
    "\n",
    "plt.plot(t_vel,cur_mag,'grey')\n",
    "plt.plot(t_vel,interp(t_vel),'k')\n",
    "plt.axhline(0,color='k',linestyle='--')\n",
    "previous_time = t_vel[0]\n",
    "duration = 5*24*60*60\n",
    "xlimmin = t_vel[0]\n",
    "xlimmax = xlimmin+duration\n",
    "ylimmin = -1#1.25*np.min(vel_prim)\n",
    "ylimmax = 1.5#1.25*np.max(vel_prim)\n",
    "for times in times_tidal_periods:  \n",
    "    if times[1] == 'Flood Start':\n",
    "        plt.fill([previous_time,previous_time,times[0],times[0]],[ylimmin,ylimmax,ylimmax,ylimmin],color='grey',alpha=0.4)\n",
    "        if times[0] >= xlimmin and times[0] <= xlimmax:\n",
    "            plt.text(np.mean([previous_time,times[0]]),ylimmax*.925,'Ebb',horizontalalignment  = 'center')\n",
    "    if times[1] == 'Ebb Start':\n",
    "        plt.fill([previous_time,previous_time,times[0],times[0]],[ylimmin,ylimmax,ylimmax,ylimmin],color='k',alpha=0.4)\n",
    "        if times[0] >= xlimmin and times[0] <= xlimmax:\n",
    "            plt.text(np.mean([previous_time,times[0]]),ylimmax*1.025,'Flood',horizontalalignment  = 'center')\n",
    "    previous_time = times[0]\n",
    "plt.xlim([xlimmin,xlimmax])\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylim([ylimmin,ylimmax])\n",
    "plt.ylabel('Current velocity along \\n principle component (m/s)');\n",
    "plt.plot(network.nodes[node]['Info']['Water level'][0],\n",
    "         network.nodes[node]['Info']['Water level'][1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e18847c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    def __init__(self,start_time,network):\n",
    "        self.now = start_time\n",
    "        self.FG = network\n",
    "\n",
    "class Vessel:\n",
    "    def __init__(self,start_time,T,ukc,name,type,v,L,B,mccur,mwt,bound,network,start_node,end_node):\n",
    "        self.env = Environment(start_time,network)\n",
    "        self.T_f = T\n",
    "        self.L = L\n",
    "        self.v = v\n",
    "        self.B = B\n",
    "        self.ukc = ukc\n",
    "        self.metadata = {}\n",
    "        self.metadata['ukc'] = ukc\n",
    "        self.metadata['max_cross_current'] = mccur\n",
    "        self.metadata['max_waiting_time'] = mwt\n",
    "        self.bound = bound\n",
    "        self.name = name\n",
    "        self.type = type\n",
    "        self.route = nx.dijkstra_path(self.env.FG, start_node, end_node)\n",
    "        \n",
    "def calc_distance(node1,node2):\n",
    "    route = nx.dijkstra_path(FG,node1,node2)\n",
    "    distance = 0\n",
    "    previous_node = node1\n",
    "    for node in route:\n",
    "        distance += calculate_distance([FG.nodes[previous_node]['geometry'].x,FG.nodes[previous_node]['geometry'].y],\n",
    "                                       [FG.nodes[node]['geometry'].x,FG.nodes[node]['geometry'].y])\n",
    "        previous_node = node\n",
    "    return distance\n",
    "\n",
    "\n",
    "distance_to_anchorage = calc_distance('Node 1','Node 3')\n",
    "horizontal_tidal_restriction_distance = calc_distance('Node 1','Node 15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519800ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tidal_window_visualization(start_node,end_node,T_lower_limit,T_upper_limit,T_ticks):\n",
    "    T_list = np.arange(T_lower_limit,T_upper_limit,T_ticks)\n",
    "    route = nx.dijkstra_path(FG, start_node, end_node)\n",
    "    vesseltjes = []\n",
    "    vesseltje = []\n",
    "    print(start_node,end_node)\n",
    "    for i in range(len(T_list)):\n",
    "        vesseltje.append(Vessel(start_time = simulation_start.timestamp(),\n",
    "                                T = T_list[i],\n",
    "                                L = 149,\n",
    "                                v = 4.5,\n",
    "                                B = 27,\n",
    "                                ukc = 0,\n",
    "                                mccur = 0,\n",
    "                                mwt = 64*60*60,\n",
    "                                bound = 'in',\n",
    "                                typ = 'Handysize',\n",
    "                                network = network,\n",
    "                                start_node = start_node,\n",
    "                                end_node = end_node))\n",
    "    vesseltjes.append(vesseltje)\n",
    "    tws = []\n",
    "    for vesseltje in range(len(vesseltjes)):\n",
    "        tw = []\n",
    "        for v in range(len(vesseltjes[vesseltje])):\n",
    "            tw.append(core.VesselTrafficService.provide_sail_in_times_tidal_window(vesseltjes[vesseltje][v],\n",
    "                                                                                   route = vesseltjes[vesseltje][v].route,\n",
    "                                                                                   plot=False,\n",
    "                                                                                   sailing_time_correction=False,\n",
    "                                                                                   visualization_calculation=True,\n",
    "                                                                                   ukc_calc=False))\n",
    "        tws.append(tw)\n",
    "\n",
    "    twtjes = []\n",
    "    end =  10*12.5*60*60\n",
    "    s = simulation_start.timestamp()\n",
    "    for vesseltje in range(len(vesseltjes)):\n",
    "        twtje = []\n",
    "        for v in range(len(vesseltjes[vesseltje])):\n",
    "            if tws[vesseltje][v] != []:\n",
    "                if tws[vesseltje][v][0][1] == 'Stop':\n",
    "                    twtje.append([[tws[vesseltje][v][t[0]-1][0]-s,t[1][0]-s] for t in enumerate(tws[vesseltje][v]) if t[1][1] == 'Start'])\n",
    "                else:\n",
    "                    twtje.append([[t[1][0]-s,tws[vesseltje][v][t[0]+1][0]-s] for t in enumerate(tws[vesseltje][v]) if t[1][1] == 'Stop' and t[0] != len(tws[vesseltje][v])-1])\n",
    "            else:\n",
    "                twtje.append([[simulation_start.timestamp()-s,simulation_start.timestamp()+end-s],\n",
    "                              [simulation_start.timestamp()-s,simulation_start.timestamp()+end-s]])\n",
    "        twtjes.append(twtje)\n",
    "\n",
    "    indexes = []\n",
    "    locaties = []\n",
    "    tijdjess = []\n",
    "    waardens = []\n",
    "    for twtje in enumerate(twtjes):\n",
    "        tijd = []\n",
    "        for tw in twtje[1]:\n",
    "            for t in tw:\n",
    "                if t[1] <= end:\n",
    "                    tijd.extend([t[0],t[1]])\n",
    "                elif t[0] <= end:\n",
    "                    tijd.extend([t[0],end])\n",
    "                else:\n",
    "                    break\n",
    "        tijd.sort()\n",
    "        tijdjes = list(dict.fromkeys(tijd))\n",
    "        tijdjes.append(end)\n",
    "        waarden = np.zeros(len(tijdjes))\n",
    "        for tw in enumerate(twtje[1]):\n",
    "            for t in enumerate(tw[1]):\n",
    "                if t[0] == 0 and t[1][0] <= end and t[1][1] >= end:\n",
    "                    t[1][0] = 0\n",
    "                    t[1][1] = end\n",
    "                if t[1][1] <= end:                 \n",
    "                    indx1 = tijdjes.index(t[1][0])\n",
    "                    indx2 = tijdjes.index(t[1][1])\n",
    "                    for i in enumerate(tijdjes[indx1:indx2+1]):\n",
    "                        waarden[i[0]+indx1] = vesseltjes[twtje[0]][tw[0]].T_f\n",
    "                \n",
    "        tijdjess.extend(tijdjes)\n",
    "        waardens.extend(waarden)\n",
    "        vesseltje = vesseltjes[twtje[0]][0]         \n",
    "        route = nx.dijkstra_path(FG,'Node 1',vesseltjes[twtje[0]][0].route[-1])\n",
    "        previous_node = 'Node 1'\n",
    "        distance = 0\n",
    "        for node in route:\n",
    "            if node != previous_node:        \n",
    "                distance += calculate_distance([FG.nodes[previous_node]['geometry'].x,FG.nodes[previous_node]['geometry'].y],\n",
    "                                               [FG.nodes[node]['geometry'].x,FG.nodes[node]['geometry'].y])\n",
    "                previous_node = node\n",
    "\n",
    "        locaties.extend(list(distance*np.ones(len(tijdjes))))\n",
    "        if twtje[0] != len(twtjes)-1:\n",
    "            indexes.append(len(locaties)-1)\n",
    "\n",
    "    return indexes,locaties,tijdjess,waardens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a268b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tidal_window_visualization2(start_node,end_node,T_lower_limit,T_upper_limit,T_ticks,bound):\n",
    "    T_list = np.arange(T_lower_limit,T_upper_limit,T_ticks)\n",
    "    route = nx.dijkstra_path(FG, start_node, end_node)\n",
    "    vesseltjes = []\n",
    "    vesseltje = []\n",
    "    print(start_node,end_node)\n",
    "    for i in range(len(T_list)):\n",
    "        vesseltje.append(Vessel(start_time = simulation_start.timestamp(),\n",
    "                                T = T_list[i],\n",
    "                                L = 149,\n",
    "                                v = 4.5,\n",
    "                                B = 27,\n",
    "                                ukc = 0,\n",
    "                                mccur = 0,\n",
    "                                mwt = 64*60*60,\n",
    "                                bound = bound,\n",
    "                                typ = 'Handysize',\n",
    "                                network = network,\n",
    "                                start_node = start_node,\n",
    "                                end_node = end_node))\n",
    "    vesseltjes.append(vesseltje)\n",
    "    tws = []\n",
    "    for vesseltje in range(len(vesseltjes)):\n",
    "        tw = []\n",
    "        for v in range(len(vesseltjes[vesseltje])):\n",
    "            tw.append(core.VesselTrafficService.provide_sail_in_times_tidal_window(vesseltjes[vesseltje][v],\n",
    "                                                                                   route = vesseltjes[vesseltje][v].route,\n",
    "                                                                                   plot=False,\n",
    "                                                                                   sailing_time_correction=False,\n",
    "                                                                                   visualization_calculation=True,\n",
    "                                                                                   ukc_calc=False))\n",
    "        tws.append(tw)\n",
    "\n",
    "    twtjes = []\n",
    "    end =  10*12.5*60*60\n",
    "    s = simulation_start.timestamp()\n",
    "    for vesseltje in range(len(vesseltjes)):\n",
    "        twtje = []\n",
    "        for v in range(len(vesseltjes[vesseltje])):\n",
    "            if tws[vesseltje][v] != []:\n",
    "                if tws[vesseltje][v][0][1] == 'Stop':\n",
    "                    twtje.append([[tws[vesseltje][v][t[0]-1][0]-s,t[1][0]-s] for t in enumerate(tws[vesseltje][v]) if t[1][1] == 'Start'])\n",
    "                else:\n",
    "                    twtje.append([[t[1][0]-s,tws[vesseltje][v][t[0]+1][0]-s] for t in enumerate(tws[vesseltje][v]) if t[1][1] == 'Stop' and t[0] != len(tws[vesseltje][v])-1])\n",
    "            else:\n",
    "                twtje.append([[simulation_start.timestamp()-s,simulation_start.timestamp()+end-s],\n",
    "                              [simulation_start.timestamp()-s,simulation_start.timestamp()+end-s]])\n",
    "        twtjes.append(twtje)\n",
    "\n",
    "    indexes = []\n",
    "    locaties = []\n",
    "    tijdjess = []\n",
    "    waardens = []\n",
    "    for twtje in enumerate(twtjes):\n",
    "        tijd = []\n",
    "        for tw in twtje[1]:\n",
    "            for t in tw:\n",
    "                tijd.extend([t[0],t[1]])\n",
    "        tijd.sort()\n",
    "        tijden = list(dict.fromkeys(tijd))\n",
    "        tijdjes = []\n",
    "        tijdjes.append(0)\n",
    "        tijdjes.append(end)\n",
    "        for t in enumerate(tijden):\n",
    "            if t[0] != 0 and t[0] != len(tijden)-1:\n",
    "                tijdjes.extend([t[1],t[1]])\n",
    "            else:\n",
    "                tijdjes.append(t[1])\n",
    "        tijdjes.append(end)\n",
    "        waarden = np.zeros(len(tijdjes))       \n",
    "        for tw in enumerate(twtje[1]):\n",
    "            for t in enumerate(tw[1]):\n",
    "                if t[0] == 0 and t[1][0] <= end and t[1][1] >= end:\n",
    "                    t[1][0] = 0\n",
    "                    t[1][1] = end\n",
    "                if t[1][1] <= end:\n",
    "                    indx1 = tijdjes.index(t[1][0])\n",
    "                    indx2 = tijdjes.index(t[1][1])\n",
    "                    if indx2 != len(tijdjes)-1 and t[1][1] != end:\n",
    "                        if indx1 != 0:\n",
    "                            indx1 = indx1+1\n",
    "                        for i in enumerate(tijdjes[indx1:indx2+1]):\n",
    "                            waarden[i[0]+indx1] = vesseltjes[twtje[0]][tw[0]].T_f\n",
    "                    else:\n",
    "                        if indx1 != 0:\n",
    "                            indx1 = indx1+1\n",
    "                            for i in enumerate(tijdjes[indx1:]):\n",
    "                                waarden[i[0]+indx1] = vesseltjes[twtje[0]][tw[0]].T_f\n",
    "                        else:\n",
    "                            for i in enumerate(tijdjes):\n",
    "                                waarden[i[0]] = vesseltjes[twtje[0]][tw[0]].T_f\n",
    "                            break\n",
    "                elif t[1][0] <= end:\n",
    "                    indx1 = tijdjes.index(t[1][0])+1\n",
    "                    for i in enumerate(tijdjes[indx1:]):\n",
    "                        waarden[i[0]+indx1] = vesseltjes[twtje[0]][tw[0]].T_f\n",
    "                    \n",
    "        tijdjess.extend(tijdjes)\n",
    "        waardens.extend(waarden)\n",
    "        \n",
    "        vesseltje = vesseltjes[twtje[0]][0]\n",
    "        route = nx.dijkstra_path(FG,'Node 1',vesseltjes[twtje[0]][0].route[-1])\n",
    "        previous_node = 'Node 1'\n",
    "        distance = 0\n",
    "        for node in route:\n",
    "            if node != previous_node:        \n",
    "                distance += calculate_distance([FG.nodes[previous_node]['geometry'].x,FG.nodes[previous_node]['geometry'].y],\n",
    "                                               [FG.nodes[node]['geometry'].x,FG.nodes[node]['geometry'].y])\n",
    "                previous_node = node\n",
    "\n",
    "        locaties.extend(list(distance*np.ones(len(tijdjes))))\n",
    "        if twtje[0] != len(twtjes)-1:\n",
    "            indexes.append(len(locaties)-1)\n",
    "\n",
    "    return indexes,locaties,tijdjess,waardens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d677bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(core)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49deb8d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "I = []\n",
    "X = []\n",
    "Y = []\n",
    "Z = []\n",
    "route = nx.dijkstra_path(FG, 'Node 1', 'Node 19')\n",
    "T_lower_limit = 4.5\n",
    "T_ticks = 0.05\n",
    "T_upper_limit = 16+T_ticks\n",
    "end = 10*12.5*60*60\n",
    "for node in enumerate(route):\n",
    "    i,x,y,z = test_tidal_window_visualization(node[1],node[1],T_lower_limit,T_upper_limit,T_ticks)\n",
    "    I.append(i)\n",
    "    X.append(x)\n",
    "    Y.append(y)\n",
    "    Z.append(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32d48e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_int = []\n",
    "y_int = []\n",
    "z_int = []\n",
    "for x in enumerate(X):  \n",
    "    print(x[0])\n",
    "    intrp = sc.interpolate.interp1d(Y[x[0]],Z[x[0]])\n",
    "    y_intrp = np.linspace(start,end,1000)\n",
    "    x_intrp = x[1][0]*np.ones(1000)\n",
    "    z_intrp = intrp(y_intrp)\n",
    "    x_int.append(x_intrp)\n",
    "    y_int.append(y_intrp)\n",
    "    z_int.append(z_intrp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc83bfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "I = []\n",
    "X = []\n",
    "Y = []\n",
    "Z = []\n",
    "route = nx.dijkstra_path(FG, 'Node 15', 'Node 15')\n",
    "T_lower_limit = 4.5\n",
    "T_ticks = 0.05\n",
    "T_upper_limit = 16+T_ticks\n",
    "for node in enumerate(route):\n",
    "    i,x,y,z = test_tidal_window_visualization2(node[1],node[1],T_lower_limit,T_upper_limit,T_ticks,'inbound')\n",
    "    I.append(i)\n",
    "    X.append(x)\n",
    "    Y.append(y)\n",
    "    Z.append(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0d90c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_int2 = []\n",
    "y_int2 = []\n",
    "z_int2 = []\n",
    "for x in enumerate(X):  \n",
    "    intrp = sc.interpolate.interp1d(Y[x[0]],Z[x[0]])\n",
    "    y_intrp = np.linspace(start,end,1000)\n",
    "    x_intrp = x[1][0]*np.ones(1000)\n",
    "    z_intrp = intrp(y_intrp)\n",
    "    x_int2.append(x_intrp)\n",
    "    y_int2.append(y_intrp)\n",
    "    z_int2.append(z_intrp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110cd1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "I = []\n",
    "X = []\n",
    "Y = []\n",
    "Z = []\n",
    "route = nx.dijkstra_path(FG, 'Node 15', 'Node 15')\n",
    "T_lower_limit = 4.5\n",
    "T_ticks = 0.05\n",
    "T_upper_limit = 16+T_ticks\n",
    "for node in enumerate(route):\n",
    "    i,x,y,z = test_tidal_window_visualization2(node[1],node[1],T_lower_limit,T_upper_limit,T_ticks,'outbound')\n",
    "    I.append(i)\n",
    "    X.append(x)\n",
    "    Y.append(y)\n",
    "    Z.append(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6806c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_int3 = []\n",
    "y_int3 = []\n",
    "z_int3 = []\n",
    "for x in enumerate(X):  \n",
    "    intrp = sc.interpolate.interp1d(Y[x[0]],Z[x[0]])\n",
    "    y_intrp = np.linspace(start,end,1000)\n",
    "    x_intrp = x[1][0]*np.ones(1000)\n",
    "    z_intrp = intrp(y_intrp)\n",
    "    x_int3.append(x_intrp)\n",
    "    y_int3.append(y_intrp)\n",
    "    z_int3.append(z_intrp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab6d5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "terminal = vessels[0].env.FG.edges['Node 18','Node 19']['Terminal'][0]\n",
    "if terminal.type == 'quay':\n",
    "    max_available_quay_length = terminal.length.capacity\n",
    "if terminal.type == 'jetty':\n",
    "    max_available_quay_length = 5\n",
    "    \n",
    "def make_rgb_transparent(rgb, bg_rgb, alpha):\n",
    "    return [alpha * c1 + (1 - alpha) * c2\n",
    "            for (c1, c2) in zip(rgb, bg_rgb)]\n",
    "\n",
    "def calculate_alpha(cf, cb):\n",
    "    a = cb[-1] + cf[-1] - cb[-1] * cf[-1]\n",
    "    return a\n",
    "\n",
    "#alphas = np.linspace(0,1,50)\n",
    "#colors = [make_rgb_transparent(mpl.colors.to_rgb('lightgreen'),[1,1,1],a) for a in alphas]\n",
    "#cmap = mpl.colors.ListedColormap(colors)\n",
    "colors = []\n",
    "colors.append([1,1,1])\n",
    "for c in enumerate(mpl.colorbar.cm.tab20.colors):\n",
    "    if (c[0]-1)%2 == 0 and c[0] <= 16:\n",
    "        colors.append(c[1])\n",
    "bounds = list(vdf['T_f'])\n",
    "bounds.insert(0,0)\n",
    "cmap = mpl.colors.ListedColormap(colors)\n",
    "norm = mpl.colors.BoundaryNorm(boundaries=bounds,ncolors=9, extend='max')\n",
    "cmap_plot = mpl.colors.ListedColormap(colors[1:])\n",
    "norm_plot = mpl.colors.BoundaryNorm(boundaries=bounds[1:],ncolors=8, extend='max')\n",
    "\n",
    "vesseltje = vessels[0]\n",
    "start = 0\n",
    "end =  10*12.5*60*60\n",
    "end_cor = 0#5*12.5*60*60\n",
    "ax3xlist = [eta+depth[1][16] for eta in water_level[1][16][1]] #let's define it at node 15 to visualize when we have the critical bed level of MBL=-16.4m NAP\n",
    "ax3ylist = [t-simulation_start.timestamp() for t in water_level[1][16][0]] \n",
    "ax4xlist = current_velocity[1][13][1]\n",
    "ax4ylist = [t-simulation_start.timestamp() for t in current_velocity[1][14][0]]\n",
    "required_water_level = vesseltje.metadata['ukc'] + vesseltje.T_f\n",
    "    \n",
    "if terminal.type == 'quay':\n",
    "    time_available_quay_length = []\n",
    "    available_quay_length = []\n",
    "    quay_level = 0\n",
    "    time_available_quay_length.append(0)\n",
    "    available_quay_length.append(quay_level)\n",
    "    for t in range(len(terminal.log[\"Message\"])):\n",
    "        time_available_quay_length.append(terminal.log[\"Timestamp\"][t].timestamp()-simulation_start.timestamp())\n",
    "        available_quay_length.append(quay_level)\n",
    "        time_available_quay_length.append(terminal.log[\"Timestamp\"][t].timestamp()-simulation_start.timestamp())\n",
    "        available_quay_length.append(terminal.log[\"Value\"][t])\n",
    "        quay_level = terminal.log[\"Value\"][t]\n",
    "        \n",
    "if terminal.type == 'jetty':\n",
    "    time_available_quay_length = []\n",
    "    available_quay_length = []\n",
    "    quay_level = 0\n",
    "    time_available_quay_length.append(0)\n",
    "    available_quay_length.append(quay_level)\n",
    "    for t in range(len(terminal.log[\"Message\"])):\n",
    "        time_available_quay_length.append(terminal.log[\"Timestamp\"][t].timestamp()-simulation_start.timestamp())\n",
    "        available_quay_length.append(quay_level)\n",
    "        time_available_quay_length.append(terminal.log[\"Timestamp\"][t].timestamp()-simulation_start.timestamp())\n",
    "        available_quay_length.append(terminal.log[\"Value\"][t])\n",
    "        quay_level = terminal.log[\"Value\"][t]\n",
    "    \n",
    "anchorage = vessels[0].env.FG.nodes['Node 20']['Anchorage'][0]\n",
    "time_anchorage_occupation = []\n",
    "anchorage_occupation = []\n",
    "anchorage_capacity = 0\n",
    "time_anchorage_occupation.append(0)\n",
    "anchorage_occupation.append(anchorage_capacity)\n",
    "for t in range(len(anchorage.log[\"Message\"])):\n",
    "    time_anchorage_occupation.append(anchorage.log[\"Timestamp\"][t].timestamp()-simulation_start.timestamp())\n",
    "    anchorage_occupation.append(anchorage_capacity)\n",
    "    time_anchorage_occupation.append(anchorage.log[\"Timestamp\"][t].timestamp()-simulation_start.timestamp())\n",
    "    anchorage_occupation.append(anchorage.log[\"Value\"][t])\n",
    "    anchorage_capacity = anchorage.log[\"Value\"][t]\n",
    "\n",
    "fig, (ax1,ax2,ax3,ax4,ax5,ax6) = plt.subplots(1,6,figsize=(16, 9),gridspec_kw={'width_ratios': [3.5, 0.25, 0.25, 1, 1, 1]})\n",
    "ax1.patch.set_alpha(0)\n",
    "ax2.patch.set_alpha(0)\n",
    "ax3.patch.set_alpha(0)\n",
    "ax4.patch.set_alpha(0)\n",
    "ax1.set_xlim([0,125000])\n",
    "figxlimits = ax1.axes.get_xlim()\n",
    "for y in enumerate(y_int[0]):\n",
    "    x_intrp_old = [x[y[0]] for x in x_int]\n",
    "    z_intrp_old = [z[y[0]] for z in z_int]\n",
    "    intrp = sc.interpolate.interp1d(x_intrp_old,z_intrp_old,fill_value='extrapolate')\n",
    "    x_intrp = np.linspace(0,figxlimits[1],1000)\n",
    "    y_intrp = y[1]*np.ones(1000)\n",
    "    z_intrp = intrp(x_intrp)\n",
    "    ax1.scatter(x_intrp,y_intrp,s=2,c=z_intrp,norm=norm,cmap=cmap)\n",
    "    \n",
    "for y in enumerate(y_int2[0]):\n",
    "    x_intrp_old2 = [[x for x in x_int2][0][y[0]]-100,[x for x in x_int2][0][y[0]]+100]\n",
    "    z_intrp_old2 = [[z for z in z_int2][0][y[0]],[z for z in z_int2][0][y[0]]]\n",
    "    intrp = sc.interpolate.interp1d(x_intrp_old2,z_intrp_old2,fill_value='extrapolate')\n",
    "    x_intrp = np.linspace(-100+horizontal_tidal_restriction_distance,100+horizontal_tidal_restriction_distance,1000)\n",
    "    y_intrp = y[1]*np.ones(1000)\n",
    "    z_intrp = intrp(x_intrp)\n",
    "    ax2.scatter(x_intrp,y_intrp,s=2,c=z_intrp,norm=norm,cmap=cmap)\n",
    "    \n",
    "for y in enumerate(y_int3[0]):\n",
    "    x_intrp_old2 = [[x for x in x_int3][0][y[0]]-100,[x for x in x_int3][0][y[0]]+100]\n",
    "    z_intrp_old2 = [[z for z in z_int3][0][y[0]],[z for z in z_int3][0][y[0]]]\n",
    "    intrp = sc.interpolate.interp1d(x_intrp_old2,z_intrp_old2,fill_value='extrapolate')\n",
    "    x_intrp = np.linspace(-100+horizontal_tidal_restriction_distance,100+horizontal_tidal_restriction_distance,1000)\n",
    "    y_intrp = y[1]*np.ones(1000)\n",
    "    z_intrp = intrp(x_intrp)\n",
    "    ax3.scatter(x_intrp,y_intrp,s=2,c=z_intrp,norm=norm,cmap=cmap)\n",
    "    \n",
    "vessel_types = list(vdf['type'])\n",
    "vessel_drafts = list(vdf['T_f'])\n",
    "vessel_ukcs = list(vdf['ukc'])\n",
    "ax1.axvline(distance_to_anchorage,color = 'k',linestyle = '--')\n",
    "ax1.fill([horizontal_tidal_restriction_distance-1000,\n",
    "          horizontal_tidal_restriction_distance,\n",
    "          horizontal_tidal_restriction_distance,\n",
    "          horizontal_tidal_restriction_distance-1000],\n",
    "         [start,start,end,end],fill=False,color='k')\n",
    "ax1.axvline(122000,color = 'k',linestyle = '--')\n",
    "ax1.text(horizontal_tidal_restriction_distance-1500,0.95*(end-end_cor),'Horizontal\\n Tidal Restriction',horizontalalignment  = 'right')\n",
    "ax1.text(distance_to_anchorage,1.02*(end-end_cor),'Anchorage',horizontalalignment  = 'center')\n",
    "ax1.text(122000,1.02*(end-end_cor),'Terminal',horizontalalignment  = 'right')\n",
    "vessel_types = list(vdf['type'])\n",
    "for v in reversed(range(len(vessels))):\n",
    "    color,linewidth = color_vessels(vessels[v])\n",
    "    ax1.plot(vessel_path_x[v],vessel_path_t[v],color=color,linewidth=linewidth)\n",
    "vessel_legend(ax1,vessel_types)\n",
    "ax1.set_title(\"Tracking diagram and vertical tidal restriction for\\n vessels calling at a liquid bulk terminal\", fontweight='bold', pad = 32)\n",
    "ax1.set_xlabel('Distance [m]')\n",
    "ax1.set_xlim(figxlimits)\n",
    "ax1.set_ylabel('Time [s]')\n",
    "ax1.set_ylim([start,end-end_cor]);\n",
    "\n",
    "ax2.set_xlim([-100+horizontal_tidal_restriction_distance,100+horizontal_tidal_restriction_distance])\n",
    "for v in reversed(range(len(vessels))):\n",
    "    color,linewidth = color_vessels(vessels[v])\n",
    "    ax2.plot(vessel_path_x[v][:int(0.5*len(vessel_path_x[0]))],vessel_path_t[v][:int(0.5*len(vessel_path_x[0]))],color=color,linewidth=linewidth)\n",
    "ax2.set_ylim([start,end-end_cor])\n",
    "ax2.set_title(\"Horizontal\\n Tidal\\n Restriction\", fontweight='bold', position = [1.4,1.4],pad=26)\n",
    "ax2.text(horizontal_tidal_restriction_distance,1.01*(end-end_cor),'inbound\\n vessels',horizontalalignment  = 'center')\n",
    "ax2.yaxis.set_visible(False)\n",
    "ax2.xaxis.set_visible(False)\n",
    "\n",
    "ax3.set_xlim([-100+horizontal_tidal_restriction_distance,100+horizontal_tidal_restriction_distance])\n",
    "for v in reversed(range(len(vessels))):\n",
    "    color,linewidth = color_vessels(vessels[v])\n",
    "    ax3.plot(vessel_path_x[v][int(0.5*len(vessel_path_x[0])):],vessel_path_t[v][int(0.5*len(vessel_path_x[0])):],color=color,linewidth=linewidth)\n",
    "ax3.set_ylim([start,end-end_cor])\n",
    "ax3.text(horizontal_tidal_restriction_distance,1.01*(end-end_cor),'outbound\\n vessels',horizontalalignment  = 'center')\n",
    "ax3.yaxis.set_visible(False)\n",
    "ax3.xaxis.set_visible(False)\n",
    "\n",
    "ax4.plot([max_available_quay_length-x for x in available_quay_length],time_available_quay_length)\n",
    "ax4.set_xlim([0,1.1*max_available_quay_length])\n",
    "figxlimits = ax4.axes.get_xlim()\n",
    "if terminal.type == 'quay':\n",
    "    ax4.axvline(vessels[0].L,color = 'k', linestyle = '--')\n",
    "    ax4.set_title(\"Available quay length \\n over time\", fontweight='bold', pad = 32)\n",
    "    ax4.text(vessels[0].L,1.01*end,'Required quay \\n length',horizontalalignment = 'center') \n",
    "elif terminal.type == 'jetty':\n",
    "    ax4.axvline(1,color = 'k', linestyle = '--')\n",
    "    ax4.set_title(\"Available jetties \\n over time\", fontweight='bold', pad = 32)\n",
    "ax4.set_xlim(figxlimits)\n",
    "ax4.yaxis.set_visible(False)\n",
    "ax4.set_ylim([start,end-end_cor])\n",
    "ax4.set_xlabel('Number of jetties [-]');\n",
    "\n",
    "ax5.plot(ax3xlist,ax3ylist)\n",
    "ax5.plot([eta+depth[1][6] for eta in water_level[1][6][1]],ax3ylist,c='#1f77b4')\n",
    "ax5.set_ylim([start,end-end_cor])\n",
    "figxlimits = ax5.axes.get_xlim()\n",
    "ax5.yaxis.set_visible(False)\n",
    "ax5.set_ylim([start,end-end_cor])\n",
    "ax5.set_xlim(figxlimits)\n",
    "ax5.set_xlabel('Water depth [m]');\n",
    "ax5.set_title(\"Available water\\n depth over\\n time\", fontweight='bold', pad = 26)\n",
    "ax5.yaxis.set_visible(False)\n",
    "\n",
    "ax6.set_xlabel('Current \\n velocity [m/s]',horizontalalignment = 'center');\n",
    "ax6.plot(ax4xlist,ax4ylist)\n",
    "ax6.set_ylim([start,end-end_cor])\n",
    "figxlimits = ax6.axes.get_xlim()\n",
    "ax6.set_title(\"Current\\n velocity\\n over time\", fontweight='bold', pad = 26)\n",
    "ax6.set_ylim([start,end-end_cor])\n",
    "ax6.set_xlim(figxlimits)\n",
    "ax6.yaxis.set_visible(False)\n",
    "\n",
    "cax = fig.add_axes([0.925, 0.125, 0.01, 0.755])\n",
    "cbar = mpl.colorbar.ColorbarBase(cax, cmap=cmap_plot,norm=norm_plot, orientation='vertical')\n",
    "cbar.set_label('Maximum draught of vessel that is allowed to sail [m]')\n",
    "plt.show();\n",
    "extent = fig.get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "#fig.savefig('added_vessels1.png', dpi=300,bbox_inches=extent.expanded(1.0, 1.2));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57d15e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vesselt = Vessel(start_time = simulation_start.timestamp(),\n",
    "                    T = 10.3,\n",
    "                    L = 180,\n",
    "                    v = 4.5,\n",
    "                    B = 27,\n",
    "                    ukc = 0,\n",
    "                    mccur = 0,\n",
    "                    mwt = 24*60*60,\n",
    "                    bound = 'inbound',\n",
    "                    name = 'testship',\n",
    "                    type = 'Tanker',\n",
    "                    network = FG,\n",
    "                    start_node = 'Node 15',\n",
    "                    end_node = 'Node 15')\n",
    "\n",
    "_ = core.VesselTrafficService.provide_sail_in_times_tidal_window(vesselt,\n",
    "                                                                 route =vesselt.route,\n",
    "                                                                 plot=True,\n",
    "                                                                 sailing_time_correction = True,\n",
    "                                                                 visualization_calculation = True,\n",
    "                                                                 ukc_calc=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f476589a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tidal_periods(t_astro_tide_wlev, astro_tide_wlev):\n",
    "    \"\"\" Function: calculates the water level which is exceeded 99% of the tides for a given node in the network.\n",
    "\n",
    "        Input:\n",
    "            - t_astro_wlev: a list containing the chronological sequence of timestamps for the specific node, derived from the\n",
    "                            list of the time series containing the water level at the specific node\n",
    "            - astro_wlev: a list containing the chronological sequence of water levels for the specific node, derived from the\n",
    "                          list of the time series containing the water level at the specific node\n",
    "    \"\"\"\n",
    "\n",
    "    # Deriving some properties\n",
    "    mean_astro_wlev = np.mean(astro_tide_wlev)\n",
    "\n",
    "    # Interpolation of the variation of the water level and calculation of the zero crossing times\n",
    "    cor_astro_tide = [astro_wlev - mean_astro_wlev for astro_wlev in astro_tide_wlev]\n",
    "    intp = sc.interpolate.CubicSpline(t_astro_tide_wlev, cor_astro_tide)\n",
    "    times_tidal_periods = []\n",
    "    index_prev_root = 0\n",
    "    for root in intp.roots():\n",
    "        index_current_root = bisect.bisect_right(t_astro_tide_wlev, root)\n",
    "        if root >= t_astro_tide_wlev[0] and root <= t_astro_tide_wlev[-1] and np.max(cor_astro_tide[index_prev_root:index_current_root]) > 0:\n",
    "            index = cor_astro_tide[index_prev_root:index_current_root].index(np.max(cor_astro_tide[index_prev_root:index_current_root]))\n",
    "            time_start_next_tidal_period = t_astro_tide_wlev[index + index_prev_root]\n",
    "            times_tidal_periods.append([time_start_next_tidal_period, 'Ebb Start'])\n",
    "            index_prev_root = index_current_root\n",
    "        elif root >= t_astro_tide_wlev[0] and root <= t_astro_tide_wlev[-1] and np.min(cor_astro_tide[index_prev_root:index_current_root]) < 0:\n",
    "            index = cor_astro_tide[index_prev_root:index_current_root].index(np.min(cor_astro_tide[index_prev_root:index_current_root]))\n",
    "            time_start_next_tidal_period = t_astro_tide_wlev[index + index_prev_root]\n",
    "            times_tidal_periods.append([time_start_next_tidal_period, 'Flood Start'])\n",
    "            index_prev_root = index_current_root\n",
    "\n",
    "    return times_tidal_periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0beb45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def astronomical_tide(signal_time,signal_values):\n",
    "    signal_datetime = [datetime.datetime.fromtimestamp(y) for y in signal_time]\n",
    "    const_list = hatyan.get_const_list_hatyan('tidalcycle')\n",
    "    times_ext = signal_datetime\n",
    "    ts_meas = pd.DataFrame({'values': signal_values}, index=signal_datetime)\n",
    "    ts_meas = hatyan.crop_timeseries(ts=ts_meas, times_ext=times_ext);\n",
    "    comp_frommeas, comp_allyears = hatyan.get_components_from_ts(ts=ts_meas, const_list=const_list, nodalfactors=True, return_allyears=True, fu_alltimes=True, analysis_peryear=True)\n",
    "    ts_prediction = hatyan.prediction(comp=comp_frommeas, nodalfactors=True, xfac=True, fu_alltimes=True, times_ext=times_ext, timestep_min=5)\n",
    "    return [[index.timestamp()-3600 for index in ts_prediction.index],[value for value in ts_prediction['values']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf62704b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import hatyan\n",
    "\n",
    "x = np.linspace(0,12.5*60*60,10000)\n",
    "y = np.sin(x/(12.5*60*60)*2*np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546746b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = astronomical_tide(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec9fb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,y)\n",
    "plt.plot(a[0],a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f53535e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51a3fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "[datetime.datetime.fromtimestamp(y) for y in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a4beff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
