{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f03a0c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import packages and set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffb7ed0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import packages\n",
    "from copy import deepcopy\n",
    "import datetime\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx  \n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pytz\n",
    "import simpy\n",
    "import xarray as xr\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "#Import packages OpenTNSim\n",
    "from opentnsim import core\n",
    "from opentnsim import plot\n",
    "from opentnsim import model\n",
    "from opentnsim import import_hydrodynamic_dataset\n",
    "from opentnsim import vessel_traffic_service\n",
    "from opentnsim import port\n",
    "from opentnsim import lock\n",
    "from opentnsim import vessel as vessel_\n",
    "from opentnsim import waterway\n",
    "from opentnsim import output\n",
    "from opentnsim import tidal_window_constructor\n",
    "from opentnsim import rule_constructor\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651034be",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.getcwd()\n",
    "path = output_path.split('\\\\04_Output_data')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bef9bb",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18104c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ship_percentage(origin_destination_matrix,lenght_min,lenght_max,draught_min,draught_max,direction):\n",
    "    \"\"\" \n",
    "    Function that calculates the percentage of vessels of a certain dimensions and directions\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    origin_destination_matrix: pandas dataframe of the vessels of call with 'length', 'draught', and '(un)loading'\n",
    "    lenght_min: minimum length of the vessel\n",
    "    lenght_max: maximum length of the vessel\n",
    "    draught_min: minimum draught of the vessel\n",
    "    draught_max: maximum draught of the vessel\n",
    "    direction: direction of the vessel as a string: 'inbound' or 'outbound'\n",
    "    \n",
    "    :returns: percentage of vessels based on the criteria as a float\n",
    "    \"\"\"\n",
    "    \n",
    "    origin_destination_matrix = origin_destination_matrix.reset_index(drop=True)\n",
    "    if direction == 'inbound':\n",
    "        percentage = len(origin_destination_matrix[(origin_destination_matrix.length >= lenght_min)&\n",
    "                                                   (origin_destination_matrix.length <= lenght_max)&\n",
    "                                                   (origin_destination_matrix.draught >= draught_min)&\n",
    "                                                   (origin_destination_matrix.draught <= draught_max)])/len(origin_destination_matrix)\n",
    "    else:\n",
    "        outbound_df = pd.DataFrame([draught-np.sum(unloading) for draught,unloading in zip(origin_destination_matrix.draught.to_numpy(),origin_destination_matrix['(un)loading'])])\n",
    "        percentage = len(origin_destination_matrix[(origin_destination_matrix.length >= lenght_min)&\n",
    "                                                   (origin_destination_matrix.length <= lenght_max)&\n",
    "                                                   (outbound_df[0] > draught_min)&\n",
    "                                                   (outbound_df[0] <= draught_max)])/len(origin_destination_matrix)\n",
    "    percentage = np.round(percentage*100,1)\n",
    "    return percentage\n",
    "\n",
    "def make_rgb_transparent(rgb, bg_rgb,alpha):\n",
    "    \"\"\" \n",
    "    Function that creates a non-transparent color based on a transparent color\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rgb: RGB-code as a list of RGB numbers from 0.0 to 1.0 as floats\n",
    "    bg_rgb: background RGB-code as a list of RGB numbers from 0.0 to 1.0 as floats\n",
    "    alpha: transparency of the RGB-color on the background RGB-color from 0.0 to 1.0 as float\n",
    "    \n",
    "    :returns: non-transparent color\n",
    "    \"\"\"\n",
    "    \n",
    "    non_transparent_color = [alpha * c1 + (1 - alpha) * c2 for (c1, c2) in zip(rgb, bg_rgb)]\n",
    "    \n",
    "    return non_transparent_color\n",
    "\n",
    "def calculate_absolute_waiting_times(df):\n",
    "    \"\"\" \n",
    "    Function that calculates the total and average waiting times of vessels\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pandas dataframe of the vessels' output containing the 'Modelled_total_waiting_time'\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    total_waiting_time: total waiting time\n",
    "    average_waiting_time: average total waiting time\n",
    "    \"\"\"\n",
    "    \n",
    "    total_waiting_time = np.sum(df.Modelled_total_waiting_time)\n",
    "    average_waiting_time = np.mean(df[df.Modelled_total_waiting_time > pd.Timedelta(0,'s')].Modelled_total_waiting_time)\n",
    "    \n",
    "    return total_waiting_time,average_waiting_time\n",
    "\n",
    "def calculate_waiting_time_percentages(full_model_comparison_df,model_no_priority_comparison_df,model_no_tidal_window_comparison_df,cascading=False,observed=True,direct=True):\n",
    "    \"\"\" \n",
    "    Function that creates a vessel agent in the nautical traffic model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    full_model_comparison_df:\n",
    "    model_no_priority_comparison_df:\n",
    "    model_no_tidal_window_comparison_df:\n",
    "    cascading:\n",
    "    observed:\n",
    "    direct:\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A list containing the following parameters:\n",
    "     - unresolved_long_term_waiting_time: timedelta of total unresolved long term waiting time (cause not known)\n",
    "     - unresolved_short_term_waiting_time: timedelta of total unresolved short term waiting time (cause not known)\n",
    "     - resolved_long_term_waiting_time_due_to_prioritization: timedelta of total resolved long term waiting time allegedly \n",
    "                                                              due to prioritization\n",
    "     - resolved_short_term_waiting_time_due_to_prioritization: timedelta of total resolved short term waiting time \n",
    "                                                               allegedly due to prioritization\n",
    "     - resolved_waiting_time_due_to_availability: timedelta of total resolved non-cascading waiting time due to terminal \n",
    "                                                  congestion\n",
    "     - resolved_cascading_waiting_time_due_to_prioritization: timedelta of total cascading waiting time allegedly due to\n",
    "                                                              prioritization\n",
    "     - resolved_cascading_waiting_time_due_to_tidal_windows: timedelta of total cascading waiting time due to tidal\n",
    "                                                             restrictions\n",
    "     - resolved_waiting_time_due_to_tidal_windows: timedelta of total non-cascading waiting time due to tidal windows\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    if observed:  \n",
    "        relative_df = full_model_comparison_df.Observed_total_waiting_time\n",
    "    else:\n",
    "        relative_df = full_model_comparison_df.Modelled_total_waiting_time\n",
    "    \n",
    "    if direct:\n",
    "        difference_df = (relative_df-full_model_comparison_df.Modelled_total_waiting_time)\n",
    "        unresolved_waiting_time = np.sum(difference_df[difference_df >= np.timedelta64(0,'s')])/(np.sum(relative_df)+pd.Timedelta(1,'s'))\n",
    "    else:\n",
    "        unresolved_waiting_time = 1-np.sum(full_model_comparison_df.Modelled_total_waiting_time)/np.sum(relative_df)\n",
    "    unresolved_df = relative_df-full_model_comparison_df.Modelled_total_waiting_time\n",
    "    long_discrepancy = unresolved_df - pd.Timedelta(12,'h')\n",
    "    short_discrepancy = unresolved_df[unresolved_df > pd.Timedelta(0,'h')].sum() - long_discrepancy[long_discrepancy > pd.Timedelta(0,'s')].sum()\n",
    "    priority_df = full_model_comparison_df.Waiting_due_to_priority_inbound\n",
    "    priority_long = priority_df[priority_df > pd.Timedelta(12,'h')].sum()/(priority_df.sum()+pd.Timedelta(1,'s'))\n",
    "    priority_short = 1 - priority_long\n",
    "    long_term_unresolved = unresolved_df[unresolved_df > pd.Timedelta(12,'h')].sum()/(np.sum(unresolved_df[unresolved_df > pd.Timedelta(0,'h')])+pd.Timedelta(1,'s'))\n",
    "    short_term_unresolved = unresolved_df[(unresolved_df > pd.Timedelta(0,'h'))&(unresolved_df < pd.Timedelta(12,'h'))].sum()/(np.sum(unresolved_df[unresolved_df > pd.Timedelta(0,'h')])+pd.Timedelta(1,'s'))\n",
    "    resolved_waiting_time = 1-unresolved_waiting_time\n",
    "    waiting_time_availability = np.sum(full_model_comparison_df.Waiting_for_available_berth_inbound)/(np.sum(full_model_comparison_df.Modelled_total_waiting_time)+np.timedelta64(1,'s'))\n",
    "    waiting_time_priority = np.sum(full_model_comparison_df.Waiting_due_to_priority_inbound)/(np.sum(full_model_comparison_df.Modelled_total_waiting_time)+np.timedelta64(1,'s'))\n",
    "    waiting_time_tidal_window = np.sum(full_model_comparison_df.Waiting_for_tidal_window_inbound)/(np.sum(full_model_comparison_df.Modelled_total_waiting_time)+np.timedelta64(1,'s'))\n",
    "    if cascading:\n",
    "        mask = full_model_comparison_df.Waiting_due_to_priority_inbound==pd.Timedelta(0,'s')\n",
    "        df = full_model_comparison_df[mask].Waiting_for_available_berth_inbound-model_no_tidal_window_comparison_df[mask].Waiting_for_available_berth_inbound\n",
    "        cascading_tidal_window = np.sum(df[df>pd.Timedelta(0,'s')])/(np.sum(full_model_comparison_df.Waiting_for_available_berth_inbound)+pd.Timedelta(1,'s'))\n",
    "        df = full_model_comparison_df[mask].Waiting_for_available_berth_inbound-model_no_priority_comparison_df[mask].Waiting_for_available_berth_inbound\n",
    "        cascading_priority = np.sum(df[df>pd.Timedelta(0,'s')])/(np.sum(full_model_comparison_df.Waiting_for_available_berth_inbound)+pd.Timedelta(1,'s'))\n",
    "        non_cascading = 1-cascading_priority-cascading_tidal_window\n",
    "    else:\n",
    "        non_cascading = 1\n",
    "        cascading_priority = 0\n",
    "        cascading_tidal_window = 0 \n",
    "        \n",
    "    unresolved_long_term_waiting_time = unresolved_waiting_time*long_term_unresolved\n",
    "    unresolved_short_term_waiting_time = unresolved_waiting_time*short_term_unresolved\n",
    "    resolved_long_term_waiting_time_due_to_prioritization = waiting_time_priority*resolved_waiting_time*priority_long\n",
    "    resolved_short_term_waiting_time_due_to_prioritization = waiting_time_priority*resolved_waiting_time*priority_short\n",
    "    resolved_waiting_time_due_to_availability = waiting_time_availability*resolved_waiting_time*non_cascading\n",
    "    resolved_cascading_waiting_time_due_to_prioritization = waiting_time_availability*resolved_waiting_time*cascading_priority\n",
    "    resolved_cascading_waiting_time_due_to_tidal_windows = waiting_time_availability*resolved_waiting_time*cascading_tidal_window\n",
    "    resolved_waiting_time_due_to_tidal_windows = waiting_time_tidal_window*resolved_waiting_time\n",
    "    \n",
    "    return [unresolved_long_term_waiting_time,\n",
    "            unresolved_short_term_waiting_time, \n",
    "            resolved_long_term_waiting_time_due_to_prioritization,\n",
    "            resolved_short_term_waiting_time_due_to_prioritization,\n",
    "            resolved_waiting_time_due_to_availability,\n",
    "            resolved_cascading_waiting_time_due_to_prioritization,\n",
    "            resolved_cascading_waiting_time_due_to_tidal_windows,\n",
    "            resolved_waiting_time_due_to_tidal_windows]\n",
    "    \n",
    "\n",
    "def create_vessel(Vessel,env,name,origin,destination,next_destination,beam,length,draught,delta_draught,berthing_time,unloading_time,turning_time,arrival_time,terminal_of_call,berth_of_call,additional_waiting_time,bound='inbound',height=0.,ukc=0.,max_cross_current=0.):\n",
    "    \"\"\" \n",
    "    Function that creates a vessel agent in the nautical traffic model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Vessel: type object element that includes the mixin objects that symbolize a vessel agent\n",
    "    env: simpy environment\n",
    "    name: name of the vessel as a string\n",
    "    origin: origin node of the network as a string\n",
    "    destination: destination node of the network as a string\n",
    "    next_destination: list of next destination nodes of the network as a string\n",
    "    beam: beam of the vessel in meters as a float\n",
    "    length: length of the vessel in meters as a float\n",
    "    draught: draught of the vessel in meters as a float\n",
    "    delta_draught: list of draught changes of the vessel in meters as a float in sequence of terminal visits\n",
    "    berthing_time: berthing time of the vessel as pandas timestamp\n",
    "    unloading_time: list of unloading times of the vessel as pandas timestamps in sequence of terminal visits\n",
    "    turning_time: list of turning times of the vessel as pandas timestamps in sequence of harbour basin visits\n",
    "    arrival_time: rrival time of vessel as pandas timestamp\n",
    "    terminal_of_call: list of terminal names as string in sequence of terminal visits\n",
    "    berth_of_call: list of berth names as string in sequence of terminal visits\n",
    "    additional_waiting_time: additional waiting time as pandas timedelta\n",
    "    bound: 'inbound' or 'outbound'\n",
    "    height: height of the vessel in meters as a float\n",
    "    ukc: extra required under keel clearance of the vessel in meters as a float\n",
    "    max_cross_current: additional maximum allowable cross-current velocity of the vessel in meters per second as a float\n",
    "\n",
    "    :returns: vessel agent\n",
    "    \"\"\"\n",
    "    \n",
    "    vessel_input = { \"name\":name,\n",
    "                     \"origin\":origin,\n",
    "                     \"destination\":destination,\n",
    "                     \"next_destination\":next_destination,\n",
    "                     \"env\":env,\n",
    "                     \"type\":'Tanker',\n",
    "                     \"B\":beam,\n",
    "                     \"L\":length,\n",
    "                     \"T\": draught,\n",
    "                     \"H\":height,\n",
    "                     \"t_berthing\":berthing_time.total_seconds(),\n",
    "                     \"t_(un)loading\":[time.total_seconds() for time in unloading_time],\n",
    "                     \"t_turning\":[time.total_seconds() for time in turning_time],\n",
    "                     \"ukc\":ukc,\n",
    "                     \"v\":np.NaN,\n",
    "                     \"terminal_of_call\": terminal_of_call,\n",
    "                     \"berth_of_call\": berth_of_call,\n",
    "                     \"(un)loading\": delta_draught,\n",
    "                     \"max_waiting_time\":datetime.timedelta(days=10).total_seconds(),\n",
    "                     \"max_cross_current\":max_cross_current,\n",
    "                     \"arrival_time\":arrival_time,\n",
    "                     \"arrival_delay\":arrival_time,\n",
    "                     \"priority\": 0,\n",
    "                     \"additional_waiting_time\": additional_waiting_time/np.timedelta64(1, 's'),\n",
    "                     \"bound\":bound,\n",
    "                     \"priority\":False}\n",
    "    \n",
    "    created_vessel = Vessel(**vessel_input)\n",
    "    return created_vessel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9755dc7",
   "metadata": {},
   "source": [
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebe3cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_start = datetime.datetime(2019,1,1,0,0,0).replace(tzinfo=pytz.utc)\n",
    "simulation_stop = datetime.datetime(2020,1,1,0,0,0).replace(tzinfo=pytz.utc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb151f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conversion kn to m/s\n",
    "knots = 0.51444"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3e3220",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_dataframe = pd.DataFrame({'Length':[120,150,180,294,366,400],\n",
    "                               'Width':[22,24.5,29,32,49,77.5],\n",
    "                               'Draught':[8.6,9.9,11.2,12,15.2,20.1],\n",
    "                               'Heigth':[25,30,35,58,58,68],\n",
    "                               'DWT':[24,35,50,80,100,200]},\n",
    "                               index=['Coaster','Handysize','Handymax','Panamax','New Panamax','Suezmax'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdd3180",
   "metadata": {},
   "source": [
    "### Import vessel speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786b4414",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path+\"\\\\03_Simulation\\\\01_Input_data\\\\03_Vessels\\\\vessel_speed_dataframe.pickle\", \"rb\") as input_file:\n",
    "    vessel_speed_dataframe = pickle.load(input_file)\n",
    "\n",
    "#Add missing vessel speeds and convert to xarray\n",
    "missing_vessel_speeds = pd.DataFrame([0.1,0.1,5,5],columns=['average_speed'],index=[('anchorage','8866969'),('8866969','anchorage'),('B17838816_B', 'B17838816_A'),('B17838816_A', 'B17838816_B')])\n",
    "missing_vessel_speeds.index.name = 'edge'\n",
    "vessel_speed_dataframe = pd.concat([vessel_speed_dataframe,missing_vessel_speeds],axis=0)\n",
    "vessel_speed_data = vessel_speed_dataframe.to_xarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7caa9b93",
   "metadata": {},
   "source": [
    "### Import hydrodynamic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b746e921",
   "metadata": {},
   "outputs": [],
   "source": [
    "hydrodynamic_data = xr.open_dataset(path+\"\\\\03_Simulation\\\\01_Input_data\\\\02_Hydrodynamic_data\\\\hydrodynamic_data_PoR_stations.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0c246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overwrite MBLs (Change MBLs here)\n",
    "node_list = hydrodynamic_data['STATION'].values\n",
    "hydrodynamic_data['MBL'] = xr.DataArray(23*np.ones(len(node_list)),coords={'STATION':node_list})\n",
    "for index,node in enumerate(node_list):\n",
    "    if node in ['8866305','8864266','8862925','8864465','S14716_B','S14716_A','8860845']:\n",
    "        hydrodynamic_data['MBL'][index] = 16.2\n",
    "    elif node in ['8867547','8867980','8866999']:\n",
    "        hydrodynamic_data['MBL'][index] = 15.9\n",
    "    elif node in ['8866859']:\n",
    "        hydrodynamic_data['MBL'][index] = 15.9\n",
    "    elif node in ['anchorage','8866969']:\n",
    "        hydrodynamic_data['MBL'][index] = 23.8\n",
    "    else:\n",
    "        hydrodynamic_data['MBL'][index] = 16.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08d2555",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Possibility to change bed level over time\n",
    "new_MBLs = np.empty((len(hydrodynamic_data['STATION']),len(hydrodynamic_data['TIME'])))\n",
    "for station,MBL in enumerate(hydrodynamic_data['MBL'].values):\n",
    "    for time,_ in enumerate(hydrodynamic_data['TIME'].values):\n",
    "        new_MBLs[station][time] = MBL\n",
    "        \n",
    "new_MBLs = xr.DataArray(new_MBLs,dims=['STATION','TIME'],coords=dict(STATION=hydrodynamic_data['STATION'],\n",
    "                                                                     TIME=hydrodynamic_data['TIME']))\n",
    "\n",
    "hydrodynamic_data['MBL'] = new_MBLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9d6235",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read tidal period data\n",
    "for tide_type,dim_name in zip(['Vertical tidal periods','Horizontal tidal periods'],['VERTICALTIDES','HORIZONTALTIDES']):\n",
    "    data = np.empty(hydrodynamic_data[tide_type].values.shape[:2], dtype=[('a','datetime64[ns]'),('b',object)])\n",
    "    tide_info = hydrodynamic_data[tide_type].values\n",
    "    for station_index,_ in enumerate(hydrodynamic_data.STATION.values):\n",
    "        for tide_index in hydrodynamic_data[dim_name].values:\n",
    "            time = tide_info[station_index][tide_index][0]\n",
    "            tide = tide_info[station_index][tide_index][1]\n",
    "            if time == 'nan':\n",
    "                new_time = 'NaT'\n",
    "            else:\n",
    "                new_time = time\n",
    "            data[station_index][tide_index] = (np.datetime64(new_time),tide)\n",
    "    \n",
    "    final_data = []\n",
    "    for i,_ in enumerate(data):\n",
    "        final_data.append([])\n",
    "        final_data[-1].append([])\n",
    "        for j,_ in enumerate(data[0]):\n",
    "            final_data[-1][-1].append([data[i][j][0],data[i][j][1]])\n",
    "    hydrodynamic_data[tide_type].data = np.array(final_data).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c71cd83",
   "metadata": {},
   "source": [
    "### Import network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28768a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path+\"\\\\03_Simulation\\\\01_Input_data\\\\01_Geospatial_data\\\\network\\\\PortNetwork.pickle\", 'rb') as f:\n",
    "    FG = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a2445e",
   "metadata": {},
   "source": [
    "### Create environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54a629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = simpy.Environment()\n",
    "env.simulation_start = simulation_start\n",
    "env.simulation_stop = simulation_stop\n",
    "env.FG = FG\n",
    "env.vessel_traffic_service = vessel_traffic_service.VesselTrafficService(env=env,\n",
    "                                                                         hydrodynamic_data=hydrodynamic_data,\n",
    "                                                                         vessel_speed_data=vessel_speed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801e5e79",
   "metadata": {},
   "source": [
    "### Set tidal window restrictions on the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e6550c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Restrictions as dictionaries\n",
    "for node in env.FG.nodes:\n",
    "    env.FG.nodes[node]['Vertical tidal restriction'] = {}\n",
    "env.FG.nodes['8861158']['Horizontal tidal restriction'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14565af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_properties = tidal_window_constructor.NetworkProperties()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d998019",
   "metadata": {},
   "outputs": [],
   "source": [
    "#According to Port of Rotterdam vertical tidal windows policy (Change here the ukc policy)\n",
    "ukc_p = []\n",
    "ukc_s = []\n",
    "fwa = []\n",
    "        \n",
    "for index,node in enumerate(env.FG.nodes):\n",
    "    if node in ['8866969','8866305','8864266','8862925','8864465','S14716_B','S14716_A','8860845']:\n",
    "        ukc_s.append(0.)\n",
    "        ukc_p.append(0.1)\n",
    "        fwa.append(0.01)\n",
    "    elif node in ['8867547','8867980','8866999']:\n",
    "        ukc_s.append(1.0)\n",
    "        ukc_p.append(0.0)\n",
    "        fwa.append(0.025)\n",
    "    elif node in ['8866859']:\n",
    "        ukc_s.append(0.5)\n",
    "        ukc_p.append(0.0)\n",
    "        fwa.append(0.0)\n",
    "    elif node in ['anchorage']:\n",
    "        ukc_s.append(0.0)\n",
    "        ukc_p.append(0.0)\n",
    "        fwa.append(0.0)\n",
    "    else:\n",
    "        ukc_s.append(0.0)\n",
    "        ukc_p.append(0.1)\n",
    "        fwa.append(0.025)\n",
    "        \n",
    "for index,node in enumerate(env.FG.nodes):\n",
    "    vertical_tidal_window_inputs = []\n",
    "\n",
    "    #Inbound_Vessels_Condition\n",
    "    vessel_specification = tidal_window_constructor.vessel_specifications({rule_constructor.vessel_characteristics.min_ge_Draught: 0},\n",
    "                                                                           'x',rule_constructor.vessel_direction.inbound.value)\n",
    "\n",
    "    window_specification = tidal_window_constructor.vertical_tidal_window_specifications(ukc_s = ukc_s[index],\n",
    "                                                                                         ukc_p = ukc_p[index],\n",
    "                                                                                         fwa = fwa[index],)\n",
    "    \n",
    "    vertical_tidal_window_inputs.append(tidal_window_constructor.vertical_tidal_window_input(vessel_specifications = vessel_specification,\n",
    "                                                                                             window_specifications = window_specification))\n",
    "\n",
    "    #Outbound_Vessels_Condition\n",
    "    vessel_specification = tidal_window_constructor.vessel_specifications({rule_constructor.vessel_characteristics.min_ge_Draught: 0},\n",
    "                                                                           'x',rule_constructor.vessel_direction.outbound.value)\n",
    "\n",
    "    window_specification = tidal_window_constructor.vertical_tidal_window_specifications(ukc_s = ukc_s[index],\n",
    "                                                                                         ukc_p = ukc_p[index],\n",
    "                                                                                         fwa = fwa[index],)\n",
    "\n",
    "    vertical_tidal_window_inputs.append(tidal_window_constructor.vertical_tidal_window_input(vessel_specifications = vessel_specification,\n",
    "                                                                                             window_specifications = window_specification))\n",
    "\n",
    "    network_properties.append_vertical_tidal_restriction_to_network(FG,node,vertical_tidal_window_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4320762f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Port of Rotterdam Horizontal tidal windows policy 3rd Petroleum Harbour\n",
    "previous_nodes = ['8861716','8861674']\n",
    "node = '8861158'\n",
    "next_node = '8867547'\n",
    "knots = 0.5144444\n",
    "horizontal_tidal_window_inputs = []\n",
    "scheurkade_data = hydrodynamic_data.sel({'STATION':'Scheurkade'})\n",
    "scheurkade_data['TIME'] = scheurkade_data.TIME.values - np.timedelta64(20,'m')\n",
    "\n",
    "for previous_node in previous_nodes:\n",
    "    #Inbound_Vessels_Condition1\n",
    "    vessel_specification = tidal_window_constructor.vessel_specifications({rule_constructor.vessel_characteristics.min_ge_Length: 180,\n",
    "                                                                           rule_constructor.vessel_characteristics.min_ge_Draught: 11.0, #11.0\n",
    "                                                                           rule_constructor.vessel_characteristics.max_lt_Draught: 14.3},\n",
    "                                                                           '(x and x and x)',rule_constructor.vessel_direction.inbound.value)\n",
    "\n",
    "    window_specification = tidal_window_constructor.horizontal_tidal_window_specifications(tidal_window_constructor.horizontal_tidal_window_method.maximum.value,\n",
    "                                                                                           {tidal_window_constructor.tidal_period.Flood.value: 2*knots,tidal_window_constructor.tidal_period.Ebb.value: 2*knots})\n",
    "\n",
    "\n",
    "    horizontal_tidal_window_inputs.append(tidal_window_constructor.horizontal_tidal_window_input(vessel_specifications = vessel_specification,\n",
    "                                                                                                 window_specifications = window_specification,\n",
    "                                                                                                 condition = {'Origin': previous_node, 'Destination': next_node},\n",
    "                                                                                                 data = scheurkade_data))\n",
    "    #Inbound_Vessels_Condition2\n",
    "    vessel_specification = tidal_window_constructor.vessel_specifications({rule_constructor.vessel_characteristics.min_ge_Draught: 14.3},\n",
    "                                                  'x',rule_constructor.vessel_direction.inbound.value)\n",
    "\n",
    "    window_specification = tidal_window_constructor.horizontal_tidal_window_specifications(tidal_window_constructor.horizontal_tidal_window_method.point_based.value,\n",
    "                                                                                           {tidal_window_constructor.tidal_period.Flood.value: [1.3*0.5*knots,0.7*0.5*knots],tidal_window_constructor.tidal_period.Ebb.value:tidal_window_constructor.accessibility.inaccessible.value})\n",
    "\n",
    "    horizontal_tidal_window_inputs.append(tidal_window_constructor.horizontal_tidal_window_input(vessel_specifications = vessel_specification,\n",
    "                                                                                                 window_specifications = window_specification,\n",
    "                                                                                                 condition = {'Origin': previous_node, 'Destination': next_node},\n",
    "                                                                                                 data = scheurkade_data))\n",
    "\n",
    "    #Outbound_Vessels_Condition1  \n",
    "    vessel_specification = tidal_window_constructor.vessel_specifications({rule_constructor.vessel_characteristics.min_ge_Length: 200,\n",
    "                                                                           rule_constructor.vessel_characteristics.min_ge_Draught: 12.0, #12.0\n",
    "                                                                           rule_constructor.vessel_characteristics.max_lt_Draught: 14.3},\n",
    "                                                                           '(x and x and x)',rule_constructor.vessel_direction.outbound.value)\n",
    "\n",
    "    window_specification = tidal_window_constructor.horizontal_tidal_window_specifications(tidal_window_constructor.horizontal_tidal_window_method.maximum.value,\n",
    "                                                                                           {tidal_window_constructor.tidal_period.Flood.value: 2*knots,tidal_window_constructor.tidal_period.Ebb.value:tidal_window_constructor.accessibility.accessible.value})\n",
    "\n",
    "\n",
    "    horizontal_tidal_window_inputs.append(tidal_window_constructor.horizontal_tidal_window_input(vessel_specifications = vessel_specification,\n",
    "                                                                                                 window_specifications = window_specification,\n",
    "                                                                                                 condition = {'Origin': next_node, 'Destination': previous_node},\n",
    "                                                                                                 data = scheurkade_data))\n",
    "\n",
    "    #Outbound_Vessels_Condition2\n",
    "    vessel_specification = tidal_window_constructor.vessel_specifications({rule_constructor.vessel_characteristics.min_ge_Draught: 14.3}, #14.3\n",
    "                                                  'x',rule_constructor.vessel_direction.outbound.value)\n",
    "\n",
    "    window_specification = tidal_window_constructor.horizontal_tidal_window_specifications(tidal_window_constructor.horizontal_tidal_window_method.point_based.value,\n",
    "                                                                                           {tidal_window_constructor.tidal_period.Flood.value: [1.3*0.5*knots,0.7*0.5*knots],tidal_window_constructor.tidal_period.Ebb.value:tidal_window_constructor.accessibility.inaccessible.value})\n",
    "\n",
    "    horizontal_tidal_window_inputs.append(tidal_window_constructor.horizontal_tidal_window_input(vessel_specifications = vessel_specification,\n",
    "                                                                                                 window_specifications = window_specification,\n",
    "                                                                                                 condition = {'Origin': next_node, 'Destination': previous_node},\n",
    "                                                                                                 data = scheurkade_data))\n",
    "\n",
    "network_properties.append_horizontal_tidal_restriction_to_network(FG,node,horizontal_tidal_window_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9c0cd1",
   "metadata": {},
   "source": [
    "### Import origin destination matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b931d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path+'\\\\02_Data_Processing\\\\01_AIS_data\\origin_destination_matrix.pickle','rb') as handle: #model_no_tidal_window\n",
    "    origin_destination_matrix = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c76e4a3",
   "metadata": {},
   "source": [
    "### Create vessels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb97fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create vessels\n",
    "list_of_vessels = []\n",
    "for loc,info in origin_destination_matrix.iterrows():\n",
    "    Vessel = type('Vessel', (vessel_.IsVessel,\n",
    "                             port.HasPortAccess, \n",
    "                             port.HasAnchorage, \n",
    "                             port.HasTurningBasin, \n",
    "                             port.HasTerminal), {})\n",
    "    if info.origin_node in ['8868178','8866859','8866999']:\n",
    "        bound = 'outbound'\n",
    "    else:\n",
    "        bound = 'inbound'\n",
    "\n",
    "    created_vessel = create_vessel(Vessel,\n",
    "                                   env=env,\n",
    "                                   name=info['name'],\n",
    "                                   origin=info['origin_node'],\n",
    "                                   destination=info['berth_node'][0],\n",
    "                                   next_destination=np.append([],info['destination_node']),\n",
    "                                   beam=info['width'],\n",
    "                                   length=info['length'],\n",
    "                                   draught=info['draught'],\n",
    "                                   delta_draught=np.append([],info['(un)loading']),\n",
    "                                   berthing_time=pd.Timedelta(1,'s'),\n",
    "                                   unloading_time=np.append([],info['(un)loading time']),\n",
    "                                   turning_time= [pd.Timedelta(0,'s')], #np.append([],info['turning_time'][0]),\n",
    "                                   arrival_time=info['arrival']+pd.Timedelta(1,'h'),\n",
    "                                   terminal_of_call=np.array(['Koole' for i in range(len(list(info['berth_of_call'])))]),\n",
    "                                   berth_of_call=np.array(info['berth_of_call']),\n",
    "                                   additional_waiting_time = pd.Timedelta(0,'s'),\n",
    "                                   bound=bound)\n",
    "    list_of_vessels.append(created_vessel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be6f986",
   "metadata": {},
   "source": [
    "### Import simulation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1455ba6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_path+'\\\\01_Simulation_results\\\\model_outcome_base.pickle','rb') as handle: #full_model\n",
    "    full_model_comparison_df = pickle.load(handle)\n",
    "    \n",
    "with open(output_path+'\\\\01_Simulation_results\\\\model_without_turning.pickle','rb') as handle: #model_no_priority_no_tidal_window\n",
    "    model_without_turning = pickle.load(handle)\n",
    "    \n",
    "with open(output_path+'\\\\01_Simulation_results\\\\model_outcome_no_priority_no_tidal_window.pickle','rb') as handle: #model_no_priority_no_tidal_window\n",
    "    model_no_priority_no_tidal_window_comparison_df = pickle.load(handle)   \n",
    "    \n",
    "with open(output_path+'\\\\01_Simulation_results\\\\model_with_shallowing.pickle','rb') as handle: #model_no_priority_no_tidal_window\n",
    "    model_with_shallowing = pickle.load(handle)   \n",
    "    \n",
    "with open(output_path+'\\\\01_Simulation_results\\\\model_without_long_laytimes.pickle','rb') as handle: #model_no_priority_no_tidal_window\n",
    "    model_without_long_laytimes = pickle.load(handle)\n",
    "    \n",
    "with open(output_path+'\\\\01_Simulation_results\\\\model_outcome_no_priority.pickle','rb') as handle: #model_no_priority\n",
    "    model_no_priority_comparison_df = pickle.load(handle)\n",
    "    \n",
    "with open(output_path+'\\\\01_Simulation_results\\\\model_outcome_no_tidal_window.pickle','rb') as handle: #model_no_tidal_window\n",
    "    model_no_tidal_window_comparison_df = pickle.load(handle)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a60670",
   "metadata": {},
   "source": [
    "### Derive shiptype dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6d6a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "ship_types = {}\n",
    "for row,trip_info in origin_destination_matrix.iterrows():\n",
    "    for ship_type,ship_dimensions in type_dataframe.iterrows():\n",
    "        if trip_info.length <= ship_dimensions.Length and trip_info.width <= ship_dimensions.Width and trip_info.draught <= ship_dimensions.Draught:\n",
    "            ship_types[trip_info.trip_id] = ship_type\n",
    "            break\n",
    "shiptype_df = pd.DataFrame.from_dict(ship_types, orient='index', columns=['Shiptype'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bbdd6c",
   "metadata": {},
   "source": [
    "## Figure 07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0ebf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(2,1,figsize=[12,16])\n",
    "ax_left1 = axes[0]\n",
    "ax_right1 = ax_left1.twinx()\n",
    "ax_left2 = axes[1]\n",
    "ax_right2 = ax_left2.twinx()\n",
    "\n",
    "vessel = list_of_vessels[274]\n",
    "vessel._T = 14.2\n",
    "vessel.bound = 'inbound'\n",
    "vessel.route = nx.dijkstra_path(FG,'8866969','8866999',)\n",
    "_,_,ax_left1,ax_right1 = vessel.env.vessel_traffic_service.provide_tidal_windows(vessel = vessel,\n",
    "                                                            route = vessel.route,ax_left=ax_left1,ax_right=ax_right1,\n",
    "                                                            time_start = pd.Timestamp('2019-01-02 18:20').to_datetime64(),\n",
    "                                                            time_end =  pd.Timestamp('2019-01-05').to_datetime64(),\n",
    "                                                            plot=True)\n",
    "\n",
    "vessel = list_of_vessels[274]\n",
    "vessel._T = 15.0\n",
    "vessel.bound = 'inbound'\n",
    "vessel.route = nx.dijkstra_path(FG,'8866969','8866999',)\n",
    "_,_,ax_left2,ax_right2 = vessel.env.vessel_traffic_service.provide_tidal_windows(vessel = vessel,\n",
    "                                                            route = vessel.route,ax_left=ax_left2,ax_right=ax_right2,\n",
    "                                                            time_start = pd.Timestamp('2019-01-02 18:20').to_datetime64(),\n",
    "                                                            time_end =  pd.Timestamp('2019-01-05').to_datetime64(),\n",
    "                                                            plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187a66e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlabels = ax_left1.get_xticklabels()\n",
    "labels = deepcopy(xlabels)\n",
    "\n",
    "ax_left = ax_left1\n",
    "ax_right = ax_right1\n",
    "ax_left.set_title('')\n",
    "lines = list(ax_left.get_lines())\n",
    "for line in lines:\n",
    "    line.set_linewidth(4)\n",
    "lines = list(ax_right.get_lines())\n",
    "for index,line in enumerate(lines):\n",
    "    line.set_linewidth(4)\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    for x,y in line.get_xydata():\n",
    "        x_data.append(x)\n",
    "        y_data.append(y/knots)\n",
    "    if index:\n",
    "        ax_right.axhline(y/knots,color='firebrick',linewidth=4,linestyle='--')\n",
    "    else:\n",
    "        ax_right.plot(x_data,y_data,color='firebrick',linewidth=4)\n",
    "    line.remove()\n",
    "\n",
    "xticks = ax_left.get_xticks()\n",
    "yticks = ax_left.get_yticks()\n",
    "ylabels = ax_left.get_yticklabels()\n",
    "ax_left.set_xticks(xticks,width=20)\n",
    "ax_left.set_xticklabels([])\n",
    "ax_left.set_xlabel([])\n",
    "ax_left.set_yticks(yticks)\n",
    "ax_left.set(xlabel=None)\n",
    "ax_left.xaxis.set_tick_params(width=1,length=10)\n",
    "ax_left.yaxis.set_tick_params(width=1,length=10)\n",
    "ax_right.yaxis.set_tick_params(width=1,length=10)\n",
    "ax_left.set_yticklabels(ylabels,fontsize=22)\n",
    "ax_left.set_ylabel('Net UKC [m]',fontsize=22)\n",
    "ax_right.set_ylabel('Current velocity [kn]',fontsize=22)\n",
    "ax_right.set_ylim(-3,3)\n",
    "ax_right.set_yticks(np.arange(-3,3+1,1))\n",
    "ax_right.set_yticklabels(np.arange(-3,3+1,1),fontsize=22)\n",
    "legend = ax_left.get_legend()\n",
    "legend.set_bbox_to_anchor([1.1,1.025])\n",
    "lines_patches = list(legend.get_lines())\n",
    "legend.remove()\n",
    "\n",
    "ax_left = ax_left2\n",
    "ax_right = ax_right2\n",
    "\n",
    "ax_left.set_title('')\n",
    "lines = list(ax_left.get_lines())\n",
    "for line in lines:\n",
    "    line.set_linewidth(4)\n",
    "lines = list(ax_right.get_lines())\n",
    "for index,line in enumerate(lines):\n",
    "    line.set_linewidth(4)\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    for x,y in line.get_xydata():\n",
    "        x_data.append(x)\n",
    "        y_data.append(y/knots)\n",
    "    if index:\n",
    "        ax_right.axhline(y/knots,color='firebrick',linewidth=4,linestyle='--')\n",
    "    else:\n",
    "        ax_right.plot(x_data,y_data,color='firebrick',linewidth=4)\n",
    "    line.remove()\n",
    "\n",
    "xticks = ax_left.get_xticks()\n",
    "yticks = ax_left.get_yticks()\n",
    "ylabels = ax_left.get_yticklabels()\n",
    "ax_left.set_yticks(np.arange(-2,1+0.5,0.5))\n",
    "ax_left.set_yticklabels(np.arange(-2,1+0.5,0.5),fontsize=22)\n",
    "ax_left.set_xticks(xticks)\n",
    "ax_left.set_xticklabels(labels,fontsize=22,rotation=45,color='k')\n",
    "ax_left.set_xlabel('Date',fontsize=22)\n",
    "ax_left.xaxis.set_tick_params(width=1,length=10)\n",
    "ax_left.yaxis.set_tick_params(width=1,length=10)\n",
    "ax_right.yaxis.set_tick_params(width=1,length=10)\n",
    "ax_left.set_ylabel('Net UKC [m]',fontsize=22)\n",
    "ax_right.set_ylabel('Current velocity [kn]',fontsize=22)\n",
    "ax_right.set_ylim(-3,3)\n",
    "ax_right.set_yticks(np.arange(-3,3+1,1))\n",
    "ax_right.set_yticklabels(np.arange(-3,3+1,1),fontsize=22)\n",
    "legend = ax_left.get_legend()\n",
    "lines_patches.extend(list(legend.get_patches()))\n",
    "targ = ax_right2.axhline(0.5,color='firebrick',linewidth=4,linestyle='-.')\n",
    "for handle in lines_patches:\n",
    "    handle.set_linewidth(4)\n",
    "lines_patches.insert(4,targ)\n",
    "ax_left1.legend(lines_patches,['Net UKC','Required net UKC','Current velocity','Critical current velocity',\n",
    "                               'Point-based current velocity\\n(flood and decreasing)','Vertical tidal windows','Horizontal tidal windows',\n",
    "                               'Resulting tidal windows'],\n",
    "               frameon=False,\n",
    "               prop={'size':18},\n",
    "               loc='upper right',\n",
    "               bbox_to_anchor=[1.65,1.05])\n",
    "\n",
    "patches1 = list(legend.get_patches())\n",
    "ax_left1.text(0.025,0.925,'a)', weight='bold', fontsize=26, transform=ax_left1.transAxes)\n",
    "ax_left2.text(0.025,0.925,'b)', weight='bold', fontsize=26, transform=ax_left2.transAxes)\n",
    "ax_left.text(-0.625,0.925,' ', fontsize=26, transform=ax_left1.transAxes)\n",
    "ax_left2.legend().remove()\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf9d53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(output_path+'\\\\02_Figures'+'\\\\Figure_07_Tidal_windows_examples.pdf',format='pdf', dpi=1000,bbox_inches='tight',facecolor=\"none\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f1e39d",
   "metadata": {},
   "source": [
    "## Figure 08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa74c9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = origin_destination_matrix.length.to_numpy()\n",
    "inbound_draught = origin_destination_matrix.draught.to_numpy()\n",
    "outbound_draught = [draught-np.sum(unloading) for draught,unloading in zip(origin_destination_matrix.draught.to_numpy(),origin_destination_matrix['(un)loading'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce812d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(1,2,figsize=[9,3],gridspec_kw={'width_ratios': [3,3]})\n",
    "\n",
    "no_tidal_window, = axes[0].fill([0,300,300,180,180,0],[0,0,11,11,13,13],facecolor='lightgreen',alpha=0.75)\n",
    "horizontal_tidal_window, = axes[0].fill([180,300,300,180],[11,11,13,13],facecolor='lightcoral',alpha=0.5)\n",
    "axes[0].fill([180,300,300,180],[13,13,14.3,14.3],\n",
    "             edgecolor=make_rgb_transparent(mpl.colors.to_rgb('lightcoral'),mpl.colors.to_rgb('w'),0.5),\n",
    "             facecolor=make_rgb_transparent(mpl.colors.to_rgb('C0'),mpl.colors.to_rgb('w'),0.75),\n",
    "             hatch=\"//\",linewidth=0)\n",
    "horizontal_tidal_point, = axes[0].fill([0,0,0,0],[0,0,0,0],facecolor='lightcoral',alpha=0.75)\n",
    "axes[0].fill([0,0,300,300],[14.3,16,16,14.3],\n",
    "             edgecolor=make_rgb_transparent(mpl.colors.to_rgb('lightcoral'),mpl.colors.to_rgb('w'),0.75),\n",
    "             facecolor=make_rgb_transparent(mpl.colors.to_rgb('C0'),mpl.colors.to_rgb('w'),0.75),\n",
    "             hatch=\"//\",linewidth=0)\n",
    "vertical_tidal_window, = axes[0].fill([0,180,180,0],[14.3,14.3,13,13],facecolor='C0',alpha=0.75)\n",
    "axes[0].scatter(length,inbound_draught,zorder=100,color='k',s=25,alpha=0.6,edgecolor=\"none\")\n",
    "axes[0].set_xlim(0,300)\n",
    "axes[0].set_ylim(0,16)\n",
    "axes[0].set_xlabel('Vessel length [m]',fontsize=9)\n",
    "axes[0].set_ylabel('Draught [m]',fontsize=9)\n",
    "axes[0].set_yticks(np.arange(0,17,5))\n",
    "axes[0].set_yticks(np.arange(0,17,1), minor = True)\n",
    "axes[0].set_title('Inbound vessels',fontsize=10);\n",
    "\n",
    "axes[1].fill([0,300,300,200,200,0],[0,0,12,12,13,13],facecolor='lightgreen',alpha=0.75)\n",
    "axes[1].fill([200,300,300,200],[13,13,14.3,14.3],\n",
    "             edgecolor=make_rgb_transparent(mpl.colors.to_rgb('lightcoral'),mpl.colors.to_rgb('w'),0.5),\n",
    "             facecolor=make_rgb_transparent(mpl.colors.to_rgb('C0'),mpl.colors.to_rgb('w'),0.75),\n",
    "             hatch=\"//\",linewidth=0)\n",
    "horizontal_tidal_point, = axes[0].fill([0,0,0,0],[0,0,0,0],facecolor='lightcoral',alpha=0.75)\n",
    "axes[1].fill([0,0,300,300],[14.3,16,16,14.3],\n",
    "             edgecolor=make_rgb_transparent(mpl.colors.to_rgb('lightcoral'),mpl.colors.to_rgb('w'),0.75),\n",
    "             facecolor=make_rgb_transparent(mpl.colors.to_rgb('C0'),mpl.colors.to_rgb('w'),0.75),\n",
    "             hatch=\"//\",linewidth=0)\n",
    "axes[1].fill([200,300,300,200],[12,12,13,13],facecolor='lightcoral',alpha=0.5)\n",
    "axes[1].fill([0,200,200,0],[14.3,14.3,13,13],facecolor='C0',alpha=0.75)\n",
    "axes[1].scatter(length,outbound_draught,zorder=100,color='k',s=25,alpha=0.6,edgecolor=\"none\")\n",
    "axes[1].set_xlim(0,300)\n",
    "axes[1].set_ylim(0,16)\n",
    "axes[1].set_xlabel('Vessel length [m]',fontsize=9)\n",
    "axes[1].set_yticks(np.arange(0,17,5))\n",
    "axes[1].set_yticks(np.arange(0,17,1), minor = True)\n",
    "axes[1].set_yticklabels([])\n",
    "axes[1].set_title('Outbound vessels',fontsize=10)\n",
    "mpl.rcParams['hatch.linewidth'] = 4\n",
    "v = axes[0].scatter([-1],[-1],s=20,color='k')\n",
    "plt.legend([no_tidal_window,vertical_tidal_window,horizontal_tidal_window,horizontal_tidal_point,v],\n",
    "           ['No tidal window',\n",
    "            'Vertical tidal window',\n",
    "            'Horizontal tidal window\\n(critical velocity)',\n",
    "            'Horizontal tidal window\\n(point-based)',\n",
    "            'Vessel'],bbox_to_anchor=[1,1.05],prop={'size':9},frameon=False)\n",
    "axes[0].text(0.025,0.925,'a)', weight='bold', fontsize=12, transform=axes[0].transAxes)\n",
    "axes[1].text(0.025,0.925,'b)', weight='bold', fontsize=12, transform=axes[1].transAxes)\n",
    "axes[0].text(150,15,str(calculate_ship_percentage(origin_destination_matrix,200,300,14.3,16,'inbound'))+'%',fontsize=12,va='center')\n",
    "axes[0].text(200,13.6,str(calculate_ship_percentage(origin_destination_matrix,200,300,13,14.2,'inbound'))+'%',fontsize=12,va='center')\n",
    "axes[0].text(200,12.0,str(calculate_ship_percentage(origin_destination_matrix,180,300,11,12.9,'inbound'))+'%',fontsize=12,va='center')\n",
    "axes[0].text(150,3.0,str((calculate_ship_percentage(origin_destination_matrix,0,300,0,10.9,'inbound')+\n",
    "                          calculate_ship_percentage(origin_destination_matrix,0,179,11,12.9,'inbound')))+'%',fontsize=12,va='center')\n",
    "axes[0].text(100,13.6,str(calculate_ship_percentage(origin_destination_matrix,0,199,13,14.2,'inbound'))+'%',fontsize=12,va='center')\n",
    "axes[1].text(150,15,str(calculate_ship_percentage(origin_destination_matrix,200,300,14.3,16,'outbound'))+'%',fontsize=12,va='center')\n",
    "axes[1].text(200,13.6,str(calculate_ship_percentage(origin_destination_matrix,200,300,13,14.2,'outbound'))+'%',fontsize=12,va='center')\n",
    "axes[1].text(200,12.5,str(calculate_ship_percentage(origin_destination_matrix,200,300,12,12.9,'outbound'))+'%',fontsize=12,va='center')\n",
    "axes[1].text(150,3.0,str((calculate_ship_percentage(origin_destination_matrix,0,300,0,11.9,'outbound')+\n",
    "                          calculate_ship_percentage(origin_destination_matrix,0,199,12,13.9,'outbound')))+'%',fontsize=12,va='center')\n",
    "axes[1].text(100,13.6,str(calculate_ship_percentage(origin_destination_matrix,0,199,13,14.2,'outbound'))+'%',fontsize=12,va='center')\n",
    "plt.subplots_adjust(wspace=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbb4529",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(output_path+'\\\\02_Figures'+'\\\\Figure_08_Tidal_windows_examples.pdf',format='pdf', dpi=1000,bbox_inches='tight',facecolor=\"none\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27aa185c",
   "metadata": {},
   "source": [
    "## Figure 09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55292b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(38, 12),gridspec_kw={'width_ratios':[1,2]},facecolor=\"none\")\n",
    "ax[1].set_facecolor('none')\n",
    "data = calculate_waiting_time_percentages(full_model_comparison_df,\n",
    "                                          model_no_priority_comparison_df,\n",
    "                                          model_no_tidal_window_comparison_df,\n",
    "                                          cascading=True)\n",
    "\n",
    "labels = ['Long-term unresolved                      ',\n",
    "          'Short-term                                ',\n",
    "          'Presumingly prioritized vessel (long-term)',\n",
    "          'Presumingly prioritized vessel (short-term)',\n",
    "          'Availability (direct, non-cascaded)',\n",
    "          'Availability (indirect, cascaded due to prioritization)',\n",
    "          'Availability (indirect, cascaded due to tidal restrictions)',\n",
    "          'Tidal restrictions']\n",
    "\n",
    "colors = ['#e63b60','#fa96ac','#03045e','#03045e','#16558F','C0','skyblue','C1']\n",
    "edgecolors = ['none','none','#e63b60','#fa96ac','none','none','none','none']\n",
    "text_colors = ['w','w','w','w','w','k','k','k']\n",
    "\n",
    "ax[0].set_aspect('equal')\n",
    "wedges, texts, percs = ax[0].pie(data, startangle=90,colors=colors,radius=1.25,center=(0,-0.15),\n",
    "                                 wedgeprops=dict(width=0.65),autopct=\"%1.1f%%\")\n",
    "\n",
    "mpl.rcParams['hatch.linewidth'] = 7\n",
    "wedges[2].set_hatch('/')\n",
    "wedges[2].set_edgecolor('#e63b60')\n",
    "wedges[2].set_linewidth(0)\n",
    "wedges[3].set_hatch('/')\n",
    "wedges[3].set_edgecolor('#fa96ac')\n",
    "wedges[3].set_linewidth(0)\n",
    "groups = [[0,1], [2], [3,4,5], [6], [7]]\n",
    "radfraction = [0,0,0,0,0,0,0,0]\n",
    "for group in groups:\n",
    "    ang = np.deg2rad((wedges[group[-1]].theta2 + wedges[group[0]].theta1) / 2)\n",
    "    for j in group:\n",
    "        center = radfraction[j] * wedges[j].r * np.array([np.cos(ang), np.sin(ang)])\n",
    "        wedges[j].set_center(center)\n",
    "        texts[j].set_position(np.array(texts[j].get_position()) + center)\n",
    "        percs[j].set_position(np.array(percs[j].get_position()) + center)\n",
    "    \n",
    "for text, color in zip(percs, text_colors):\n",
    "    text.set_color(color) \n",
    "    \n",
    "kw = dict(arrowprops=dict(arrowstyle=\"-\"),\n",
    "         zorder=0, va=\"center\")\n",
    "\n",
    "text_height = [0,0,0,0,0,0,0,0]#[0,0,0,0,-0.3,-0.15,0]\n",
    "text_factor = [0.75,0.75,0.75,0.75,0.75,0.6,0.75,0.9] #[0.75,0.75,0.8,0.8,0.625,0.75,0.875]\n",
    "font_factor = [1,1,1,1,1,1,1,1]\n",
    "location_correction_x = [0,0,0,0.10,0,0,0,0] #[0,0,0,0,0.05,0.05,0]\n",
    "location_correction_y = [0,0,0,0.15,0,0,0,0] #[0,0,0,0,0.05,0.05,0]\n",
    "for i, p in enumerate(wedges):\n",
    "    ang = (p.theta2 - p.theta1)/2. + p.theta1\n",
    "    y = np.sin(np.deg2rad(ang))+location_correction_y[i]\n",
    "    x = np.cos(np.deg2rad(ang))+location_correction_x[i]\n",
    "    percs[i]._x = x*text_factor[i]*1.2\n",
    "    percs[i]._y = y*text_factor[i]*1.2\n",
    "    percs[i].set_fontsize(32*font_factor[i])\n",
    "\n",
    "percs[3].set_text(\"\")\n",
    "percs[5].set_text(\"\")\n",
    "percs[6].set_text(\"\")\n",
    "percs[7].set_text(\"\")\n",
    "\n",
    "dummy_wedge = mpl.patches.Wedge(0,0,0,0)\n",
    "dummy_wedge.set_color('none')\n",
    "\n",
    "wedges.insert(2,dummy_wedge)\n",
    "wedges.insert(3,dummy_wedge)\n",
    "wedges.insert(4,dummy_wedge)\n",
    "wedges.extend([dummy_wedge])\n",
    "wedges.extend([dummy_wedge])\n",
    "wedges.extend([dummy_wedge])\n",
    "wedges.extend([dummy_wedge])\n",
    "labels.insert(2,'')\n",
    "labels.insert(3,'')\n",
    "labels.insert(4,'')\n",
    "labels.extend([''])\n",
    "labels.extend([''])\n",
    "labels.extend([''])\n",
    "\n",
    "ax[0].legend(wedges,labels,loc=\"center left\",bbox_to_anchor=(0, 0, 1, -0.75),frameon=False,fontsize=32,ncol=3)\n",
    "\n",
    "\n",
    "total_waiting_time = np.round(np.sum(full_model_comparison_df.Observed_total_waiting_time).total_seconds()/(24*3600),2)\n",
    "number_of_waiting_vessels = len(full_model_comparison_df[full_model_comparison_df.Observed_total_waiting_time > pd.Timedelta(0,'s')])\n",
    "\n",
    "ax[1].grid(axis=\"x\",color='k',linewidth=2)\n",
    "bar_height = 0.6\n",
    "offset = [(bar_height/2+0.025),-(bar_height/2+0.025)]\n",
    "model_outcome = [full_model_comparison_df]\n",
    "comparison_outcome_tidal_window = [model_no_tidal_window_comparison_df,model_no_priority_no_tidal_window_comparison_df]\n",
    "comparison_outcome_priority = [model_no_priority_comparison_df,model_no_priority_no_tidal_window_comparison_df]\n",
    "for index,datatype in enumerate(model_outcome):\n",
    "    data = {}\n",
    "    total_waiting_time = {}\n",
    "    groups = list(type_dataframe.index)\n",
    "    indexes = np.arange(len(groups))\n",
    "    if not index:\n",
    "        for ship_index,shiptype in enumerate(reversed(type_dataframe.index)):\n",
    "            mask = model_outcome[index].index.isin(shiptype_df[shiptype_df.Shiptype == shiptype].index)\n",
    "            data[shiptype] = calculate_waiting_time_percentages(model_outcome[index][mask],\n",
    "                                                                comparison_outcome_priority[index][mask],\n",
    "                                                                comparison_outcome_tidal_window[index][mask],True,True)\n",
    "            total_waiting_time[shiptype] = np.sum(model_outcome[index][mask].Observed_total_waiting_time)\n",
    "            reorder_list = [5,6,0,1,2,3,4]\n",
    "            reordered_data = [x for _, x in sorted(zip(reorder_list, data[shiptype]))]\n",
    "            reordered_colors = [x for _, x in sorted(zip(reorder_list, colors))]\n",
    "            reordered_edgecolors = [x for _, x in sorted(zip(reorder_list, edgecolors))]\n",
    "            sub_df = full_model_comparison_df.loc[shiptype_df[shiptype_df.Shiptype == shiptype].index]          \n",
    "            number_of_vessels = len(sub_df[sub_df.Observed_total_waiting_time > pd.Timedelta(0,'s')])\n",
    "            number_of_vessels = 1\n",
    "            averaged_waiting_time = list(reversed(np.cumsum(np.array(reordered_data)*total_waiting_time[shiptype]/np.timedelta64(1,'s')/(24*3600)/number_of_vessels)))\n",
    "            ax[1].barh(y=ship_index,\n",
    "                       width=averaged_waiting_time,\n",
    "                       color=list(reversed(reordered_colors)),height=bar_height,zorder=20,edgecolor=list(reversed(reordered_edgecolors)),linewidth=0)\n",
    "\n",
    "    for loc,patch in enumerate(ax[1].patches):\n",
    "        if patch.get_facecolor() == tuple(np.append(mpl.colors.to_rgb('#03045e'),1.0)):\n",
    "            patch.set_hatch('/')\n",
    "\n",
    "groups.extend([''])\n",
    "for loc,group in enumerate(groups):\n",
    "    sub_df = full_model_comparison_df.loc[shiptype_df[shiptype_df.Shiptype == group].index]  \n",
    "    number_of_vessels = len(sub_df[sub_df.Observed_total_waiting_time > pd.Timedelta(0,'s')])\n",
    "    groups[loc] = group+'\\n('+str(np.round(number_of_vessels/191*100,1))+'%)'\n",
    "ax[1].set_yticklabels(list(reversed(groups)))\n",
    "for label in ax[1].get_yticklabels():\n",
    "    label.set_ha('right')\n",
    "    label.set_fontsize(32)\n",
    "ax[1].set_xlabel('Average waiting time per vessel [days]',fontsize=32)\n",
    "#ax[1].set_xticks(np.arange(0,5,1))\n",
    "ax[1].xaxis.set_tick_params(labelsize=28,length=20, width=2)\n",
    "ax[1].set_position(mpl.transforms.Bbox([[0.475, 0.15], [1, 0.95]]))\n",
    "ax[1].spines['top'].set_visible(False)\n",
    "ax[1].spines['right'].set_visible(False)\n",
    "ax[1].spines['bottom'].set_visible(False)\n",
    "ax[1].spines['left'].set_visible(False)\n",
    "ax[1].yaxis.set_tick_params(length=10, width=0)\n",
    "#ax[0].text(-1.2,-1,'Base case',fontsize=32,horizontalalignment = 'left')\n",
    "#fig.suptitle('Cause for waiting times of vessels\\n ',fontsize=40,fontweight='bold',fontname ='arial',verticalalignment='center')\n",
    "ax[1].text(-77,-1.75,'Unresolved waiting time (53.5%)',fontweight='bold',fontsize=32)\n",
    "ax[1].text(-16.8,-1.75,'Resolved waiting time (46.5%)',fontweight='bold',fontsize=32)\n",
    "line = mpl.lines.Line2D([-17.2,112],[-1.875,-1.875], lw=4., color='k')\n",
    "line.set_clip_on(False)\n",
    "ax[1].add_line(line)\n",
    "line = mpl.lines.Line2D([-17.2,112],[-1.45,-1.45], lw=4., color='k')\n",
    "line.set_clip_on(False)\n",
    "ax[1].add_line(line)\n",
    "line = mpl.lines.Line2D([-17.2,112],[-4.0,-4.0], lw=4., color='k')\n",
    "line.set_clip_on(False)\n",
    "ax[1].add_line(line)\n",
    "line = mpl.lines.Line2D([-77,-20],[-1.875,-1.875], lw=4., color='k')\n",
    "line.set_clip_on(False)\n",
    "ax[1].add_line(line)\n",
    "line = mpl.lines.Line2D([-77,-20],[-1.45,-1.45], lw=4., color='k')\n",
    "line.set_clip_on(False)\n",
    "ax[1].add_line(line)\n",
    "line = mpl.lines.Line2D([-77,-20],[-4,-4], lw=4., color='k')\n",
    "line.set_clip_on(False)\n",
    "ax[1].add_line(line)\n",
    "ax[0].annotate(\"0.4%\",\n",
    "            xy=(0.01, 1.25), xycoords='data',fontsize=32,\n",
    "            xytext=(0.5, 1.65), textcoords='data',annotation_clip=False,\n",
    "            arrowprops=dict(arrowstyle=\"-\", connectionstyle=\"arc,angleA=-180,armA=165\",linewidth=5))\n",
    "ax[0].annotate(\"0.2%\",\n",
    "            xy=(0.04, 1.25), xycoords='data',fontsize=32,\n",
    "            xytext=(0.5, 1.5), textcoords='data',annotation_clip=False,\n",
    "            arrowprops=dict(arrowstyle=\"-\", connectionstyle=\"arc,angleA=-180,armA=155\",linewidth=5))\n",
    "ax[0].annotate(\"0.8%\",\n",
    "            xy=(0.09, 1.25), xycoords='data',fontsize=32,\n",
    "            xytext=(0.5, 1.35), textcoords='data',annotation_clip=False,\n",
    "            arrowprops=dict(arrowstyle=\"-\", connectionstyle=\"arc,angleA=-180,armA=140\",linewidth=5))\n",
    "ax[0].annotate(\"1.2%\",\n",
    "            xy=(1.13, -0.525), xycoords='data',fontsize=32,\n",
    "            xytext=(1.25, -1.25), textcoords='data',annotation_clip=False,\n",
    "            arrowprops=dict(arrowstyle=\"-\", connectionstyle=\"arc,angleA=90,armA=150\",linewidth=5))\n",
    "\n",
    "radius=0.55\n",
    "arc = mpl.patches.Arc((0, 0), radius*2, radius*2, color='k',linewidth=5, theta1=95, theta2=275)\n",
    "ax[0].add_patch(arc)\n",
    "arc = mpl.patches.Arc((0, 0), radius*2, radius*2, color='k',linewidth=5, theta1=285, theta2=85)\n",
    "ax[0].add_patch(arc)\n",
    "ax[0].scatter([0.05],[0.55],marker=(3,0,90),s=500,color='k')\n",
    "ax[0].scatter([-0.05],[0.55],marker=(3,0,270),s=500,color='k')\n",
    "ax[0].scatter([0.05],[-0.535],marker=(3,0,280),s=500,color='k')\n",
    "ax[0].scatter([0.15],[-0.525],marker=(3,0,100),s=500,color='k')\n",
    "ax[0].text(-0.5,-0.025,'53.5%',fontsize=32)\n",
    "ax[0].text(0.5,-0.025,'46.5%',fontsize=32,horizontalalignment='right')\n",
    "ax[0].scatter([0.15],[-0.525],marker=(3,0,100),s=500,color='k')\n",
    "ax[0].text(-1.25,1.10,'a)',fontweight='bold',fontsize=36)\n",
    "ax[0].text(1.45,1.10,'b)',fontweight='bold',fontsize=36)\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ce8d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(output_path+'\\\\02_Figures'+'\\\\Figure_09_Causality_waiting_times.pdf',format='pdf',dpi=500,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0140d1c4",
   "metadata": {},
   "source": [
    "## Figure 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894c9037",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrepancy_data = full_model_comparison_df.Observed_total_waiting_time-full_model_comparison_df.Modelled_total_waiting_time\n",
    "\n",
    "#unloading vessels\n",
    "unloading = [True if draught[0]>0 else False for draught in origin_destination_matrix['(un)loading'].to_numpy()]\n",
    "unloading_df = shiptype_df[shiptype_df.index.isin(origin_destination_matrix[unloading].trip_id)]\n",
    "\n",
    "#loading vessels\n",
    "loading = [True if draught[0]<0 else False for draught in origin_destination_matrix['(un)loading'].to_numpy()]\n",
    "loading_df = shiptype_df[shiptype_df.index.isin(origin_destination_matrix[loading].trip_id)]\n",
    "\n",
    "#not loading vessels\n",
    "not_loading = [True if draught[0]==0 else False for draught in origin_destination_matrix['(un)loading'].to_numpy()]\n",
    "not_loading_df = shiptype_df[shiptype_df.index.isin(origin_destination_matrix[not_loading].trip_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b41051",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "gs1 = GridSpec(2, 31,bottom=0.25,top=0.75,left=-0.5,right=1)\n",
    "ax1 = fig.add_subplot(gs1[0, 0:16])\n",
    "ax2 = fig.add_subplot(gs1[0, 18:22])\n",
    "ax3 = fig.add_subplot(gs1[0, 26:30])\n",
    "ax4 = fig.add_subplot(gs1[1, 0:16])\n",
    "ax5 = fig.add_subplot(gs1[1, 18:22])\n",
    "ax6 = fig.add_subplot(gs1[1, 26:30])\n",
    "\n",
    "df = discrepancy_data+full_model_comparison_df.Waiting_due_to_priority_inbound\n",
    "unloading_df = df[unloading_df.index]\n",
    "\n",
    "N, bins, patches = ax1.hist([time.total_seconds()/3600 for time in unloading_df[unloading_df > pd.Timedelta(0,'s')]],edgecolor='k',bins=np.arange(0,1000,1),cumulative=-1,density=True,facecolor='#fa96ac',)\n",
    "for i,_bin in enumerate(np.arange(0,100,1)):\n",
    "    if _bin > 11:\n",
    "        patches[i].set_facecolor('#e63b60')\n",
    "\n",
    "ax1.set_xlim(0,96)\n",
    "ax1.set_xticks(np.arange(0,100,6))\n",
    "ax1.set_xticklabels(np.arange(0,100,6))\n",
    "ax1.set_ylim(0,1)\n",
    "ax1.set_ylabel('Density [-]');\n",
    "\n",
    "y = [0,1,2,3,4,5]\n",
    "xunloading_short = []\n",
    "xunloading_long = []\n",
    "for shiptype in ['Coaster','Handysize','Handymax','Panamax','New Panamax','Suezmax']:\n",
    "    xunloading_short.append(len(unloading_df.loc[unloading_df.keys().isin(shiptype_df[shiptype_df.Shiptype == shiptype].index)][(unloading_df > pd.Timedelta(0,'s'))&(unloading_df <= pd.Timedelta(12,'h'))]))\n",
    "    xunloading_long.append(len(unloading_df.loc[unloading_df.keys().isin(shiptype_df[shiptype_df.Shiptype == shiptype].index)][unloading_df > pd.Timedelta(12,'h')]))\n",
    "\n",
    "xunloading_shorts = xunloading_short/np.sum(xunloading_short)+0.01\n",
    "xunloading_longs = xunloading_long/np.sum(xunloading_long)+0.01\n",
    "    \n",
    "ax2.barh(y, xunloading_shorts, align='center', color='#fa96ac')\n",
    "ax2.set_xticklabels([]);\n",
    "ax2.set_yticklabels([]);\n",
    "ax3.barh(y, xunloading_longs, align='center', color='#e63b60')\n",
    "ax3.set_xticklabels([]);\n",
    "ax3.set_yticklabels([]); \n",
    "ax2.axis('off')\n",
    "ax3.axis('off')\n",
    "\n",
    "loading_df = df[loading_df.index]\n",
    "N, bins, patches = ax4.hist([time.total_seconds()/3600 for time in loading_df[loading_df > pd.Timedelta(0,'s')]],edgecolor='k',bins=np.arange(0,1000,1),cumulative=-1,density=True,facecolor='#fa96ac',)\n",
    "for i,_bin in enumerate(np.arange(0,100,1)):\n",
    "    if _bin > 11:\n",
    "        patches[i].set_facecolor('#e63b60')\n",
    "\n",
    "ax4.set_xlim(0,96)\n",
    "ax4.set_xticks(np.arange(0,100,6))\n",
    "ax4.set_xticklabels(np.arange(0,100,6))\n",
    "ax4.set_ylim(0,1)\n",
    "ax4.set_xlabel('Waiting time [hours]')\n",
    "ax4.set_ylabel('Density [-]')\n",
    "\n",
    "y = [0,1,2,3,4,5]\n",
    "xloading_short = []\n",
    "xloading_long = []\n",
    "for shiptype in ['Coaster','Handysize','Handymax','Panamax','New Panamax','Suezmax']:\n",
    "    xloading_short.append(len(loading_df.loc[loading_df.keys().isin(shiptype_df[shiptype_df.Shiptype == shiptype].index)][(loading_df > pd.Timedelta(0,'s'))&(loading_df <= pd.Timedelta(12,'h'))]))\n",
    "    xloading_long.append(len(loading_df.loc[loading_df.keys().isin(shiptype_df[shiptype_df.Shiptype == shiptype].index)][loading_df > pd.Timedelta(12,'h')]))\n",
    "\n",
    "xloading_shorts = xloading_short/np.sum(xloading_short)+0.01\n",
    "xloading_longs = xloading_long/np.sum(xloading_long)+0.01\n",
    "\n",
    "ax5.barh(y, xloading_shorts, align='center', color='#fa96ac')\n",
    "ax5.set_xticklabels([]);\n",
    "ax5.set_yticklabels([]);\n",
    "ax6.barh(y, xloading_longs, align='center', color='#e63b60')\n",
    "ax6.set_xticklabels([]);\n",
    "ax6.set_yticklabels([]);\n",
    "ax5.axis('off')\n",
    "ax6.axis('off')\n",
    "max_x = np.max([ax2.get_xlim()[1],ax3.get_xlim()[1],ax5.get_xlim()[1],ax6.get_xlim()[1]])\n",
    "for ax in [ax2,ax3,ax5,ax6]:\n",
    "    ax.set_xlim(0,max_x)\n",
    "    \n",
    "ax2.invert_xaxis()\n",
    "ax5.invert_xaxis()\n",
    "ax1.set_xticklabels([])\n",
    "ax1.spines[['right', 'top']].set_visible(False)\n",
    "ax4.spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "for loc,(label,label_short,label_long) in enumerate(zip(['Coaster','Handysize','Handymax','Panamax','New Panamax','Suezmax'],xunloading_shorts,xunloading_longs)):\n",
    "    ax3.text(-0.35,loc,label,horizontalalignment='center',verticalalignment='center')\n",
    "    ax2.text(label_short+0.01,loc,str(np.round((label_short-0.01)*100,1))+'%',horizontalalignment='right',verticalalignment='center')\n",
    "    ax3.text(label_long+0.01,loc,str(np.round((label_long-0.01)*100,1))+'%',horizontalalignment='left',verticalalignment='center')\n",
    "for loc,(label,label_short,label_long) in enumerate(zip(['Coaster','Handysize','Handymax','Panamax','New Panamax','Suezmax'],xloading_shorts,xloading_longs)):\n",
    "    ax6.text(-0.35,loc,label,horizontalalignment='center',verticalalignment='center')\n",
    "    ax5.text(label_short+0.01,loc,str(np.round((label_short-0.01)*100,1))+'%',horizontalalignment='right',verticalalignment='center')\n",
    "    ax6.text(label_long+0.01,loc,str(np.round((label_long-0.01)*100,1))+'%',horizontalalignment='left',verticalalignment='center')\n",
    "    \n",
    "ax1.text(54,0.95,'a) Unloading vessels ('+str(np.round(unloading_df.sum()/(unloading_df.sum()+loading_df.sum())*100,1))+'%)',weight='bold',horizontalalignment='left')\n",
    "ax4.text(54,0.95,'b) Loading vessels ('+str(np.round(loading_df.sum()/(unloading_df.sum()+loading_df.sum())*100,1))+'%)',weight='bold',horizontalalignment='left')\n",
    "legend1, = ax1.fill([0,0,0,0],[0,0,0,0],color='#fa96ac')\n",
    "legend2, = ax1.fill([0,0,0,0],[0,0,0,0],color='#e63b60')\n",
    "ax1.axvline(12,color='k')\n",
    "ax4.axvline(12,color='k')\n",
    "ax1.text(11.5,0.95,str(np.round((np.sum(xunloading_short)/(np.sum(xunloading_short)+np.sum(xunloading_long)))*100,1))+'%',horizontalalignment='right')\n",
    "ax1.text(12.5,0.95,str(np.round((np.sum(xunloading_long)/(np.sum(xunloading_short)+np.sum(xunloading_long)))*100,1))+'%',horizontalalignment='left')\n",
    "ax4.text(11.5,0.95,str(np.round((np.sum(xloading_short)/(np.sum(xloading_short)+np.sum(xloading_long)))*100,1))+'%',horizontalalignment='right')\n",
    "ax4.text(12.5,0.95,str(np.round((np.sum(xloading_long)/(np.sum(xloading_short)+np.sum(xloading_long)))*100,1))+'%',horizontalalignment='left')\n",
    "ax3.legend([legend1,legend2],['Short term','Long term'],bbox_to_anchor=[1.0,1.05],edgecolor='k', framealpha=1)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a6ffae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(output_path+'\\\\02_Figures'+'\\\\Figure_10_Discrepancies.pdf',format='pdf',dpi=500,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef987e13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
