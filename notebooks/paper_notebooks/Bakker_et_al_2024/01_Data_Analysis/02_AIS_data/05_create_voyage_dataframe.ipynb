{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02b351b5-2275-4c5d-baae-f3834ecb7e76",
   "metadata": {},
   "source": [
    "### Import packages and set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d54d4bf-f061-48f7-b5d0-18a66b476fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import dask.dataframe as dd\n",
    "import dask_gateway\n",
    "import dask.distributed\n",
    "\n",
    "import dotenv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27690c2-76e9-4b8d-81b2-d5865c56a501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import geopandas\n",
    "from shapely.geometry import Polygon, LineString, Point, MultiPolygon\n",
    "from shapely.ops import transform, cascaded_union\n",
    "from shapely import wkt\n",
    "import numpy as np\n",
    "import movingpandas as mpd\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import pyproj\n",
    "import scipy\n",
    "import pyarrow as pa\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9362886-740f-4ddc-93df-2a134710f71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sets the path to load pre-processed ais data\n",
    "folder_name = '2022_PoR'\n",
    "path_name = 'abfs://ais/parquet/' + folder_name  \n",
    "\n",
    "#sets the path to load other local data\n",
    "current_directory = os.getcwd()\n",
    "path = current_directory.split(\"\\\\01_Data_Analysis\\\\02_AIS_data\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cb1c85-7b35-437e-a7f1-daf4e2b0f59e",
   "metadata": {},
   "source": [
    "### Loads the access token (we use a SAS-token to protect the data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c586c559-0d9e-426a-9b1f-ea0452efa3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for environmental variables for secrets (needs python-dotenv)\n",
    "# You can copy the  .env.example file and rename it to .env (one directory  up from the notebooks)\n",
    "# \n",
    "%load_ext dotenv\n",
    "# Load environment variables from the .env file 1 directory up\n",
    "%dotenv -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c67c2a6-6f6b-445c-ab15-de023b508f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the environment variable from the  .env file\n",
    "sas_token = dotenv.dotenv_values()['AZURE_BLOB_SAS_TOKEN']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0c5647-a22e-44e3-976a-efabc41cf6d6",
   "metadata": {},
   "source": [
    "### Creation of the cluster with high worker memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbe013a-043d-4fe1-98be-8d0d022f063b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gateway = dask_gateway.Gateway()\n",
    "cluster_options = gateway.cluster_options()\n",
    "cluster = gateway.new_cluster(cluster_options)\n",
    "cluster.adapt(minimum=1, maximum=100)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f337b4e9-c634-435a-af85-8cd23ff09149",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = dask.distributed.Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431e5564-7977-4557-baf9-4e2ae377eb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_setup(dask_worker: dask.distributed.Worker):\n",
    "    import os\n",
    "    os.system(\"pip install -q movingpandas\")  # or pip\n",
    "    os.system(\"pip install -q more-itertools\")\n",
    "    os.system(\"pip install -q dask\")\n",
    "\n",
    "client.register_worker_callbacks(worker_setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8cf503-fc75-4064-9f4d-fb5f5ccc11be",
   "metadata": {},
   "source": [
    "### Geospatial and vessel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f04167f-1149-4ae4-8dfe-12a9868c6b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "utm = pyproj.CRS('EPSG:28992')\n",
    "wgs84 = pyproj.CRS('EPSG:4326')\n",
    "wgs_to_utm = pyproj.Transformer.from_crs(wgs84,utm,always_xy=True).transform\n",
    "utm_to_wgs = pyproj.Transformer.from_crs(utm,wgs84,always_xy=True).transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe2b504-1b8b-435d-ac6a-dd9c0d2241c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchorage_areas = gpd.read_file(path+\"\\\\00_Input_data\\\\01_Geospatial_data\\\\anchorage_areas.geojson\")\n",
    "anchorage_areas['geometry'] = [Polygon(geom) for geom in anchorage_areas['geometry']] \n",
    "turning_basins = pickle.load(open(path+\"\\\\00_Input_data\\\\01_Geospatial_data\\\\turning_basins_PoR.pickle\",'rb'))\n",
    "\n",
    "areas_of_interest = {}\n",
    "areas_of_interest['port_entrance'] = gpd.read_file(path+\"\\\\00_Input_data\\\\01_Geospatial_data\\\\Port_Entrance.geojson\")['geometry'][0]\n",
    "areas_of_interest['berths'] = transform(utm_to_wgs,MultiPolygon(pickle.load(open(path+\"\\\\00_Input_data\\\\01_Geospatial_data\\\\berths_PoR.pickle\",'rb'))['geometry'].to_list()))\n",
    "areas_of_interest['anchorage_areas'] = cascaded_union(anchorage_areas['geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58755b48-9b52-477a-bc3d-125eaaf169ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "harbour_basins = pickle.load(path+\"\\\\00_Input_data\\\\01_Geospatial_data\\\\harbour_basins_PoR.pickle\",'rb'))\n",
    "berths = pickle.load(open(path+\"\\\\00_Input_data\\\\01_Geospatial_data\\\\selected_berths_PoR.pickle\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cd8177-1f13-43cb-a437-226112f9a2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "berths.Harbour_basin = ['Waalhaven' if str(name).find('Waalhaven')+1 else name for name in berths.Harbour_basin]\n",
    "berths.loc[berths[berths.Harbour_basin == 'IJselhaven'].index,'Harbour_basin'] = 'IJsselhaven'\n",
    "berths.loc[berths[berths.Harbour_basin == 'Scheur'].index,'Harbour_basin'] = 'Scheurkade'\n",
    "berths.loc[berths[berths.index == 'NIEUWE MAAS HBR HOLLAND AMERIKAKADE'].index,'Harbour_basin'] = 'Holland Amerika Kade'\n",
    "berths.loc[berths[(berths.Terminal == 'VOPAK')&(berths.Harbour_basin == 'Nieuwe Maas')].index,'Harbour_basin'] = 'VOPAK'\n",
    "berths.loc[berths[(berths.Terminal == 'NESTE')&(berths.Harbour_basin == 'Nieuwe Maas')].index,'Harbour_basin'] = 'Neste'\n",
    "berths.loc[berths[(berths.Terminal == 'KTM')&(berths.Harbour_basin == 'Nieuwe maas')].index,'Harbour_basin'] = 'Koole Kade'\n",
    "berths.loc[berths[berths.Harbour_basin == '3e Petroleumhaven'].index,'Harbour_basin'] = 'Botlek'\n",
    "berths.loc[berths[berths.Harbour_basin == 'Torontohaven'].index,'Harbour_basin'] = 'Botlek'\n",
    "berths.loc[berths[berths.Harbour_basin == 'Chemiehaven'].index,'Harbour_basin'] = 'Botlek'\n",
    "berths.loc[berths[berths.Harbour_basin == '1e Werkhaven'].index,'Harbour_basin'] = 'Botlek'\n",
    "berths.loc[berths[berths.Harbour_basin == '2e Werkhaven'].index,'Harbour_basin'] = 'Botlek'\n",
    "berths.loc[berths[berths.Harbour_basin == 'Sint -Laurenshaven'].index,'Harbour_basin'] = 'Botlek'\n",
    "berths.loc[berths[berths.Harbour_basin == 'Prins Willem-Alexanderhaven'].index,'Harbour_basin'] = 'Eemhaven'\n",
    "berths.loc[berths[berths.Harbour_basin == 'Prins Johan Frisohaven'].index,'Harbour_basin'] = 'Eemhaven'\n",
    "berths.loc[berths[berths.Harbour_basin == 'Prinses Beatrixhaven'].index,'Harbour_basin'] = 'Eemhaven'\n",
    "berths = berths[berths.Harbour_basin != 'Koggehaven']\n",
    "berths = berths[berths.index != 'OUDE MAAS HBR KADE']\n",
    "berths = berths[berths.Harbour_basin != 'Zevenmanshaven']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e1d429-c620-4d90-bb82-bde8d9142ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "harbour_basins.Geometry = harbour_basins.Geometry.apply(lambda x: transform(utm_to_wgs,x))\n",
    "berths.geometry = berths.geometry.apply(lambda x: transform(utm_to_wgs,x))\n",
    "turning_basins.geometry = turning_basins.geometry.apply(lambda x: transform(utm_to_wgs,x))\n",
    "harbour_basins = harbour_basins.rename(columns={'Geometry':'geometry'})\n",
    "turning_basins.index = turning_basins.index.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476f50a7-8a39-4429-8aa2-1e0b98254bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc,basin_info in harbour_basins.iterrows():\n",
    "    if isinstance(basin_info.geometry,MultiPolygon):\n",
    "        harbour_basins.loc[loc,'geometry'] = basin_info.geometry.convex_hull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dd144a-9db9-49f3-96cc-2f5c41c781af",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path+\"\\\\03_Simulation\\\\01_Input_data\\\\01_Geospatial_data\\\\network\\\\PoR_graph_with_information.pickle\", 'rb') as f:\n",
    "    FG = pickle.load(f)\n",
    "origin_name = '8866969'\n",
    "origin_node = FG.nodes[origin_name]['geometry']\n",
    "origin_edge = FG.edges[origin_name,'8866305',0]['geometry']\n",
    "origin_edge = transform(wgs_to_utm,origin_edge)\n",
    "\n",
    "cd_length = 1000\n",
    "left = origin_edge.parallel_offset(cd_length / 2, 'left')\n",
    "right = origin_edge.parallel_offset(cd_length / 2, 'right')\n",
    "perp_left = left.boundary.geoms[1]\n",
    "perp_right = right.boundary.geoms[1]\n",
    "port_entrance_transect = transform(utm_to_wgs,LineString([perp_left, perp_right]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63a2357-0fc1-46bf-b5dc-7a81a8c7ad8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = dd.read_parquet(path_name+'/ship_dataframe',storage_options={\"account_name\": \"rwsais\", \"sas_token\": sas_token})\n",
    "ship_dataframe = ddf.compute()\n",
    "ship_dataframe.loc['testschip-30642','length'] = ship_dataframe.loc['testschip-30642','length']/10\n",
    "ship_dataframe.loc['testschip-8325','length'] = ship_dataframe.loc['testschip-8325','length']/10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45cccab-c6f8-4bf6-b202-88ddf0b65ce9",
   "metadata": {},
   "source": [
    "### Create voyage dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7b2c48-5c41-4018-a8e9-500988abf326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_string_geometry_to_shapely_geometry(df,geometry_columns):\n",
    "    \"\"\" \n",
    "    Function that converts string geometry data to shapely geometries\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pandas dataframe with trips\n",
    "    geometry_columns: columns with geometry types as string data\n",
    "\n",
    "    :returns: pandas dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    if df.empty or df['origin'].iloc[0] == 'a':\n",
    "        return df\n",
    "    for column in geometry_columns:\n",
    "        df[column] = df[column].apply(wkt.loads)\n",
    "    return df\n",
    "\n",
    "def add_bounds(df):\n",
    "    \"\"\" \n",
    "    Determines if the trip is inbound (to anchorage or to terminal) and outbound\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pandas dataframe with trips\n",
    "\n",
    "    :returns: pandas dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    df['bound'] = np.NaN \n",
    "    new_df = pd.DataFrame(columns=df.columns)\n",
    "    for ship_name in list(dict.fromkeys(df.name)):\n",
    "        ship_df = df[df.name == ship_name]\n",
    "        for trip_index in list(dict.fromkeys(ship_df.trip_id)):\n",
    "            trip_df = ship_df[ship_df.trip_id == trip_index]\n",
    "            trip_df.iloc[0,trip_df.columns.get_loc('bound')] = 'to_terminal'\n",
    "            if len(trip_df) > 2:\n",
    "                trip_df.iloc[0,trip_df.columns.get_loc('bound')] = 'to_anchorage'\n",
    "                trip_df.iloc[1,trip_df.columns.get_loc('bound')] = 'to_terminal' \n",
    "            trip_df.iloc[-1,trip_df.columns.get_loc('bound')] = 'from_terminal'\n",
    "            if len(trip_df) == 1:\n",
    "                berth_at_origin = trip_df.origin.iloc[0] in list(berths.index)\n",
    "                berth_at_departure = trip_df.destination.iloc[0] in list(berths.index)\n",
    "                if berth_at_origin:\n",
    "                    trip_df.iloc[0,trip_df.columns.get_loc('bound')] = 'from_terminal'\n",
    "                elif berth_at_departure:\n",
    "                    trip_df.iloc[0,trip_df.columns.get_loc('bound')] = 'to_terminal'\n",
    "            \n",
    "            new_df = pd.concat([new_df,trip_df])\n",
    "    return new_df\n",
    "\n",
    "def determine_location_of_turning(inbound_df,outbound_df):\n",
    "    \"\"\" \n",
    "    Function that determines over which trip (inbound/outbound), which turning basin, and for what duration \n",
    "    a vessel is turning\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    inbound_df: pandas dataframe with the inbound trip\n",
    "    outbound_df: pandas dataframe with the outbound trip\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    turning_basin_at_arrival: if applicable, the turning basin name that was used during arrival \n",
    "    turning_basin_at_departure: if applicable, the turning basin name that was used during departure\n",
    "    arrival_at_turning_basin: the time at which the vessel started turning\n",
    "    departure_from_turning_basin: the time at which the vessel stopped turning\n",
    "    sailing_distance_to_turning_basin: the distance to the turning basin from the origin of the vessel trip\n",
    "    sailing_distance_from_turning_basin: the distance from the turning basin to the destination of the vessel trip\n",
    "    \"\"\"\n",
    "    \n",
    "    import more_itertools as mit\n",
    "    turning_basin_at_arrival = ''\n",
    "    turning_basin_at_departure = ''\n",
    "    arrival_at_turning_basin = pd.Timestamp('NaT')\n",
    "    departure_from_turning_basin = pd.Timestamp('NaT')\n",
    "    sailing_distance_to_turning_basin = np.NaN\n",
    "    sailing_distance_from_turning_basin = np.NaN\n",
    "    turning_times_in_turning_basin = {'to_terminal':{},'from_terminal':{}}\n",
    "    time_bounds_in_turning_basin = {'to_terminal':{},'from_terminal':{}}\n",
    "\n",
    "    for index,(bound,df) in enumerate(zip(['to_terminal','from_terminal'],[inbound_df,outbound_df])):\n",
    "        if len(df):\n",
    "            passed_turning_basins = turning_basins[[df.geometry.iloc[0].intersects(basin_info.geometry) for _,basin_info in turning_basins.iterrows()]]\n",
    "            for name,basin_info in passed_turning_basins.iterrows():\n",
    "                coordinates = df.coordinates.iloc[0]\n",
    "                times = df.times.iloc[0]\n",
    "                mask = np.array([Point(coord).intersects(basin_info.geometry) for coord in df.geometry.iloc[0].coords], dtype=bool)\n",
    "                indices = [i for i, x in enumerate(mask) if x == True]\n",
    "                if indices:\n",
    "                    new_mask = [list(group) for group in mit.consecutive_groups(indices)]\n",
    "                    new_mask = new_mask[np.argmax([len(series) for series in new_mask])]\n",
    "                    time = [x for i, x in enumerate(times) if i in new_mask]\n",
    "                    if time:\n",
    "                        turning_time = time[-1]-time[0]\n",
    "                        turning_times_in_turning_basin[bound][name] = turning_time.item().total_seconds()\n",
    "                        time_bounds_in_turning_basin[bound][name] = [time[-1],time[0]]\n",
    "\n",
    "    if turning_times_in_turning_basin['to_terminal'].values() or turning_times_in_turning_basin['from_terminal'].values():\n",
    "        maxima = [max(turning_times_in_turning_basin[bound].values()) if turning_times_in_turning_basin[bound].values() else -1 for bound in turning_times_in_turning_basin.keys()]\n",
    "        turning_bound = list(time_bounds_in_turning_basin.keys())[np.argmax(maxima)]\n",
    "        turning_basin = max(turning_times_in_turning_basin[turning_bound], key=turning_times_in_turning_basin[turning_bound].get)\n",
    "        turning_times = time_bounds_in_turning_basin[turning_bound][turning_basin]\n",
    "        arrival_at_turning_basin = turning_times[-1]\n",
    "        departure_from_turning_basin = turning_times[0]\n",
    "        if turning_bound == 'to_terminal':\n",
    "            geometry_arrival = inbound_df.geometry.iloc[0]\n",
    "            turning_basin_at_arrival = turning_basin\n",
    "            times = list(inbound_df.times.iloc[0])\n",
    "            track_to_turning_basin = [Point(coord) for coord in geometry_arrival.coords][0:times.index(turning_times[-1])]\n",
    "            sailing_distance_to_turning_basin = 0\n",
    "            if len(track_to_turning_basin) > 1:\n",
    "                track_to_turning_basin = LineString(track_to_turning_basin)\n",
    "                sailing_distance_to_turning_basin = transform(wgs_to_utm,track_to_turning_basin).length\n",
    "        elif turning_bound == 'from_terminal':\n",
    "            geometry_departure = outbound_df.geometry.iloc[0]\n",
    "            turning_basin_at_departure = turning_basin    \n",
    "            times = list(outbound_df.times.iloc[0])\n",
    "            track_from_turning_basin = [Point(coord) for coord in geometry_departure.coords][times.index(turning_times[-1]):]\n",
    "            sailing_distance_from_turning_basin = 0\n",
    "            if len(track_from_turning_basin) > 1:\n",
    "                track_from_turning_basin = LineString(track_from_turning_basin)\n",
    "                sailing_distance_from_turning_basin = transform(wgs_to_utm,geometry_departure).length - transform(wgs_to_utm,track_from_turning_basin).length\n",
    "\n",
    "    return turning_basin_at_arrival,turning_basin_at_departure,arrival_at_turning_basin,departure_from_turning_basin,sailing_distance_to_turning_basin,sailing_distance_from_turning_basin\n",
    "\n",
    "def find_time_and_location_of_crossing(df,area_geometry,mode):\n",
    "    \"\"\" \n",
    "    Function that finds the location and timing of a vessel crossing a linestring over its route\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pandas dataframe with trips\n",
    "    area_geometry: LineString geometry of the geometry of interest\n",
    "    mode: 'arrival' or 'departure' determining which trip should be considered (in- or outbound)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    arrival_departure_time: time of crossing as a pandas timestamp\n",
    "    arrival_departure_distance: distance to the crossing point from the origin of the trip\n",
    "    \"\"\"\n",
    "\n",
    "    arrival_departure_time = pd.Timestamp('NaT')\n",
    "    arrival_departure_distance = np.NaN\n",
    "    times = df.times.iloc[0]\n",
    "    trajectory_geometry = df.geometry.iloc[0]\n",
    "    trajectory_geometry = transform(wgs_to_utm,trajectory_geometry)\n",
    "    area_geometry = transform(wgs_to_utm,area_geometry)\n",
    "    distance = 0\n",
    "    for index,(start_point_segment,end_point_segment) in enumerate(zip(trajectory_geometry.coords[:-1],trajectory_geometry.coords[1:])):\n",
    "        line = LineString([start_point_segment,end_point_segment])\n",
    "        distance += line.length\n",
    "        if line.intersects(area_geometry):\n",
    "            arrival_departure_point = line.intersection(area_geometry)\n",
    "            offset_percentage = line.boundary.geoms[0].distance(arrival_departure_point)/(line.boundary.geoms[0].distance(arrival_departure_point)+line.boundary.geoms[1].distance(arrival_departure_point))\n",
    "            arrival_departure_time = (times[index+1]-times[index])*offset_percentage+times[index]\n",
    "            arrival_departure_distance = distance-line.length*(1-offset_percentage)\n",
    "            if mode == 'departure':\n",
    "                arrival_departure_distance = trajectory_geometry.length - arrival_departure_distance\n",
    "                break\n",
    "                \n",
    "    return arrival_departure_time,arrival_departure_distance\n",
    "\n",
    "def merge_data(df,variable_name):\n",
    "    \"\"\" \n",
    "    Function that merges the data of a dataframe into a single variable\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pandas dataframe with trips\n",
    "    variable_name: column name of data to be merged\n",
    "\n",
    "    returns: a list with the data of the column\n",
    "    \"\"\"\n",
    "    \n",
    "    variable = []\n",
    "    for row_index in range(len(df)):\n",
    "        variable.extend(df.iloc[row_index][variable_name])\n",
    "    return variable\n",
    "    \n",
    "def create_vessel_journeys(df,berths,turning_basins,harbour_basins,scheme_information):\n",
    "    \"\"\" \n",
    "    Function that creates a dataframe of vessel voyages consisting of an in- and outbound trip\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pandas dataframe with trips\n",
    "    berths: dataframe with geometries of the berhts, should contain the harbour basin nam\n",
    "    turning_basins: dataframe with geometries of the turning basins\n",
    "    harbour_basins: dataframe with geometries of the harbour basins\n",
    "    scheme_information: information in a dictionary with column names as names and pyarrow datatypes as values\n",
    "\n",
    "    returns: a list with the data of the column\n",
    "    \"\"\"\n",
    "    columns = scheme_information.keys()\n",
    "    df_trips = pd.DataFrame(columns=columns)\n",
    "    for datacolumn,datatype in scheme_information.items(): \n",
    "        df_trips[datacolumn] = df_trips[datacolumn].astype(datatype.to_pandas_dtype())\n",
    "    ship_name = ''\n",
    "    trip_number = np.NaN\n",
    "    for ship_name in list(dict.fromkeys(df.name)):\n",
    "        ship_df = df[df.name == ship_name]\n",
    "        ship_name = ship_name\n",
    "        for trip_number in list(dict.fromkeys(ship_df.trip_id)):\n",
    "            trip_df = ship_df[ship_df.trip_id == trip_number]\n",
    "            trip_number = trip_number\n",
    "            trip_anchorage = trip_df[trip_df.bound == 'to_anchorage']\n",
    "            trip_arrival = trip_df[trip_df.bound == 'to_terminal']\n",
    "            trip_departure = trip_df[trip_df.bound == 'from_terminal']\n",
    "\n",
    "            #Defaults\n",
    "            origin = Point()\n",
    "            anchorage_at_arrival = ''\n",
    "            turning_basin_at_arrival = ''\n",
    "            berth_of_call = ''\n",
    "            turning_basin_at_departure = ''\n",
    "            destination = Point()\n",
    "            draught_at_arrival = np.NaN\n",
    "            draught_at_departure = np.NaN\n",
    "            arrival_at_port = pd.Timestamp('NaT')\n",
    "            arrival_at_anchorage_at_arrival = pd.Timestamp('NaT')\n",
    "            departure_from_anchorage_at_arrival = pd.Timestamp('NaT')\n",
    "            arrival_at_port_entrance = pd.Timestamp('NaT')\n",
    "            arrival_at_harbour_entrance = pd.Timestamp('NaT')\n",
    "            arrival_at_turning_basin = pd.Timestamp('NaT')\n",
    "            arrival_at_berth = pd.Timestamp('NaT')\n",
    "            departure_from_berth = pd.Timestamp('NaT')\n",
    "            departure_from_turning_basin = pd.Timestamp('NaT')\n",
    "            departure_from_harbour_entrance = pd.Timestamp('NaT')\n",
    "            departure_from_port_entrance = pd.Timestamp('NaT')\n",
    "            departure_from_port = pd.Timestamp('NaT')\n",
    "            geometry_anchorage = LineString()\n",
    "            geometry_arrival = LineString()\n",
    "            geometry_departure = LineString()\n",
    "            sailing_distance_to_anchorage = np.NaN\n",
    "            sailing_distance_to_port_entrance = np.NaN\n",
    "            sailing_distance_to_harbour_entrance = np.NaN\n",
    "            sailing_distance_to_turning_basin = np.NaN\n",
    "            sailing_distance_to_berth = np.NaN\n",
    "            sailing_distance_from_berth = np.NaN\n",
    "            sailing_distance_from_turning_basin = np.NaN\n",
    "            sailing_distance_from_harbour_entrance = np.NaN\n",
    "            sailing_distance_from_port_entrance = np.NaN\n",
    "            times = []\n",
    "            coordinates = []\n",
    "            sog = []\n",
    "            cog = []\n",
    "            speed = []\n",
    "            direction = []\n",
    "            acceleration = []\n",
    "    \n",
    "            #Geometries\n",
    "            geometry_anchorage = np.NaN\n",
    "            geometry_arrival = np.NaN\n",
    "            geometry_departure = np.NaN\n",
    "            if len(trip_anchorage):\n",
    "                geometry_anchorage = trip_anchorage.geometry.iloc[0]\n",
    "            if len(trip_arrival):\n",
    "                geometry_arrival = trip_arrival.geometry.iloc[0]\n",
    "            if len(trip_departure):\n",
    "                geometry_departure = trip_departure.geometry.iloc[0]\n",
    "        \n",
    "            #Parameters\n",
    "            coordinates = merge_data(trip_df,'coordinates')\n",
    "            times = merge_data(trip_df,'times')\n",
    "            sog = merge_data(trip_df,'sog')\n",
    "            cog = merge_data(trip_df,'cog')\n",
    "            speed = merge_data(trip_df,'speed')\n",
    "            direction = merge_data(trip_df,'direction')\n",
    "            acceleration = merge_data(trip_df,'acceleration')\n",
    "        \n",
    "            #Origin\n",
    "            harbour_entrance_transect = LineString()\n",
    "            if len(trip_arrival):\n",
    "                if len(trip_anchorage):\n",
    "                    origin = trip_anchorage.origin.iloc[0]\n",
    "                    arrival_at_port = trip_anchorage.arrival.iloc[0]\n",
    "                else:\n",
    "                    origin = trip_arrival.origin.iloc[0]\n",
    "                    arrival_at_port = trip_arrival.arrival.iloc[0]\n",
    "                berth = trip_arrival.destination.iloc[0]\n",
    "                draught_at_arrival = trip_arrival.draught.iloc[0]\n",
    "                if berth in list(berths.index):\n",
    "                    if berths.loc[berth].Harbour_basin in list(harbour_basins.Name):\n",
    "                        harbour_entrance_transect = harbour_basins[harbour_basins.Name == berths.loc[berth].Harbour_basin].iloc[0].geometry.exterior\n",
    "            else:\n",
    "                origin = berth = trip_departure.origin.iloc[0]\n",
    "                arrival_at_port = trip_departure.departure.iloc[0]\n",
    "                draught_at_arrival = trip_departure.draught.iloc[0]\n",
    "                if berth in list(berths.index):\n",
    "                    if berths.loc[berth].Harbour_basin in list(harbour_basins.Name):\n",
    "                        harbour_entrance_transect = harbour_basins[harbour_basins.Name == berths.loc[berth].Harbour_basin].iloc[0].geometry.exterior\n",
    "            \n",
    "            #Anchorage at arrival\n",
    "            anchorage_at_arrival = np.NaN\n",
    "            arrival_at_anchorage_at_arrival = pd.Timestamp('NaT')\n",
    "            departure_from_anchorage_at_arrival = pd.Timestamp('NaT')\n",
    "            sailing_distance_to_anchorage = np.NaN\n",
    "            if len(trip_anchorage):\n",
    "                anchorage_at_arrival = trip_anchorage.destination.iloc[0]\n",
    "                arrival_at_anchorage_at_arrival = trip_anchorage.arrival.iloc[0]\n",
    "                departure_from_anchorage_at_arrival = trip_arrival.departure.iloc[0]\n",
    "                sailing_distance_to_anchorage = trip_anchorage.distance.iloc[0]\n",
    "        \n",
    "            #Entry\n",
    "            arrival_at_port_entrance = pd.Timestamp('NaT')\n",
    "            sailing_distance_to_port_entrance = np.NaN\n",
    "            if len(trip_arrival):\n",
    "                arrival_at_port_entrance,sailing_distance_to_port_entrance = find_time_and_location_of_crossing(trip_arrival,port_entrance_transect,'arrival')\n",
    "                arrival_at_harbour_entrance,sailing_distance_to_harbour_entrance = find_time_and_location_of_crossing(trip_arrival,harbour_entrance_transect,'arrival')\n",
    "        \n",
    "            #Turning Basin\n",
    "            turning_basin_at_arrival,turning_basin_at_departure,arrival_at_turning_basin,departure_from_turning_basin,sailing_distance_to_turning_basin,sailing_distance_from_turning_basin = determine_location_of_turning(trip_arrival,trip_departure) \n",
    "        \n",
    "            #Berth inbound\n",
    "            berth_of_call = np.NaN\n",
    "            arrival_at_berth = pd.Timestamp('NaT')\n",
    "            sailing_distance_to_berth = np.NaN\n",
    "            if len(trip_arrival):\n",
    "                berth_of_call = trip_arrival.destination.iloc[0]\n",
    "                arrival_at_berth = trip_arrival.arrival.iloc[0]\n",
    "                sailing_distance_to_berth = transform(wgs_to_utm,geometry_arrival).length\n",
    "            \n",
    "            #Berth outbound\n",
    "            departure_from_berth = pd.Timestamp('NaT')\n",
    "            sailing_distance_from_berth = np.NaN\n",
    "            if len(trip_departure):\n",
    "                berth_of_call = trip_departure.origin.iloc[0]\n",
    "                departure_from_berth = trip_departure.departure.iloc[0]\n",
    "                sailing_distance_from_berth = transform(wgs_to_utm,geometry_departure).length\n",
    "        \n",
    "            #Departure\n",
    "            departure_from_port_entrance = pd.Timestamp('NaT')\n",
    "            sailing_distance_from_port_entrance = np.NaN\n",
    "            if len(trip_departure):\n",
    "                departure_from_port_entrance,sailing_distance_from_port_entrance = find_time_and_location_of_crossing(trip_departure,port_entrance_transect,'departure')\n",
    "                departure_from_harbour_entrance,sailing_distance_from_harbour_entrance = find_time_and_location_of_crossing(trip_departure,harbour_entrance_transect,'departure')\n",
    "            \n",
    "            #Destination  \n",
    "            if len(trip_departure):\n",
    "                destination = trip_departure.destination.iloc[0]\n",
    "                draught_at_departure = trip_departure.draught.iloc[0]\n",
    "                departure_from_port = trip_departure.arrival.iloc[0]\n",
    "            else:\n",
    "                destination = trip_arrival.destination.iloc[0]\n",
    "                draught_at_departure = trip_arrival.draught.iloc[0]\n",
    "                departure_from_port = trip_arrival.arrival.iloc[0]\n",
    "\n",
    "            data = [trip_number,\n",
    "                    ship_name,\n",
    "                    origin,\n",
    "                    anchorage_at_arrival,\n",
    "                    turning_basin_at_arrival,\n",
    "                    berth_of_call,\n",
    "                    turning_basin_at_departure,\n",
    "                    destination,\n",
    "                    draught_at_arrival,\n",
    "                    draught_at_departure,\n",
    "                    arrival_at_port,\n",
    "                    arrival_at_anchorage_at_arrival,\n",
    "                    departure_from_anchorage_at_arrival,\n",
    "                    arrival_at_port_entrance,\n",
    "                    arrival_at_harbour_entrance,\n",
    "                    arrival_at_turning_basin,\n",
    "                    arrival_at_berth,\n",
    "                    departure_from_berth,\n",
    "                    departure_from_turning_basin,\n",
    "                    departure_from_harbour_entrance,\n",
    "                    departure_from_port_entrance,\n",
    "                    departure_from_port,\n",
    "                    geometry_anchorage,\n",
    "                    geometry_arrival,\n",
    "                    geometry_departure,\n",
    "                    sailing_distance_to_anchorage,\n",
    "                    sailing_distance_to_port_entrance,\n",
    "                    sailing_distance_to_harbour_entrance,\n",
    "                    sailing_distance_to_turning_basin,\n",
    "                    sailing_distance_to_berth,\n",
    "                    sailing_distance_from_berth,\n",
    "                    sailing_distance_from_turning_basin,\n",
    "                    sailing_distance_from_harbour_entrance,\n",
    "                    sailing_distance_from_port_entrance,\n",
    "                    times,\n",
    "                    coordinates,\n",
    "                    sog,\n",
    "                    cog,\n",
    "                    speed,\n",
    "                    direction,\n",
    "                    acceleration]    \n",
    "            df_trips = pd.concat([df_trips,pd.DataFrame(data=[data],columns=columns)])\n",
    "    return df_trips\n",
    "\n",
    "def change_data_format(df,data_columns,scheme_information):\n",
    "    \"\"\" \n",
    "    Function that transforms the geometry data into string data in order to save it in dask\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pandas dataframe with geometries\n",
    "    data_columns: column names of geometries\n",
    "\n",
    "    :returns: pandas dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    new_df = pd.DataFrame(columns=scheme_information.keys())\n",
    "    for datacolumn,datatype in scheme_information.items(): \n",
    "        new_df[datacolumn] = new_df[datacolumn].astype(datatype.to_pandas_dtype())\n",
    "    for loc,info in df.iterrows():\n",
    "        row_df = pd.DataFrame([info])\n",
    "        for data_column in data_columns:\n",
    "            if type(info[data_column]) == list or type(info[data_column]) == tuple:\n",
    "                for index,data in enumerate(info[data_column]):\n",
    "                    if not index:\n",
    "                        row_df.loc[loc,data_column] = [str(data)]\n",
    "                    else:\n",
    "                        row_df.loc[loc,data_column].append(str(data))\n",
    "            else:\n",
    "                row_df.loc[loc,data_column] = str(info[data_column])\n",
    "        new_df = pd.concat([new_df,row_df])\n",
    "    return new_df\n",
    "\n",
    "def reset_index(df):\n",
    "    \"\"\" \n",
    "    Function that resets the index of a pandas dataframe \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pandas dataframe\n",
    "\n",
    "    :returns: pandas dataframe\n",
    "    \"\"\"\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def set_time_UTC(df,time_columns):\n",
    "    \"\"\" \n",
    "    Function that converts the datetimes into datetime with a time zone in utc\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pandas dataframe\n",
    "    time_columns: columns that contain datetime elements\n",
    "\n",
    "    :returns: pandas dataframe\n",
    "    \"\"\"\n",
    "    df_new = pd.DataFrame(columns=time_columns)\n",
    "    for time_column in time_columns:\n",
    "        df_new[time_column] = pd.to_datetime([None]*len(df[time_column]), utc=True)\n",
    "        for loc,time_info in df[[time_column]].iterrows():\n",
    "            time = time_info[time_column]\n",
    "            if isinstance(time,pd.Timestamp):\n",
    "                if not time.tz:\n",
    "                    df_new.loc[loc,time_column] = time.tz_localize(datetime.timezone.utc)\n",
    "                else:\n",
    "                    df_new.loc[loc,time_column] = time\n",
    "\n",
    "        df[time_column] = df_new[time_column]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547edf78-c618-4c00-9d5e-1e2aff31e316",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheme_information = {'trip_number': pa.int64(),\n",
    "                      'name': pa.string(),\n",
    "                      'origin': pa.string(),\n",
    "                      'anchorage_at_arrival':pa.string(),\n",
    "                      'turning_basin_at_arrival':pa.string(),\n",
    "                      'berth_of_call': pa.string(),\n",
    "                      'turning_basin_at_departure': pa.string(), \n",
    "                      'destination': pa.string(),\n",
    "                      'draught_at_arrival': pa.float64(),\n",
    "                      'draught_at_departure': pa.float64(),\n",
    "                      'arrival_at_port': pa.timestamp('ns', tz='UTC'),\n",
    "                      'arrival_at_anchorage_at_arrival': pa.timestamp('ns', tz='UTC'),\n",
    "                      'departure_from_anchorage_at_arrival': pa.timestamp('ns', tz='UTC'),\n",
    "                      'arrival_at_port_entrance': pa.timestamp('ns', tz='UTC'),\n",
    "                      'arrival_at_harbour_entrance': pa.timestamp('ns', tz='UTC'),\n",
    "                      'arrival_at_turning_basin': pa.timestamp('ns', tz='UTC'),\n",
    "                      'arrival_at_berth': pa.timestamp('ns', tz='UTC'),\n",
    "                      'departure_from_berth': pa.timestamp('ns', tz='UTC'),\n",
    "                      'departure_from_turning_basin': pa.timestamp('ns', tz='UTC'),\n",
    "                      'departure_from_harbour_entrance': pa.timestamp('ns', tz='UTC'),\n",
    "                      'departure_from_port_entrance': pa.timestamp('ns', tz='UTC'),\n",
    "                      'departure_from_port': pa.timestamp('ns', tz='UTC'),\n",
    "                      'geometry_anchorage': pa.string(),\n",
    "                      'geometry_entry': pa.string(),\n",
    "                      'geometry_departure': pa.string(),\n",
    "                      'sailing_distance_to_anchorage': pa.float64(),\n",
    "                      'sailing_distance_to_port_entrance': pa.float64(),\n",
    "                      'sailing_distance_to_harbour_entrance': pa.float64(),\n",
    "                      'sailing_distance_to_turning_basin': pa.float64(),\n",
    "                      'sailing_distance_to_berth': pa.float64(),\n",
    "                      'sailing_distance_from_berth': pa.float64(),\n",
    "                      'sailing_distance_from_turning_basin': pa.float64(),\n",
    "                      'sailing_distance_from_harbour_entrance': pa.float64(),\n",
    "                      'sailing_distance_from_port_entrance': pa.float64(),\n",
    "                      'times': pa.list_(pa.timestamp('us')),\n",
    "                      'coordinates': pa.list_(pa.string()),\n",
    "                      'sog': pa.list_(pa.float64()),\n",
    "                      'cog': pa.list_(pa.float64()),\n",
    "                      'speed': pa.list_(pa.float64()),\n",
    "                      'direction': pa.list_(pa.float64()),\n",
    "                      'acceleration': pa.list_(pa.float64())}\n",
    "\n",
    "time_columns = ['arrival_at_port',\n",
    "                'arrival_at_anchorage_at_arrival',\n",
    "                'departure_from_anchorage_at_arrival',\n",
    "                'arrival_at_port_entrance',\n",
    "                'arrival_at_harbour_entrance',\n",
    "                'arrival_at_turning_basin',\n",
    "                'arrival_at_berth',\n",
    "                'departure_from_berth',\n",
    "                'departure_from_turning_basin',\n",
    "                'departure_from_harbour_entrance',\n",
    "                'departure_from_port_entrance',\n",
    "                'departure_from_port']\n",
    "\n",
    "voyage_df = pd.DataFrame(columns=list(scheme_information.keys()))\n",
    "for datacolumn,datatype in scheme_information.items(): \n",
    "    voyage_df[datacolumn] = voyage_df[datacolumn].astype(datatype.to_pandas_dtype())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55f2ae7-4ad7-4707-b2dc-b97ef04872a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = dd.read_parquet(path_name+'/trip_dataframe',storage_options={\"account_name\": \"rwsais\", \"sas_token\": sas_token})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75db1414-944f-4bbc-9e73-e62601e5bcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_i = ddf.partitions[:]\n",
    "ddf_i = ddf_i.map_partitions(convert_string_geometry_to_shapely_geometry,['coordinates','geometry'])\n",
    "ddf_i = ddf_i.map_partitions(add_bounds)\n",
    "ddf_i = ddf_i.map_partitions(create_vessel_journeys,berths,turning_basins,harbour_basins,scheme_information=scheme_information,meta=voyage_df)\n",
    "ddf_i = ddf_i.map_partitions(change_data_format,data_columns=['origin',\n",
    "                                                              'destination',\n",
    "                                                              'geometry_anchorage', \n",
    "                                                              'geometry_entry', \n",
    "                                                              'geometry_departure',\n",
    "                                                              'coordinates'],scheme_information=scheme_information,meta=voyage_df)\n",
    "ddf_i = ddf_i.map_partitions(reset_index,meta=voyage_df)\n",
    "ddf_i = ddf_i.map_partitions(set_time_UTC,time_columns=time_columns,meta=voyage_df)\n",
    "\n",
    "for datacolumn,datatype in scheme_information.items(): \n",
    "   ddf_i[datacolumn] = ddf_i[datacolumn].astype(datatype.to_pandas_dtype())\n",
    "    \n",
    "ddf_i.to_parquet(path_name+'/voyage_dataframe',storage_options={\"account_name\": \"rwsais\", \"sas_token\": sas_token},schema=scheme_information,engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed038a18-7c3d-4760-b19f-bce49d9fd9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b0fb0b-f296-4da3-b206-72ff7a6df782",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
