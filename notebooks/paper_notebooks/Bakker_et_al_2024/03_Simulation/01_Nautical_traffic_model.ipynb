{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f03a0c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Installed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffb7ed0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import bisect\n",
    "import datetime\n",
    "import folium\n",
    "import functools\n",
    "import geopandas as gpd\n",
    "import io\n",
    "import logging\n",
    "import math\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot as plt, dates\n",
    "import networkx as nx  \n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pyproj\n",
    "import requests\n",
    "import scipy as sc\n",
    "import shapely.geometry\n",
    "from shapely.geometry import Point,Polygon,MultiPolygon\n",
    "from shapely.ops import transform\n",
    "import shapely.wkt\n",
    "import time as timpie\n",
    "import xarray as xr\n",
    "import scipy as sc\n",
    "import yaml\n",
    "import pytz\n",
    "\n",
    "#Import packages OpenTNSim\n",
    "from opentnsim import core\n",
    "from opentnsim import plot\n",
    "from opentnsim import model\n",
    "from opentnsim import import_hydrodynamic_dataset\n",
    "from opentnsim import vessel_traffic_service\n",
    "from opentnsim import port\n",
    "from opentnsim import lock\n",
    "from opentnsim import vessel as vessel_\n",
    "from opentnsim import waterway\n",
    "from opentnsim import output\n",
    "from opentnsim import tidal_window_constructor\n",
    "from opentnsim import rule_constructor\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "geod = pyproj.Geod(ellps=\"WGS84\")\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86c977c",
   "metadata": {},
   "source": [
    "## Set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46d50de",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "path = path.split('\\\\03_Simulation')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ef59c7",
   "metadata": {},
   "source": [
    "## Set default colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104cf35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_lijnA = (0/255,152/255,51/255)\n",
    "color_lijnB = (253/255,223/255,1/255)\n",
    "color_lijnC = (231/255,33/255,24/255)\n",
    "color_lijnD = (52/255,180/255,229/255)\n",
    "color_lijnE = (2/255,58/255,141/255)\n",
    "color_lijnF = (212/255,103/255,160/255)\n",
    "colors = [color_lijnA,color_lijnB,color_lijnC,color_lijnD,color_lijnE,color_lijnF]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216e7846",
   "metadata": {},
   "source": [
    "## Some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54082058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_additional_waiting_time(origin_destination_matrix, trip_id1,trip_id2):\n",
    "    \"\"\" \n",
    "    Function that calculates the waiting time if another vessel was observed to be having priority\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    origin_destination_matrix: origin-destination matrix of the vessels as pandas dataframe\n",
    "    trip_id1: trip ID as string of vessel that was observed to have additional waiting time\n",
    "    trip_id2: trip ID as string of vessel that was observed to be having priority over the other vessel\n",
    "\n",
    "    :returns: dictionary with vessel name as name and delay as value\n",
    "    \"\"\"\n",
    "    \n",
    "    arrival_time1 = origin_destination_matrix[origin_destination_matrix.trip_id == trip_id1].iloc[0].arrival\n",
    "    arrival_time2 = origin_destination_matrix[origin_destination_matrix.trip_id == trip_id2].iloc[0].arrival\n",
    "    delay = arrival_time2 - arrival_time1\n",
    "    return {trip_id1:delay}\n",
    "\n",
    "def create_vessel(Vessel,env,name,origin,destination,next_destination,beam,length,draught,delta_draught,berthing_time,unloading_time,turning_time,arrival_time,terminal_of_call,berth_of_call,additional_waiting_time,bound='inbound',height=0.,ukc=0.,max_cross_current=0.):\n",
    "    \"\"\" \n",
    "    Function that creates a vessel agent in the nautical traffic model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Vessel: type object element that includes the mixin objects that symbolize a vessel agent\n",
    "    env: simpy environment\n",
    "    name: name of the vessel as a string\n",
    "    origin: origin node of the network as a string\n",
    "    destination: destination node of the network as a string\n",
    "    next_destination: list of next destination nodes of the network as a string\n",
    "    beam: beam of the vessel in meters as a float\n",
    "    length: length of the vessel in meters as a float\n",
    "    draught: draught of the vessel in meters as a float\n",
    "    delta_draught: list of draught changes of the vessel in meters as a float in sequence of terminal visits\n",
    "    berthing_time: berthing time of the vessel as pandas timestamp\n",
    "    unloading_time: list of unloading times of the vessel as pandas timestamps in sequence of terminal visits\n",
    "    turning_time: list of turning times of the vessel as pandas timestamps in sequence of harbour basin visits\n",
    "    arrival_time: rrival time of vessel as pandas timestamp\n",
    "    terminal_of_call: list of terminal names as string in sequence of terminal visits\n",
    "    berth_of_call: list of berth names as string in sequence of terminal visits\n",
    "    additional_waiting_time: additional waiting time as pandas timedelta\n",
    "    bound: 'inbound' or 'outbound'\n",
    "    height: height of the vessel in meters as a float\n",
    "    ukc: extra required under keel clearance of the vessel in meters as a float\n",
    "    max_cross_current: additional maximum allowable cross-current velocity of the vessel in meters per second as a float\n",
    "\n",
    "    :returns: vessel agent\n",
    "    \"\"\"\n",
    "    \n",
    "    vessel_input = { \"name\":name,\n",
    "                     \"origin\":origin,\n",
    "                     \"destination\":destination,\n",
    "                     \"next_destination\":next_destination,\n",
    "                     \"env\":env,\n",
    "                     \"type\":'Tanker',\n",
    "                     \"B\":beam,\n",
    "                     \"L\":length,\n",
    "                     \"T\": draught,\n",
    "                     \"H\":height,\n",
    "                     \"t_berthing\":berthing_time.total_seconds(),\n",
    "                     \"t_(un)loading\":[time.total_seconds() for time in unloading_time],\n",
    "                     \"t_turning\":[time.total_seconds() for time in turning_time],\n",
    "                     \"ukc\":ukc,\n",
    "                     \"v\":np.NaN,\n",
    "                     \"terminal_of_call\": terminal_of_call,\n",
    "                     \"berth_of_call\": berth_of_call,\n",
    "                     \"(un)loading\": delta_draught,\n",
    "                     \"max_waiting_time\":datetime.timedelta(days=10).total_seconds(),\n",
    "                     \"max_cross_current\":max_cross_current,\n",
    "                     \"arrival_time\":arrival_time,\n",
    "                     \"arrival_delay\":arrival_time,\n",
    "                     \"priority\": 0,\n",
    "                     \"additional_waiting_time\": additional_waiting_time/np.timedelta64(1, 's'),\n",
    "                     \"bound\":bound,\n",
    "                     \"priority\":False}\n",
    "    \n",
    "    created_vessel = Vessel(**vessel_input)\n",
    "    return created_vessel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a3f534",
   "metadata": {},
   "source": [
    "## Simulation settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607521f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_start = datetime.datetime(2019,1,1,0,0,0).replace(tzinfo=pytz.utc)\n",
    "simulation_stop = datetime.datetime(2020,1,1,0,0,0).replace(tzinfo=pytz.utc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da63526e",
   "metadata": {},
   "source": [
    "## Import graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217fd79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path+\"\\\\03_Simulation\\\\01_Input_data\\\\01_Geospatial_data\\\\network\"+\"\\\\PortNetwork.pickle\", 'rb') as f:\n",
    "    FG = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83c87c6",
   "metadata": {},
   "source": [
    "## Open hydrodynamic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4714d229",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open analyzed and structured hydrodynamic data\n",
    "hydrodynamic_data = xr.open_dataset(path+\"\\\\03_Simulation\\\\01_Input_data\\\\02_Hydrodynamic_data\\\\+'hydrodynamic_data_PoR_stations.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7743a1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overwrite MBLs (Change MBLs here)\n",
    "node_list = hydrodynamic_data['STATION'].values\n",
    "hydrodynamic_data['MBL'] = xr.DataArray(23*np.ones(len(node_list)),coords={'STATION':node_list})\n",
    "for index,node in enumerate(node_list):\n",
    "    if node in ['8866305','8864266','8862925','8864465','S14716_B','S14716_A','8860845']:\n",
    "        hydrodynamic_data['MBL'][index] = 16.2\n",
    "    elif node in ['8867547','8867980','8866999']:\n",
    "        hydrodynamic_data['MBL'][index] = 15.9\n",
    "    elif node in ['8866859']:\n",
    "        hydrodynamic_data['MBL'][index] = 15.9\n",
    "    elif node in ['anchorage','8866969']:\n",
    "        hydrodynamic_data['MBL'][index] = 23.8\n",
    "    else:\n",
    "        hydrodynamic_data['MBL'][index] = 16.4\n",
    "        \n",
    "#Possibility to change bed level over time\n",
    "new_MBLs = np.empty((len(hydrodynamic_data['STATION']),len(hydrodynamic_data['TIME'])))\n",
    "for station,MBL in enumerate(hydrodynamic_data['MBL'].values):\n",
    "    for time,_ in enumerate(hydrodynamic_data['TIME'].values):\n",
    "        new_MBLs[station][time] = MBL\n",
    "        \n",
    "new_MBLs = xr.DataArray(new_MBLs,dims=['STATION','TIME'],coords=dict(STATION=hydrodynamic_data['STATION'],\n",
    "                                                                     TIME=hydrodynamic_data['TIME']))\n",
    "\n",
    "hydrodynamic_data['MBL'] = new_MBLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a39a0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read tidal period data\n",
    "for tide_type,dim_name in zip(['Vertical tidal periods','Horizontal tidal periods'],['VERTICALTIDES','HORIZONTALTIDES']):\n",
    "    data = np.empty(hydrodynamic_data[tide_type].values.shape[:2], dtype=[('a','datetime64[ns]'),('b',object)])\n",
    "    tide_info = hydrodynamic_data[tide_type].values\n",
    "    for station_index,_ in enumerate(hydrodynamic_data.STATION.values):\n",
    "        for tide_index in hydrodynamic_data[dim_name].values:\n",
    "            time = tide_info[station_index][tide_index][0]\n",
    "            tide = tide_info[station_index][tide_index][1]\n",
    "            if time == 'nan':\n",
    "                new_time = 'NaT'\n",
    "            else:\n",
    "                new_time = time\n",
    "            data[station_index][tide_index] = (np.datetime64(new_time),tide)\n",
    "    \n",
    "    final_data = []\n",
    "    for i,_ in enumerate(data):\n",
    "        final_data.append([])\n",
    "        final_data[-1].append([])\n",
    "        for j,_ in enumerate(data[0]):\n",
    "            final_data[-1][-1].append([data[i][j][0],data[i][j][1]])\n",
    "    hydrodynamic_data[tide_type].data = np.array(final_data).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14c4e06",
   "metadata": {},
   "source": [
    "## Add vessel speeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2cc392",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(path+\"\\\\03_Simulation\\\\01_Input_data\\\\03_Vessels\\\\vessel_speed_dataframe.pickle\", \"rb\") as input_file:\n",
    "    vessel_speed_dataframe = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bef943c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add missing vessel speeds and convert to xarray\n",
    "missing_vessel_speeds = pd.DataFrame([0.1,0.1,5,5],columns=['average_speed'],index=[('anchorage','8866969'),('8866969','anchorage'),('B17838816_B', 'B17838816_A'),('B17838816_A', 'B17838816_B')])\n",
    "missing_vessel_speeds.index.name = 'edge'\n",
    "vessel_speed_dataframe = pd.concat([vessel_speed_dataframe,missing_vessel_speeds],axis=0)\n",
    "vessel_speed_data = vessel_speed_dataframe.to_xarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd6f507",
   "metadata": {},
   "source": [
    "## Create Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43d4ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = model.Simulation(graph = FG,\n",
    "                       simulation_start=simulation_start,\n",
    "                       simulation_stop=simulation_stop,\n",
    "                       hydrodynamic_data = hydrodynamic_data,\n",
    "                       vessel_speed_data = vessel_speed_data)\n",
    "env = sim.environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69d0de9",
   "metadata": {},
   "source": [
    "## Import vessels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b620d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path+\"\\\\03_Simulation\\\\01_Input_data\\\\03_Vessels\\\\origin_destination_PoR.pickle\", \"rb\") as input_file:\n",
    "    origin_destination_matrix = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dacf08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some corrections to the matrix\n",
    "origin_destination_matrix['berth_node'] = '8866859'\n",
    "origin_destination_matrix = origin_destination_matrix.sort_values('arrival')\n",
    "origin_destination_matrix = origin_destination_matrix.reset_index(drop=True)\n",
    "origin_destination_matrix.loc[69,'(un)loading time'] = origin_destination_matrix.loc[69,'(un)loading time']/2\n",
    "origin_destination_matrix.loc[69,'destination_node'] = '8868178'\n",
    "origin_destination_matrix.loc[144,'berth_of_call'] = 'Koole_Buiten10'\n",
    "origin_destination_matrix.loc[259,'berth_of_call'] = 'Koole_Kade_H'\n",
    "origin_destination_matrix.loc[460,'arrival'] = pd.Timestamp('2019-12-08 05:20:00+0000', tz=pytz.utc)\n",
    "for index in origin_destination_matrix[origin_destination_matrix.origin_node == '8866859'].index:\n",
    "    origin_destination_matrix.loc[index,'origin_node'] = '8866999'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8898fd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define arrival times, departure times and berths of calls for the nautical traffic model\n",
    "origin_destination_matrix['arrival_time'] = origin_destination_matrix['arrival']+origin_destination_matrix['waiting_time_in_anchorage']\n",
    "origin_destination_matrix['departure_time'] = origin_destination_matrix['arrival_time']+origin_destination_matrix['(un)loading time']\n",
    "origin_destination_matrix['berth_of_call'] = [berth.split('Koole_')[1] for berth in origin_destination_matrix['berth_of_call']]\n",
    "corrected_origin_destination_matrix = origin_destination_matrix.copy()\n",
    "merge_locs = {}\n",
    "for column in origin_destination_matrix.columns:\n",
    "    origin_destination_matrix[column] = origin_destination_matrix[column].astype('object')\n",
    "for name in list(dict.fromkeys(origin_destination_matrix.name)):\n",
    "    df_ship = origin_destination_matrix[origin_destination_matrix.name == name]\n",
    "    if len(df_ship) > 1:\n",
    "        remove_indexes = []\n",
    "        trip_merge = False\n",
    "        for (_,prev_row),(_,next_row) in zip(df_ship.iloc[:-1].iterrows(),df_ship.iloc[1:].iterrows()):\n",
    "            if next_row.arrival_time - prev_row.departure_time < pd.Timedelta(2,'h') and next_row.origin_node in ['8866999','8866859']:\n",
    "                if not trip_merge:\n",
    "                    merge_loc = prev_row.name\n",
    "                    merge_trip_id = prev_row.trip_id\n",
    "                    merge_locs[merge_trip_id] = []\n",
    "                    trip_merge = True\n",
    "                if trip_merge: \n",
    "                    remove_indexes.append(next_row.name)\n",
    "                    merge_locs[merge_trip_id].append(next_row.trip_id)\n",
    "                    for column in ['(un)loading','berth_of_call','(un)loading time','berth_node','destination_node','turning_time']:\n",
    "                        origin_destination_matrix.at[merge_loc,column] = list(np.append(np.array(origin_destination_matrix.loc[merge_loc,column]),next_row[column]))   \n",
    "            elif trip_merge:        \n",
    "                trip_merge = False\n",
    "        origin_destination_matrix = origin_destination_matrix.drop(remove_indexes)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef4c318",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define other parameters for the nautical traffic model\n",
    "for column in ['(un)loading','berth_of_call','turning_time','(un)loading time','berth_node','destination_node']:\n",
    "    values = []\n",
    "    for value in origin_destination_matrix[column].to_numpy():\n",
    "        if not isinstance(value,list):\n",
    "            values.append([value])\n",
    "        else:\n",
    "            values.append(value)\n",
    "    origin_destination_matrix[column] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b9f18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some corrections to these numbers\n",
    "for index in [12,109,156,175]:\n",
    "    origin_destination_matrix.loc[index,'(un)loading'] = [np.max(origin_destination_matrix.loc[index]['(un)loading'])]\n",
    "    origin_destination_matrix.loc[index,'berth_of_call'] = [origin_destination_matrix.loc[index]['berth_of_call'][0]]\n",
    "    origin_destination_matrix.loc[index,'turning_time'] = [origin_destination_matrix.loc[index]['turning_time'][0]]\n",
    "    origin_destination_matrix.loc[index,'(un)loading time'] = [np.sum(origin_destination_matrix.loc[index]['(un)loading time'])]\n",
    "    origin_destination_matrix.loc[index,'destination_node'] = [origin_destination_matrix.loc[index]['destination_node'][-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c47fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculates additional waiting time of vessels\n",
    "additional_waiting_times = {}\n",
    "additional_waiting_times = {**calculate_additional_waiting_time(origin_destination_matrix,\n",
    "                                                                'testschip-3417_0','testschip-2718_0'),\n",
    "                            **calculate_additional_waiting_time(origin_destination_matrix,\n",
    "                                                                'testschip-4407_0','testschip-4157_0'),\n",
    "                            **calculate_additional_waiting_time(origin_destination_matrix,\n",
    "                                                                'testschip-1186_0','testschip-3491_1'), \n",
    "                            **calculate_additional_waiting_time(origin_destination_matrix,\n",
    "                                                                'testschip-8014_0','testschip-1635_0'),\n",
    "                            **calculate_additional_waiting_time(origin_destination_matrix,\n",
    "                                                                'testschip-9416_0','testschip-4025_0'),\n",
    "                            **calculate_additional_waiting_time(origin_destination_matrix,\n",
    "                                                                'testschip-3005_0','testschip-4815_1'),\n",
    "                            **calculate_additional_waiting_time(origin_destination_matrix,\n",
    "                                                                'testschip-12542_0','testschip-12705_0'),\n",
    "                            **calculate_additional_waiting_time(origin_destination_matrix,\n",
    "                                                                'testschip-2817_1','testschip-1290_1'),\n",
    "                            **calculate_additional_waiting_time(origin_destination_matrix,\n",
    "                                                                'testschip-3762_1','testschip-1587_5'),\n",
    "                            **calculate_additional_waiting_time(origin_destination_matrix,\n",
    "                                                                'testschip-6532_1','testschip-5133_1'),\n",
    "                            **calculate_additional_waiting_time(origin_destination_matrix,\n",
    "                                                                'testschip-8702_0','testschip-14181_0'),\n",
    "                            **calculate_additional_waiting_time(origin_destination_matrix,\n",
    "                                                                'testschip-5981_0','testschip-4723_1'),\n",
    "                            **calculate_additional_waiting_time(origin_destination_matrix,\n",
    "                                                                'testschip-9057_0','testschip-14377_0'),\n",
    "                            **calculate_additional_waiting_time(origin_destination_matrix,\n",
    "                                                                'testschip-3688_0','testschip-4269_1'),\n",
    "                            **calculate_additional_waiting_time(origin_destination_matrix,\n",
    "                                                                'testschip-17119_0','testschip-1587_9'),\n",
    "                            **calculate_additional_waiting_time(origin_destination_matrix,\n",
    "                                                                'testschip-9057_1','testschip-5202_2'),\n",
    "                            **calculate_additional_waiting_time(origin_destination_matrix,\n",
    "                                                                'testschip-3491_2','testschip-6922_0'),\n",
    "                            **calculate_additional_waiting_time(origin_destination_matrix,\n",
    "                                                                'testschip-8702_1','testschip-1191_1'),\n",
    "                            **calculate_additional_waiting_time(origin_destination_matrix,\n",
    "                                                                'testschip-4683_0','testschip-18879_0'),\n",
    "                            **calculate_additional_waiting_time(origin_destination_matrix,\n",
    "                                                                'testschip-7523_0','testschip-4908_12'),\n",
    "                            **calculate_additional_waiting_time(origin_destination_matrix,\n",
    "                                                                'testschip-5108_1','testschip-5218_1'),\n",
    "                            **calculate_additional_waiting_time(origin_destination_matrix,\n",
    "                                                                'testschip-4723_2','testschip-5218_1'),\n",
    "                            **calculate_additional_waiting_time(origin_destination_matrix,\n",
    "                                                                'testschip-4352_0','testschip-4723_3'),\n",
    "                            **calculate_additional_waiting_time(origin_destination_matrix,\n",
    "                                                                'testschip-1186_7','testschip-6052_3'),\n",
    "                            **calculate_additional_waiting_time(origin_destination_matrix,\n",
    "                                                                'testschip-4843_2','testschip-20371_0'),\n",
    "                            **calculate_additional_waiting_time(origin_destination_matrix,\n",
    "                                                                'testschip-2343_0','testschip-20933_0'),\n",
    "                            **calculate_additional_waiting_time(origin_destination_matrix,\n",
    "                                                                'testschip-19943_0','testschip-5459_1'), \n",
    "                            **calculate_additional_waiting_time(origin_destination_matrix,\n",
    "                                                                'testschip-4948_2','testschip-12657_1'),\n",
    "                            **calculate_additional_waiting_time(origin_destination_matrix,\n",
    "                                                                'testschip-9416_1','testschip-6409_2'),\n",
    "                            **calculate_additional_waiting_time(origin_destination_matrix,\n",
    "                                                                'testschip-6903_0','testschip-8786_0'), \n",
    "                            **calculate_additional_waiting_time(origin_destination_matrix,\n",
    "                                                                'testschip-6782_2','testschip-18514_0'),\n",
    "                            **calculate_additional_waiting_time(origin_destination_matrix,\n",
    "                                                                'testschip-4955_2','testschip-12657_2'),\n",
    "                            **calculate_additional_waiting_time(origin_destination_matrix,\n",
    "                                                                'testschip-2528_1','testschip-9592_0')}\n",
    "additional_waiting_times['testschip-5108_1']+=np.timedelta64(1,'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9eda25a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Create vessels\n",
    "list_of_vessels = []\n",
    "for loc,info in origin_destination_matrix.iterrows():\n",
    "    Vessel = type('Vessel', (vessel_.IsVessel,\n",
    "                             port.HasPortAccess, \n",
    "                             port.HasAnchorage, \n",
    "                             port.HasTurningBasin, \n",
    "                             port.HasTerminal), {})\n",
    "    if info.origin_node in ['8868178','8866859','8866999']:\n",
    "        bound = 'outbound'\n",
    "    else:\n",
    "        bound = 'inbound'\n",
    "    if info.trip_id in additional_waiting_times.keys():\n",
    "        additional_waiting_time = additional_waiting_times[info.trip_id]\n",
    "    else:\n",
    "        additional_waiting_time = np.timedelta64(0,'s')\n",
    "    \n",
    "    created_vessel = create_vessel(Vessel,\n",
    "                                   env=env,\n",
    "                                   name=info['name'],\n",
    "                                   origin=info['origin_node'],\n",
    "                                   destination=info['berth_node'][0],\n",
    "                                   next_destination=np.append([],info['destination_node']),\n",
    "                                   beam=info['width'],\n",
    "                                   length=info['length'],\n",
    "                                   draught=info['draught'],\n",
    "                                   delta_draught=np.append([],info['(un)loading']),\n",
    "                                   berthing_time=pd.Timedelta(1,'s'),\n",
    "                                   unloading_time=np.append([],info['(un)loading time']),\n",
    "                                   turning_time= [pd.Timedelta(0,'s')], #np.append([],info['turning_time'][0]),\n",
    "                                   arrival_time=info['arrival']+pd.Timedelta(1,'h'),\n",
    "                                   terminal_of_call=np.array(['Koole' for i in range(len(list(info['berth_of_call'])))]),\n",
    "                                   berth_of_call=np.array(info['berth_of_call']),\n",
    "                                   additional_waiting_time = additional_waiting_time,\n",
    "                                   bound=bound)\n",
    "    list_of_vessels.append(created_vessel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8e9ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add vessels to the network\n",
    "for index,vessel in enumerate(list_of_vessels):\n",
    "    sim.add_vessels(vessel=vessel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c193c9d8-38ea-4af9-98fb-cb694896e48c",
   "metadata": {},
   "source": [
    "## Generate and assign infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ba954f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Koole_berths = pd.DataFrame({'MBL':[12.65,8.15,8.15,8.15,17,12.65,6.8,15.9,15.9],\n",
    "                             'Length':[250,253.5,253.5,140,395,250,162,222,253]},\n",
    "                            index=['Kade11','Kade_G','Kade_H','Binnen10','Buiten10','Buiten9','Binnen7','Buiten7','Buiten6'])\n",
    "Koole_berths.index.name = 'Berth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40287275",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(Change infrastructure capacities here)\n",
    "turning_basin_1 = port.IsTurningBasin(env = env, name = 'Turning Basin 1', information = {'Length': 300})\n",
    "anchorage_1 = port.IsAnchorage(env = env, name = 'Anchorage 1', capacity = 50)\n",
    "terminal_1 = port.IsJettyTerminal(env=env,name = 'Koole terminal',type='jetty',information=Koole_berths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373dc446",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FG.nodes['anchorage'][\"Anchorage\"] = [anchorage_1]\n",
    "FG.edges['8866999', '8866859',0][\"Terminal\"] = {'Koole':terminal_1}\n",
    "FG.nodes['8866999'][\"Turning Basin\"] = [turning_basin_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d245fba2",
   "metadata": {},
   "source": [
    "## Append the tidal restriction to the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111934f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Conversion kn to m/s\n",
    "knots = 0.51444\n",
    "\n",
    "# #Restrictions as dictionaries\n",
    "for node in env.FG.nodes:\n",
    "    env.FG.nodes[node]['Info'] = {}\n",
    "    env.FG.nodes[node]['Info']['Vertical tidal restriction'] = {}\n",
    "env.FG.nodes['8861158']['Info']['Horizontal tidal restriction'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5112d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_properties = tidal_window_constructor.NetworkProperties()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef1eee8",
   "metadata": {},
   "source": [
    "### Vertical tidal window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e7355e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#According to Port of Rotterdam Policy (Change here the ukc policy)\n",
    "ukc_p = []\n",
    "ukc_s = []\n",
    "fwa = []\n",
    "        \n",
    "for index,node in enumerate(env.FG.nodes):\n",
    "    if node in ['8866969','8866305','8864266','8862925','8864465','S14716_B','S14716_A','8860845']:\n",
    "        ukc_s.append(0.)\n",
    "        ukc_p.append(0.1)\n",
    "        fwa.append(0.01)\n",
    "    elif node in ['8867547','8867980','8866999']:\n",
    "        ukc_s.append(1.0)\n",
    "        ukc_p.append(0.0)\n",
    "        fwa.append(0.025)\n",
    "    elif node in ['8866859']:\n",
    "        ukc_s.append(0.5)\n",
    "        ukc_p.append(0.0)\n",
    "        fwa.append(0.0)\n",
    "    elif node in ['anchorage']:\n",
    "        ukc_s.append(0.0)\n",
    "        ukc_p.append(0.0)\n",
    "        fwa.append(0.0)\n",
    "    else:\n",
    "        ukc_s.append(0.0)\n",
    "        ukc_p.append(0.1)\n",
    "        fwa.append(0.025)\n",
    "        \n",
    "for index,node in enumerate(env.FG.nodes):\n",
    "    vertical_tidal_window_inputs = []\n",
    "\n",
    "    #Inbound_Vessels_Condition\n",
    "    vessel_specification = tidal_window_constructor.vessel_specifications({rule_constructor.vessel_characteristics.min_ge_Draught: 0},\n",
    "                                                                           'x',rule_constructor.vessel_direction.inbound.value)\n",
    "\n",
    "    window_specification = tidal_window_constructor.vertical_tidal_window_specifications(ukc_s = ukc_s[index],\n",
    "                                                                                         ukc_p = ukc_p[index],\n",
    "                                                                                         fwa = fwa[index],)\n",
    "    \n",
    "    vertical_tidal_window_inputs.append(tidal_window_constructor.vertical_tidal_window_input(vessel_specifications = vessel_specification,\n",
    "                                                                                             window_specifications = window_specification))\n",
    "\n",
    "    #Outbound_Vessels_Condition\n",
    "    vessel_specification = tidal_window_constructor.vessel_specifications({rule_constructor.vessel_characteristics.min_ge_Draught: 0},\n",
    "                                                                           'x',rule_constructor.vessel_direction.outbound.value)\n",
    "\n",
    "    window_specification = tidal_window_constructor.vertical_tidal_window_specifications(ukc_s = ukc_s[index],\n",
    "                                                                                         ukc_p = ukc_p[index],\n",
    "                                                                                         fwa = fwa[index],)\n",
    "\n",
    "    vertical_tidal_window_inputs.append(tidal_window_constructor.vertical_tidal_window_input(vessel_specifications = vessel_specification,\n",
    "                                                                                             window_specifications = window_specification))\n",
    "\n",
    "    network_properties.append_vertical_tidal_restriction_to_network(FG,node,vertical_tidal_window_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cce7e1",
   "metadata": {},
   "source": [
    "### Horizontal tidal window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb29d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Port of Rotterdam Policy 3rd Petroleum Harbour\n",
    "previous_nodes = ['8861716','8861674']\n",
    "node = '8861158'\n",
    "next_node = '8867547'\n",
    "knots = 0.5144444\n",
    "horizontal_tidal_window_inputs = []\n",
    "scheurkade_data = hydrodynamic_data.sel({'STATION':'Scheurkade'})\n",
    "scheurkade_data['TIME'] = scheurkade_data.TIME.values - np.timedelta64(20,'m')\n",
    "\n",
    "for previous_node in previous_nodes:\n",
    "    #Inbound_Vessels_Condition1\n",
    "    vessel_specification = tidal_window_constructor.vessel_specifications({rule_constructor.vessel_characteristics.min_ge_Length: 180,\n",
    "                                                                           rule_constructor.vessel_characteristics.min_ge_Draught: 11.0, #11.0\n",
    "                                                                           rule_constructor.vessel_characteristics.max_lt_Draught: 14.3},\n",
    "                                                                           '(x and x and x)',rule_constructor.vessel_direction.inbound.value)\n",
    "\n",
    "    window_specification = tidal_window_constructor.horizontal_tidal_window_specifications(tidal_window_constructor.horizontal_tidal_window_method.maximum.value,\n",
    "                                                                                           {tidal_window_constructor.tidal_period.Flood.value: 2*knots,tidal_window_constructor.tidal_period.Ebb.value: 2*knots})\n",
    "\n",
    "\n",
    "    horizontal_tidal_window_inputs.append(tidal_window_constructor.horizontal_tidal_window_input(vessel_specifications = vessel_specification,\n",
    "                                                                                                 window_specifications = window_specification,\n",
    "                                                                                                 condition = {'Origin': previous_node, 'Destination': next_node},\n",
    "                                                                                                 data = scheurkade_data))\n",
    "    #Inbound_Vessels_Condition2\n",
    "    vessel_specification = tidal_window_constructor.vessel_specifications({rule_constructor.vessel_characteristics.min_ge_Draught: 14.3},\n",
    "                                                  'x',rule_constructor.vessel_direction.inbound.value)\n",
    "\n",
    "    window_specification = tidal_window_constructor.horizontal_tidal_window_specifications(tidal_window_constructor.horizontal_tidal_window_method.point_based.value,\n",
    "                                                                                           {tidal_window_constructor.tidal_period.Flood.value: [1.3*0.5*knots,0.7*0.5*knots],tidal_window_constructor.tidal_period.Ebb.value:tidal_window_constructor.accessibility.inaccessible.value})\n",
    "\n",
    "    horizontal_tidal_window_inputs.append(tidal_window_constructor.horizontal_tidal_window_input(vessel_specifications = vessel_specification,\n",
    "                                                                                                 window_specifications = window_specification,\n",
    "                                                                                                 condition = {'Origin': previous_node, 'Destination': next_node},\n",
    "                                                                                                 data = scheurkade_data))\n",
    "\n",
    "    #Outbound_Vessels_Condition1  \n",
    "    vessel_specification = tidal_window_constructor.vessel_specifications({rule_constructor.vessel_characteristics.min_ge_Length: 200,\n",
    "                                                                           rule_constructor.vessel_characteristics.min_ge_Draught: 12.0, #12.0\n",
    "                                                                           rule_constructor.vessel_characteristics.max_lt_Draught: 14.3},\n",
    "                                                                           '(x and x and x)',rule_constructor.vessel_direction.outbound.value)\n",
    "\n",
    "    window_specification = tidal_window_constructor.horizontal_tidal_window_specifications(tidal_window_constructor.horizontal_tidal_window_method.maximum.value,\n",
    "                                                                                           {tidal_window_constructor.tidal_period.Flood.value: 2*knots,tidal_window_constructor.tidal_period.Ebb.value:tidal_window_constructor.accessibility.accessible.value})\n",
    "\n",
    "\n",
    "    horizontal_tidal_window_inputs.append(tidal_window_constructor.horizontal_tidal_window_input(vessel_specifications = vessel_specification,\n",
    "                                                                                                 window_specifications = window_specification,\n",
    "                                                                                                 condition = {'Origin': next_node, 'Destination': previous_node},\n",
    "                                                                                                 data = scheurkade_data))\n",
    "\n",
    "    #Outbound_Vessels_Condition2\n",
    "    vessel_specification = tidal_window_constructor.vessel_specifications({rule_constructor.vessel_characteristics.min_ge_Draught: 14.3}, #14.3\n",
    "                                                  'x',rule_constructor.vessel_direction.outbound.value)\n",
    "\n",
    "    window_specification = tidal_window_constructor.horizontal_tidal_window_specifications(tidal_window_constructor.horizontal_tidal_window_method.point_based.value,\n",
    "                                                                                           {tidal_window_constructor.tidal_period.Flood.value: [1.3*0.5*knots,0.7*0.5*knots],tidal_window_constructor.tidal_period.Ebb.value:tidal_window_constructor.accessibility.inaccessible.value})\n",
    "\n",
    "    horizontal_tidal_window_inputs.append(tidal_window_constructor.horizontal_tidal_window_input(vessel_specifications = vessel_specification,\n",
    "                                                                                                 window_specifications = window_specification,\n",
    "                                                                                                 condition = {'Origin': next_node, 'Destination': previous_node},\n",
    "                                                                                                 data = scheurkade_data))\n",
    "\n",
    "network_properties.append_horizontal_tidal_restriction_to_network(FG,node,horizontal_tidal_window_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128bd13d",
   "metadata": {},
   "source": [
    "## Initiation of the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f487b64",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t1 = timpie.time()\n",
    "sim.run()\n",
    "t2 = timpie.time()\n",
    "print('total simulation time:', t2-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e70baa7",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943fc79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vessels = sim.environment.vessels #extract vessels (entitie) from environment. It collects info while it moves through the network. That info is stored in the log file. The log file has \n",
    "env = sim.environment #extract the environment itself"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bc10cf",
   "metadata": {},
   "source": [
    "### Vessel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b2c0c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create vessel output dataframe\n",
    "output_df = pd.DataFrame(columns=['Shipname','Length','Beam','Trip_number','Origin','Destination','Routes','Anchorage_area',\n",
    "                                  'Waiting_time_in_anchorage','Waiting_time_at_terminal','Turning_basin','Turning_time',\n",
    "                                  'Terminal_of_call','Berth_of_call','(Un)loading_time','Total_sailing_time','Times',\n",
    "                                  'Actions','Location','Nodes','Sailing_distance','Speed','Heading','Draught','MBL',\n",
    "                                  'Net_UKC','Gross_UKC','Ship_related_factors','Water_level','Limiting_current_velocity'])\n",
    "for vessel in vessels:\n",
    "    df = pd.DataFrame.from_dict(vessel.log)\n",
    "    if vessel.output['sailed_routes']:\n",
    "        output_df = pd.concat([output_df,pd.DataFrame(data=[[vessel.name, #'Shipname'   \n",
    "                                                             vessel.L, #'Length'\n",
    "                                                             vessel.B, #'Beam'\n",
    "                                                             0, #'Trip_number'\n",
    "                                                             vessel.output['sailed_routes'][0][0], #'Origin'\n",
    "                                                             vessel.output['sailed_routes'][-1][-1], #'Destination'\n",
    "                                                             vessel.output['sailed_routes'], #'Routes' \n",
    "                                                             vessel.output['visited_anchorages'], #'Anchorage_area'\n",
    "                                                             vessel.output['waiting_times_in_anchorages'], #'Waiting_time_in_anchorage'\n",
    "                                                             vessel.output['waiting_times_at_terminals'], #'Waiting_time_in_anchorage'\n",
    "                                                             vessel.output['visited_turning_basins'], #'Turning_basin'\n",
    "                                                             vessel.output['turning_times'], #'Turning_time'\n",
    "                                                             vessel.output['visited_terminals'], #'Terminal_of_call'\n",
    "                                                             vessel.output['visited_berths'], #'Berth_of_call'\n",
    "                                                             vessel.output['(un)loading_times'], #'(Un)loading_time'\n",
    "                                                             np.array([status['sailing_time'] for status in df.Status.to_numpy()]).sum(), #'Total_sailing_time'\n",
    "                                                             df.Time.to_numpy(), #'Times'\n",
    "                                                             df.Action.to_numpy(), #'Actions'\n",
    "                                                             df.Location.to_numpy(), #'Location'\n",
    "                                                             np.array([status['current_node'] for status in df.Status.to_numpy()]), #'Nodes'\n",
    "                                                             np.array([status['sailing_distance'] for status in df.Status]), #'Sailing_distance'\n",
    "                                                             np.array([status['speed'] for status in df.Status.to_numpy()]), #'Speed'\n",
    "                                                             np.array([status['heading'] for status in df.Status.to_numpy()]), #'Heading'\n",
    "                                                             np.array([status['draught'] for status in df.Status.to_numpy()]), #'Draught'\n",
    "                                                             np.array([status['MBL'] for status in df.Status.to_numpy()]), #'MBL'\n",
    "                                                             np.array([status['net_ukc'] for status in df.Status.to_numpy()]), #'Net_UKC'\n",
    "                                                             np.array([status['gross_ukc'] for status in df.Status.to_numpy()]), #'Gross_UKC'\n",
    "                                                             np.array([status['ship_related_ukc_factors'] for status in df.Status.to_numpy()]), #'Ship_related_factors'\n",
    "                                                             np.array([status['water_level'] for status in df.Status.to_numpy()]), #'Water_level'\n",
    "                                                             np.array([status['limiting current velocity'] for status in df.Status.to_numpy()])]], #'Limiting_current_velocity'\n",
    "                                                      columns=output_df.columns)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b919dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = output_df.reset_index(drop=True)\n",
    "output_df['Trip_id'] = output_df['Shipname']+'_0'\n",
    "\n",
    "for name in list(dict.fromkeys(output_df.Shipname)):\n",
    "    in_df = origin_destination_matrix[origin_destination_matrix.name == name]\n",
    "    out_df = output_df[output_df.Shipname == name]\n",
    "    for trip_id,loc in enumerate(out_df.index):\n",
    "        output_df.loc[loc,'Trip_id'] = in_df.iloc[trip_id].trip_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf92d26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "waiting_time_comparison = {}\n",
    "for loc,trip_id in enumerate(output_df.Trip_id):\n",
    "    modelled_waiting_time_in_anchorage = output_df.loc[loc].Waiting_time_in_anchorage\n",
    "    modelled_waiting_time_at_terminal = output_df.loc[loc].Waiting_time_at_terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56d27d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "waiting_time_comparison = {}\n",
    "for loc,trip_id in enumerate(output_df.Trip_id):\n",
    "    modelled_waiting_time_in_anchorage = output_df.loc[loc].Waiting_time_in_anchorage\n",
    "    modelled_waiting_time_at_terminal = output_df.loc[loc].Waiting_time_at_terminal\n",
    "    if modelled_waiting_time_in_anchorage:\n",
    "        total_waiting_time = np.sum(list(modelled_waiting_time_in_anchorage[0].values()))\n",
    "        waiting_for_available_terminal = modelled_waiting_time_in_anchorage[0]['Availability']\n",
    "        waiting_for_tidal_window = modelled_waiting_time_in_anchorage[0]['Tidal window']\n",
    "        waiting_due_to_priority = modelled_waiting_time_in_anchorage[0]['Priority']\n",
    "    elif modelled_waiting_time_at_terminal:\n",
    "        total_waiting_time = np.sum(list(modelled_waiting_time_at_terminal[0][0].values()))\n",
    "        waiting_for_available_terminal = modelled_waiting_time_at_terminal[0][0]['Availability']\n",
    "        waiting_for_tidal_window = modelled_waiting_time_at_terminal[0][0]['Tidal window']\n",
    "        waiting_due_to_priority =  modelled_waiting_time_at_terminal[0][0]['Priority']\n",
    "    else:\n",
    "        total_waiting_time = pd.Timedelta(0,'s')\n",
    "        waiting_due_to_priority = pd.Timedelta(0,'s')\n",
    "        waiting_for_tidal_window = pd.Timedelta(0,'s')\n",
    "        waiting_for_available_terminal = pd.Timedelta(0,'s')\n",
    "    if modelled_waiting_time_at_terminal:\n",
    "        total_waiting_time += np.sum(list(modelled_waiting_time_at_terminal[0][-1].values()))\n",
    "        outbound_waiting_for_available_terminal = modelled_waiting_time_at_terminal[0][-1]['Availability']\n",
    "        outbound_waiting_for_tidal_window = modelled_waiting_time_at_terminal[0][-1]['Tidal window']\n",
    "        outbound_waiting_due_to_priority =  modelled_waiting_time_at_terminal[0][-1]['Priority']\n",
    "    else:\n",
    "        outbound_waiting_due_to_priority = pd.Timedelta(0,'s')\n",
    "        outbound_waiting_for_tidal_window = pd.Timedelta(0,'s')\n",
    "        outbound_waiting_for_available_terminal = pd.Timedelta(0,'s')\n",
    "        \n",
    "    \n",
    "    waiting_time_comparison[trip_id] = [waiting_for_tidal_window,\n",
    "                                        waiting_for_available_terminal,\n",
    "                                        waiting_due_to_priority,\n",
    "                                        outbound_waiting_due_to_priority,\n",
    "                                        outbound_waiting_for_available_terminal,\n",
    "                                        outbound_waiting_for_tidal_window,\n",
    "                                        total_waiting_time,\n",
    "                                        origin_destination_matrix[origin_destination_matrix.trip_id == trip_id].waiting_time_in_anchorage.to_numpy()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e1c285",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df = pd.DataFrame.from_dict(waiting_time_comparison,orient='index',columns=['Waiting_for_tidal_window_inbound',\n",
    "                                                                                       'Waiting_for_available_berth_inbound',\n",
    "                                                                                       'Waiting_due_to_priority_inbound',\n",
    "                                                                                       'Waiting_due_to_priority_outbound',\n",
    "                                                                                       'Waiting_for_available_berth_outbound',\n",
    "                                                                                       'Waiting_for_tidal_window_outbound',\n",
    "                                                                                       'Modelled_total_waiting_time',\n",
    "                                                                                       'Observed_total_waiting_time'])\n",
    "for index in comparison_df[pd.isnull(comparison_df['Observed_total_waiting_time'].to_numpy())].index:\n",
    "    comparison_df.loc[index,'Observed_total_waiting_time'] = np.timedelta64(0,'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecfb45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path+'\\\\04_Output_data'+'\\\\01_Simulation_results'+'\\\\model_outcome.pickle','wb') as handle:\n",
    "    pickle.dump(comparison_df, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
